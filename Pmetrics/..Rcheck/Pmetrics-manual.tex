\nonstopmode{}
\documentclass[a4paper]{book}
\usepackage[times,inconsolata,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8,latin1]{inputenc}
% \usepackage{graphicx} % @USE GRAPHICX@
\makeindex{}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `Pmetrics'}}
\par\bigskip{\large \today}
\end{center}
\begin{description}
\raggedright{}
\item[Maintainer]\AsIs{Michael Neely }\email{mneely@usc.edu}\AsIs{}
\item[License]\AsIs{GPL (>= 2)}
\item[Title]\AsIs{Pmetrics is a parametric and non-parametric pharmacometric
modeling and simulation software package}
\item[Type]\AsIs{Package}
\item[LazyLoad]\AsIs{yes}
\item[LazyData]\AsIs{yes}
\item[Author]\AsIs{Michael Neely }\email{contact@lapk.org}\AsIs{}
\item[Description]\AsIs{This package contains functions to run and
analyze the output from all three components of the
Pmetrics software suite for population pharmacometric
data analysis: 1) IT2B (Iterative Two-Stage Bayesian)
for parametric models; 2) NPAG (Non-parametric Adaptive
Grid) for non-paramametric models; 3) Simulator for
semi-parametric Monte-Carlo simulations. It includes
source code from the NPDE package by Emanuelle Comets, et al,
which used to be on CRAN.}
\item[Author@R]\AsIs{person(``Michael'', ``Neely'', email=``mneely@usc.edu'',
role=``aut'')}
\item[Version]\AsIs{1.9}
\item[URL]\AsIs{}\url{http://www.lapk.org}\AsIs{}
\item[Date]\AsIs{2020-02-29}
\item[Depends]\AsIs{R (>= 3.5.0), utils, stats}
\item[Suggests]\AsIs{chron, reshape2, plyr, Rcpp, shiny, openxlsx, Matrix, rjson,
stringi, ggplot2, mclust, purrr, askpass, base64enc, methods,
testthat}
\item[Collate]\AsIs{'Deprecated.R' 'dopt.R' 'ERRreport.R' 'ERRrun.R' 'GenAlData.R'
'getGfortran.R' 'getPMoptions.R' 'growth.R' 'ITparse.R'
'ITrun.R' 'makeAUC.R' 'makeCov.R' 'makeCycle.R'
'makeErrorPoly.R' 'makeFinal.R' 'makeNCA.R' 'makeOP.R'
'makePop.R' 'makePost.R' 'makePTA.R' 'makePTAtarg.R'
'makeValid.R' 'mic1.R' 'MMopt.R' 'mtsknn.eq.R' 'mtsknn.R'
'Namespace.R' 'NM2PM.R' 'NpdeGlobal.R' 'NpdeData.R' 'NpdeRes.R'
'NpdeObject.R' 'NpdeFunc\_methods.R' 'NpdeFunc\_plots.R'
'NpdeMain.R' 'NPparse.R' 'NPrun.R' 'plotMMopt.R' 'plotPMcov.R'
'plotPMcycle.R' 'plotPMdopt.R' 'plotPMfinal.R' 'plotPMmatrix.R'
'plotPMop.R' 'plotPMpta.R' 'plotPMsim.R' 'plotPMvalid.R'
'PMaddCRCL.R' 'PMbatch.R' 'PMbuild.R' 'PMcheck.R' 'PMcode.R'
'PMcompare.R' 'PMconfig.R' 'Pmetrics-package.R' 'PMex1.R'
'PMex2.R' 'PMex3.R' 'PMFortranConfig.R' 'PMload.R' 'PMmanual.R'
'PMmatrixRelTime.R' 'PMmb2csv.R' 'PMnews.R' 'PMpatch.R'
'PMreadMatrix.R' 'PMremote.R' 'PMreport.R' 'PMrun.R' 'PMsave.R'
'PMstart.R' 'PMstep.R' 'PMtest.R' 'PMtree.R' 'PMupdate.R'
'PMutilities.R' 'PMwriteMatrix.R' 'PMwrk2csv.R' 'printMMopt.R'
'printPMdopt.R' 'printPMerr.R' 'printPMnpc.R'
'printSummaryPMmatrix.R' 'printSummaryPMop.R' 'qgrowth.R'
'setPMoptions.R' 'SIMparse.R' 'SIMrun.R' 'ssPK.R'
'summaryPMcov.R' 'summaryPMdopt.R' 'summaryPMfinal.R'
'summaryPMmatrix.R' 'summaryPMop.R' 'summaryPMpta.R'}
\item[RoxygenNote]\AsIs{7.0.2}
\end{description}
\Rdcontents{\R{} topics documented:}
\inputencoding{utf8}
\HeaderA{Pmetrics-package}{Parametric and non-parametric modeling and simulation of pharmacokinetic-pharmacodynamic systems.}{Pmetrics.Rdash.package}
\aliasA{Pmetrics}{Pmetrics-package}{Pmetrics}
\keyword{package}{Pmetrics-package}
%
\begin{Description}\relax
This package contains functions to run and analyze the output from all three components
of the Pmetrics software suite for population pharmacometric data analysis:
1) IT2B (Iterative Two-Stage Bayesian) for parametric models; 2) NPAG (Non-parametric
Adaptive Grid) for non-parametric models; 3) Simulator for semi-parametric Monte-Carlo
simulations.
\end{Description}
%
\begin{Author}\relax
Michael Neely, MD
\url{http://www.lapk.org}
\end{Author}
\inputencoding{utf8}
\HeaderA{dist.pred.sim}{Compute distribution of pd/npde using simulations}{dist.pred.sim}
\aliasA{calcnpde.sim}{dist.pred.sim}{calcnpde.sim}
%
\begin{Description}\relax
This function is used to built the distribution of pd/npde using the simulations under the model. The default is to build only the distribution of pd, and to sample from N(0,1) when building the distribution of npde under the null hypothesis.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
dist.pred.sim(npdeObject,nsamp, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{npdeObject}] an object returned by a call to \code{\LinkA{npde}{npde}} or \code{\LinkA{autonpde}{autonpde}}

\item[\code{nsamp}] number of datasets (defaults to 100 or to the number of replications if it is smaller)

\item[\code{...}] additional arguments. Currently only the value of calc.pd and calc.npde may be passed on, and will override their corresponding value in the "options" slot of npdeObject
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an object of class NpdeObject; the ["results"] slot will contain pd and/or npde for a sample of the simulated datasets (depending on whether calc.pd/calc.npde are ), stored in pd.sim and/or npde.sim
\end{Value}
%
\begin{Author}\relax
Emmanuelle Comets <emmanuelle.comets@bichat.inserm.fr>
\end{Author}
%
\begin{References}\relax
K. Brendel, E. Comets, C. Laffont, C. Laveille, and F.
Mentre. Metrics for external model evaluation with an application to the
population pharmacokinetics of gliclazide. \emph{Pharmaceutical Research},
23:2036--49, 2006.
\end{References}
%
\begin{SeeAlso}\relax
\code{\LinkA{npde}{npde}}, \code{\LinkA{autonpde}{autonpde}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

data(theopp)
data(simtheopp)
x<-autonpde(theopp,simtheopp,1,3,4,boolsave=FALSE)
# Use random samples from N(0,1) to obtain a prediction interval on the empirical cdf of the npde
plot(x,plot.type="ecdf",bands=TRUE,approx.pi=TRUE)
# defaults to computing the pd and npde for 100 simulated datasets (in the theophylline example, this uses all the simulated datasets)
x<-dist.pred.sim(x)
# Use the npde from the simulated datasets to obtain a prediction interval on the empirical cdf
plot(x,plot.type="ecdf",bands=TRUE,approx.pi=FALSE)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{Dopt}{Compute D-optimal Sample Times}{Dopt}
%
\begin{Description}\relax
Computes D-optimal sampling times.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
Dopt(run, data, clean = T)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{run}] Run number of an NPAG model run that you wish to use to calculate the D-optimal sample times. An error will result if you try to use a run that was not NPAG.

\item[\code{data}] An optional character vector with the filename of a Pmetrics data file which serves as the template for the dosage regimen and the initial times for the D-optimal sampling.  The format of this file is the same as for any other Pmetrics run, except that EVID=0 observations are the initial sampling times.  OUT values for these lines will be ignored.  Only the first subject will be used as a template.  If a Pmetrics data file is not specified, the first subject will be used from the original run as a template.

\item[\code{clean}] Boolean operator to clean (delete) temporary files made during the optimization.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This algorithm calculates the D-optimal sample times for each grid point 
in a nonparametric population model.  It returns all the sample times and the mean weighted
results.  The optimization is run twice for stability checking, and the results of both runs
are reported.
\end{Details}
%
\begin{Value}
A list of class \emph{PMdopt} with 2 items.
\begin{ldescription}
\item[\code{allDopt }] A data frame with 5 columns: timenum, time1, time2, gridpt, prob.  The \code{timenum} column contains a number from 1 to the number of D-optimal sample times.  The \code{time1} and \code{time2} columns contain the optimal times for each gridpoint and run.  Two separate optimizations are made for stability checking so that the results can be compared.  The \code{gridpt} column contains the gridpoint number for each set of optimal sample times.  The \code{prob} column reports the probability of each gridpoint, and thus of each set of optimal sample times.
\item[\code{means }] A data frame with the weighted mean optimal sample times for each of the two runs.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{SIMrun}{SIMrun}}, \code{\LinkA{plot.MMopt}{plot.MMopt}}, \code{\LinkA{print.MMopt}{print.MMopt}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{ERRreport}{Summarize ERR Run}{ERRreport}
%
\begin{Description}\relax
Generates a summary of an ERR run
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ERRreport(wd, icen, type)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{wd}] The working directory containing the ASS0001 file

\item[\code{icen}] Not used, but included for compatibility with other report functions

\item[\code{type}] Not used, but included for compatibility with other report functions
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Creates an HTML page summarizing an ERR run.  This report is generated
automatically at the end of a successful run.
\end{Details}
%
\begin{Value}
Two files are placed in the \code{wd}
\begin{ldescription}
\item[\code{ASS0001 }] A text file of the results
\item[\code{errlog }] A text file with a log of the session\end{ldescription}
,
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{ERRrun}{Execute an Assay Error Estimation run.}{ERRrun}
%
\begin{Description}\relax
Runs Assay Error Module
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ERRrun(
  model = "model.txt",
  data = "data.csv",
  run,
  include,
  exclude,
  ode = -4,
  tol = 0.001,
  salt,
  cycles = 100,
  search = "cursory",
  xdev = 5,
  auto = T,
  intern = F,
  silent = F,
  overwrite = F,
  nocheck = F
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model}] Name of a suitable model file template in the working directory or
an existing (previous) run number corresponding to a folder in the current working directory that used the same model file as will be used in the current run.
If this is supplied, then the model file will be copied into the current 
working directory for convenience.  If not supplied, 
the default is ``model.txt''.  This file will be converted to a fortran model file.
If it is detected to already be a fortran file, then the analysis will proceed without any further
file conversion.

\item[\code{data}] Name of a suitable data file (see \code{\LinkA{PMwriteMatrix}{PMwriteMatrix}}) or
an existing (previous) run number corresponding to a folder in the current working directory that used the same data file as will be used in the current run.
If this is supplied, then previously made  '.ZMQ' files will be copied into the current 
working directory, bypassing the need to re-convert the .csv file and speeding up the run..

\item[\code{run}] Specify the run number of the output folder.  Default if missing is the next available number.

\item[\code{include}] Vector of subject id values in the data file to include in the analysis.  The default (missing) is all.

\item[\code{exclude}] A vector of subject IDs to exclude in the plot, e.g. c(4,6:14,16:20)

\item[\code{ode}] Ordinary Differential Equation solver log tolerance or stiffness.  Default is -4, i.e. 0.0001.  Higher values will result in faster
runs, but parameter estimates may not be as accurate.

\item[\code{tol}] Tolerance for convergence, with default of 0.001.

\item[\code{salt}] Vector of salt fractions for each ndrug, default is 1 for each drug.  This is not the same as bioavailability.

\item[\code{cycles}] Number of cycles to run. Default is 100.

\item[\code{search}] Default is "cursory", but can be "medium" or "extensive", which take progressively
longer times to converge, but are more accurate.

\item[\code{xdev}] Multiple of standard deviations for parameters to be sent to NPAG as a range.  Default is 5.

\item[\code{auto}] If \code{auto} is \code{False} you can answer all questions about the run environment manually.  This might
be helpful for beginners.  Default is \code{True}.

\item[\code{intern}] MacOSX only: Run ERR in the R console without a batch script.  Default is false.
This will be ignored on Windows systems.  On the latter, the behavior of cmd.exe (aka the ``DOS'' window)
with R is poor - it does not update until the end of execution, so you cannot see any output that indicates that ERR is running.  
If \code{intern=T} the HTML summary page will not be automatically loaded at the end of the run, but all post-run processing will occur normally,
and you can find the HTML summary page in the /outputs folder: ERRreport.html.

\item[\code{silent}] Boolean operator controlling whether a model summary report is given.  Default is \code{True}.

\item[\code{overwrite}] Overwrite existing run result folders.  Default is FALSE.

\item[\code{nocheck}] Suppress the automatic checking of the data file with \code{\LinkA{PMcheck}{PMcheck}}.  Default is \code{FALSE}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{ERRrun} will execute an Assay Error run to estimate error polynomial coefficients.

If all function arguments are default, the simplest execution of this command is 
\code{ERRrun()}.  This will result in generation of a batch file.  On Unix (Mac) systems
will be launched automatically in a terminal window.  On Windows systems, the user
must execute the batch file from the current working directory, which will launch the estimation
program in a command prompt (DOS-like) window.  In either case, it will run independently of R
so that R can be used for other purposes if desired.
\end{Details}
%
\begin{Value}
A successful  run will result in creation of a new folder in the working
directory.  This folder will be named with a date-time stamp in the format "out-YYYYMMMDD-hhmm",
e.g. out-2011Apr10-1015.  Under this folder will be four subfolders: etc, inputs, outputs, and
wrkcopy, described below.
\begin{itemize}

\item{} \bold{etc}   Control files generally not needed by the user after a completed run.
\item{} \bold{inputs}   This folder will contain the .csv data file and the model file.
\item{} \bold{outputs}   This folder will contain the output from the run: a file that will be
prefixed by ASS with appended numbers, usually 0001. This file contains all the output of the
run, with the estimated assay error polynomical coefficients at the end.
\item{} \bold{wrkcopy}    The working copy format which is used by the program.  Invisibly to the user,
the .csv input file is converted to these text files, one file per subject.  

\end{itemize}

\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{ITrun}{ITrun}}, \code{\LinkA{NPrun}{NPrun}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{getPMoptions}{Get Pmetrics User Options}{getPMoptions}
%
\begin{Description}\relax
Get user options for Pmetrics
\end{Description}
%
\begin{Usage}
\begin{verbatim}
getPMoptions(opt)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{opt}] The option to retrieve.  If omitted, all option values will be returned.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will get user options for Pmetrics.  Current user options are
\begin{itemize}

\item{} sep Field separator in data files
\item{} dec Decimal separator in numbers

\end{itemize}

\end{Details}
%
\begin{Value}
The user options file will be updated.  This will persist from session to session.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{gof.test}{Test on npde or pd}{gof.test}
\methaliasA{gof.test.NpdeObject}{gof.test}{gof.test.NpdeObject}
\methaliasA{gof.test.NpdeRes}{gof.test}{gof.test.NpdeRes}
\methaliasA{gof.test.numeric}{gof.test}{gof.test.numeric}
\aliasA{print.gof.test}{gof.test}{print.gof.test}
\keyword{test}{gof.test}
%
\begin{Description}\relax
Performs a global test on npde (default) or pd
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'NpdeObject'
gof.test(object, which = "npde", parametric = TRUE, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] an object (currently has methods for types numeric, NpdeRes and NpdeObject)

\item[\code{which}] whether the tests should be performed for npde (default), pd or npd (normalised pd)

\item[\code{parametric}] whether parametric or non-parametric tests should be applied

\item[\code{...}] additional arguments passed on to the function; special arguments are \code{na.action}, which controls how to handle NAs in the results (\code{\LinkA{na.action}{na.action}}), \code{verbose} (if FALSE, suppresses printing of the results) and \code{covsplit} which requests the tests to be performed split by categories or quantiles of the data. If \code{covsplit} is TRUE, continuous covariates will be split in 3 categories (<Q1, Q1-Q3, >Q3) (see details in the PDF documentation), but this behaviour can be overriden by passing the argument \code{ncat=XXX} where XXX is the number of categories to divide the continuous covariates in.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
If object is an NpdeObject and an argument covsplit=TRUE is given in \dots, in addition to the global descriptive statistics and tests, tests will be performed for each covariate in \code{which.cov}. This argument can be set in \dots; barring an explicit specification, the component \code{which.cov} of the prefs slot for a NpdeObject object will be used. The default value is \code{which.cov="all"}, which produces tests for each covariate in the dataset. Two additional dataframes will then be present:
\begin{description}

\item[cov.stat] descriptive statistics and test p-values split by covariate and by categories
\item[cov.p.value] p-values split by covariate; for each covariate, two tests are performed: the first test is a correlation test for continuous covariates and a Chi-square test for categorical covariates; the second test is defined using the p-values of the global tests split by each category, and appling a Bonferroni correction to obtain an overall p-value (see PDF documentation for details)

\end{description}

The p.value elements is a named vector with four components:
\begin{description}

\item[p.mean] p-value for the mean test (Wilcoxon test if parametric=FALSE, Student test if parametric=TRUE)
\item[p.var] p-value for the variance test (parametric=FALSE, Fisher test if parametric=TRUE)
\item[p.dist] p-value for the distribution test (XXX if parametric=FALSE, XXX if parametric=TRUE)
\item[p.global] p-value for the global test (combination of the mean, variance and distribution tests with a Bonferroni correction)

\end{description}

\end{Details}
%
\begin{Value}
A list with the following elements:
\begin{description}

\item[mean] mean
\item[se.mean] standard error of the mean
\item[var] variance
\item[se.var] standard error on variance
\item[kurtosis] kurtosis (see \code{\LinkA{kurtosis}{kurtosis}})
\item[skewness] skewness (see \code{\LinkA{skewness}{skewness}})
\item[p.value] p-values for several tests (see below)

\end{description}

\end{Value}
%
\begin{References}\relax
K. Brendel, E. Comets, C. Laffont, C. Laveille, and F.Mentre. Metrics for external model evaluation with an application to the population pharmacokinetics of gliclazide. \emph{Pharmaceutical Research}, 23:2036--49, 2006.

K. Brendel, E. Comets, C. Laffont, and F.Mentre. Evaluation of different tests based on observations for external model evaluation of  population analyses. \emph{Journal of Pharmacokinetics and Pharmacodynamics}, 37:49--65, 2010.
\end{References}
%
\begin{SeeAlso}\relax
\code{\LinkA{kurtosis}{kurtosis}}, \code{\LinkA{skewness}{skewness}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

data(theopp)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{growth}{CDC Pediatric and Adolescent Growth Data Table}{growth}
\keyword{datasets}{growth}
%
\begin{Description}\relax
Centers for Disease Control Pediatric and Adolescent Growth Data Table
\end{Description}
%
\begin{Usage}
\begin{verbatim}
growth
\end{verbatim}
\end{Usage}
%
\begin{Format}
A data frame with the following 9 columns: KNOT (integer age in months); A, B1, B2, B3 (coefficients for calculating
percentiles), SEX, AGE, PERCENTILE, and CHART (length x age, wt x age, wt x length, hc x age, or ht x age).
\end{Format}
%
\begin{Details}\relax
Coefficients to calculate sex-specific percentiles of length, weight and head cicumference data 
in children from 0 to 18 years.  Downloaded and combined from http://www.cdc.gov/growthcharts/data\_tables.htm.
Used with the \code{qgrowth} function to generate height and weight percentiles for the purposes of simulation.
\end{Details}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{ITparse}{Parse Pmetrics IT2B Output}{ITparse}
%
\begin{Description}\relax
\code{ITparse} processes the output from an IT2B run into a list.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ITparse(outfile = "IT_RF0001.TXT")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{outfile}] This is the filename of the output from IT2B. Typically,
the file will be called IT\_RF0001.txt, and this is the default.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function can take some time to process the RFILE, depending on the number of subjects,
doses, observations, etc.  Typical wait times are a few seconds up to 5 minutes.
When processing is complete a summary of the extracted data will be reported on the console.
\end{Details}
%
\begin{Value}
The output of \code{ITparse} is a list with the following objects and
of the class \emph{IT2B}.
\begin{ldescription}
\item[\code{nsub }] Number of subjects
\item[\code{nvar }] Number of random variables or parameters in the model
\item[\code{nofix }] Number of fixed variables or parameters in the model
\item[\code{par }] Names of random parameters
\item[\code{parfix }] Names of fixed parameters
\item[\code{covnames }] Names of covariates
\item[\code{ab }] Suggested boundaries for each random parameter to be passed to NPAG
\item[\code{fixedpos }] Index of variables fixed to be positive
\item[\code{valfix }] Values for fixed parameters
\item[\code{icycmax }] Maximum number of cycles specified by the user
\item[\code{icyctot }] Number of cycles run.  If less than \code{icycmax}, convergence occurred.
\item[\code{stoptol }] Stopping tolerance for convergence, default 0.001
\item[\code{converge }] Boolean value if convergence occurred.
\item[\code{ODEtol }] Ordindary Differential Equation solver tolerance.
\item[\code{numeqt }] Number of output equations
\item[\code{ERRmod }] Vector of length equal to \code{numeqt} whose values are 0 if gamma was estimated for that
output equation or 1 if gamma was fixed to 1 for that output equation
\item[\code{ndrug }] Number of drug inputs
\item[\code{salt }] Vector of values of the salt fraction for each \code{ndrug}
\item[\code{ndose }] Vector of the number of doses for each subject in the population
\item[\code{ncov }] Number of covariates in the model
\item[\code{nobs }] Vector of the number of observations for each subject in the population
\item[\code{nobsmax }] Maximum number of observation in any individual subject
\item[\code{ypredpop }] Array of population model predictions for each subject at each observation time point.
\emph{ypredpop[nsub,numeqt,time,type]} where \emph{type} is 1=mean, 2=median of the population prior used to calculate ypredpop
\item[\code{ypredbay }] Array of Bayesian posterior model predictions for each subject at each observation time point.
\emph{ypredbay[nsub,numeqt,time,type]} where \emph{type} is 1=mean, 2=median of the population prior used to calculate ypredbay
\item[\code{parbay }] Array of Bayesian posterior parameter estimates for each subject,
\emph{parbay[nsub,nvar,type]} where \emph{type} is 1=mean, 2=median of the population prior used to calculate parbay
\item[\code{ic }] Data frame with one row and two columns for final cycle Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC)
\item[\code{ilog }] Vector of cycle number and associated log-likelihood
\item[\code{imean }] Matrix of cycle numbers and associated means for each random parameter
\item[\code{imed }] Matrix of cycle numbers and associated medians for each random parameter
\item[\code{isd }] Matrix of cycle numbers and associated standard deviations for each random parameter
\item[\code{icv }] Matrix of cycle numbers and associated coefficients of variation for each random parameter
\item[\code{igamlam }] Matrix of cycle number and associated gamma or lambda with each output equation in a column
\item[\code{lpar }] Matrix of subjects in rows and MAP Bayesian parameter estimates in columns for each parameter,
based on population means from the next to last cycle.
\item[\code{lsd }] Matrix of subjects in rows and SD of Bayesian posterior parameter distributions in columns for each parameter,
based on population means from the next to last cycle.
\item[\code{lcv }] Matrix of subjects in rows and CV of Bayesian posterior parameter distributions in columns for each parameter,
based on population means from the next to last cycle.
\item[\code{sdata }] Subject data consisting of 5 columns: [id,  nsub,  age,  sex,  ht],
\emph{id} is the original identification number in the .csv matrix file;
\emph{nsub} is the sequential subject number in the IT2B run; \emph{age},
\emph{sex} and \emph{ht} will be missing for .csv input and present if included in .wrk input files
\item[\code{dosecov }] Data frame with all dosing information for each subject,  including times,  routes,  amounts,  and associated covariate values
\item[\code{outputs }] Data frame with measured outputs for each subject and associated assay error polynomials.
The order of the columns is nsub, time, numeqt, observation, c0, c1, c2, c3, where the last
four columns are the coefficients of the assay error polynomial for that observation, such that
SD[obs] = c0 + c1*[obs] + c2*[obs]**2 + c3*[obs]**3
\item[\code{negflag }] A flag indicating that some negative predictions were changed to missing.
This means that the model may be misspecified.
\item[\code{mdata }] The filename of the data used in the run.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{ITrun}{Execute an IT2B run.}{ITrun}
%
\begin{Description}\relax
Runs IT2B
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ITrun(
  model = "model.txt",
  data = "data.csv",
  run,
  include,
  exclude,
  ode = -4,
  tol = 0.001,
  salt,
  cycles = 100,
  xdev = 5,
  icen = "median",
  auto = T,
  intern = F,
  silent = F,
  overwrite = F,
  nocheck = F,
  batch = F,
  alq = F
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model}] Name of a suitable model file template in the working directory or
an existing (previous) run number corresponding to a folder in the current working directory that used the same model file as will be used in the current run.
If this is supplied, then the model file will be copied into the current 
working directory for convenience.  If not supplied, 
the default is ``model.txt''.  This file will be converted to a fortran model file.
If it is detected to already be a fortran file, then the analysis will proceed without any further
file conversion.

\item[\code{data}] Name of a suitable data file (see \code{\LinkA{PMwriteMatrix}{PMwriteMatrix}}) or
an existing (previous) run number corresponding to a folder in the current working directory that used the same data file as will be used in the current run.
If this is supplied, then previously made  '.ZMQ' files will be copied into the current 
working directory, bypassing the need to re-convert the .csv file and speeding up the run..

\item[\code{run}] Specify the run number of the output folder.  Default if missing is the next available number.

\item[\code{include}] Vector of subject id values in the data file to include in the analysis.  The default (missing) is all.

\item[\code{exclude}] A vector of subject IDs to exclude in the plot, e.g. c(4,6:14,16:20)

\item[\code{ode}] Ordinary Differential Equation solver log tolerance or stiffness.  Default is -4, i.e. 0.0001.  Higher values will result in faster
runs, but parameter estimates may not be as accurate.

\item[\code{tol}] Tolerance for convergence, with default of 0.001.

\item[\code{salt}] Vector of salt fractions for each ndrug, default is 1 for each drug.  This is not the same as bioavailability.

\item[\code{cycles}] Number of cycles to run. Default is 100.

\item[\code{xdev}] Multiple of standard deviations for parameters to be sent to NPAG as a range.  Default is 5.

\item[\code{icen}] Summary of parameter distributions to be used to calculate predictions in HTML report.  Default is "median", but could be "mean".
\#Predictions based on both summaries will be available in objects loaded by \code{\LinkA{PMload}{PMload}}.

\item[\code{auto}] If \code{auto} is \code{False} you can answer all questions about the run environment manually.  This might
be helpful for beginners.  Default is \code{True}.

\item[\code{intern}] MacOSX only: Run IT2B in the R console without a batch script.  Default is false.
This will be ignored on Windows systems.  On the latter, the behavior of cmd.exe (aka the ``DOS'' window)
with R is poor - it does not update until the end of execution, so you cannot see any output that indicates that IT2B is running.  
If \code{intern=T} the HTML summary page will not be automatically loaded at the end of the run, but all post-run processing will occur normally,
and you can find the HTML summary page in the /outputs folder: IT2Breport.html.

\item[\code{silent}] Boolean operator controlling whether a model summary report is given.  Default is \code{True}.

\item[\code{overwrite}] Overwrite existing run result folders.  Default is \code{FALSE}.

\item[\code{nocheck}] Suppress the automatic checking of the data file with \code{\LinkA{PMcheck}{PMcheck}}.  Default is \code{FALSE}.

\item[\code{batch}] Set to true when \code{\LinkA{PMbatch}{PMbatch}} is used.

\item[\code{alq}] For internal developer use only.  Should be set to \code{FALSE}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{ITrun} will execute an IT2B run.

If all function arguments are default, the simplest execution of this command is 
\code{ITrun()}.  This will result in generation of a batch file.  On Unix (Mac) systems
will be launched automatically in a terminal window.  On Windows systems, the user
must execute the batch file from the current working directory, which will launch IT2B
in a command prompt (DOS-like) window.  In either case, IT2B will run independently of R
so that R can be used for other purposes if desired.
\end{Details}
%
\begin{Value}
A successful IT2B run will result in creation of a new folder in the working
directory. This folder will be named numerically and sequentially with respect to previous runs.   
Within this folder will be four subfolders: etc, inputs, outputs, and
wrkcopy, described below.
\begin{itemize}

\item{} \bold{etc}   Control files for IT2B generally not needed by the user after a completed run.
\item{} \bold{inputs}   This folder will contain the .csv data file and the model file.
\item{} \bold{outputs}   This folder will contain the output from the IT2B run.  These files will be
prefixed by DENF, ILOG, OUTF, OUFF, LAST, FROM and RFILE, with appended numbers, usually 0001.
DEN is the density file which contains the joint posterior density which can be passed to IT2B.
OUTF and OUFF are full and truncated textfiles containing all output of IT2B.  OUFF is missing
density file.  LAST contains last cycle Bayesian posterior parameters and predictions for
each subject.  FROM contains estimated parameter ranges which can be passed to IT2B.
RFILE contains IT2B output formatted for easy import into R, and is the file read by
the \code{\LinkA{ITparse}{ITparse}} command.  Finally, there will also be an itlog.txt file
containing additional run information.
\item{} \bold{wrkcopy}    The working copy format which is used by IT2B.  Invisibly to the user,
the .csv input file is converted to these text files, one file per subject.  

\end{itemize}

\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{ITparse}{ITparse}}, \code{\LinkA{NPrun}{NPrun}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{kurtosis}{Kurtosis}{kurtosis}
\keyword{univar}{kurtosis}
%
\begin{Description}\relax
Computes the kurtosis.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
kurtosis(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] a numeric vector containing the values whose kurtosis is to be
computed. NA values are removed in the computation.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
If \eqn{N = \mathrm{length}(x)}{}, then the kurtosis of \eqn{x}{}
is defined as: \deqn{N sum_i (x_i-\mathrm{mean}(x))^4 (sum_i
(x_i-\mathrm{mean}(x))^2)^(-2) - }{}\deqn{3}{}
\end{Details}
%
\begin{Value}
The kurtosis of \code{x}.
\end{Value}
%
\begin{References}\relax
G. Snedecor, W. Cochran. \emph{Statistical Methods}, 
Wiley-Blackwell, 1989
\end{References}
%
\begin{Examples}
\begin{ExampleCode}

x <- rnorm(100)
kurtosis(x)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{makeAUC}{Calculation of AUCs}{makeAUC}
%
\begin{Description}\relax
Calculates AUC from a variety of inputs
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeAUC(
  data,
  formula,
  include,
  exclude,
  start = 0,
  end = Inf,
  icen = "median",
  outeq = 1,
  block = 1,
  method = "linear"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] A suitable data object of the \emph{PMpop} class (see \code{\LinkA{makePop}{makePop}}),
\emph{PMpost} class (see \code{\LinkA{makePost}{makePost}}),
\emph{PMop} class (see \code{\LinkA{makeOP}{makeOP}}),
the \emph{PMsim} class (see \code{\LinkA{SIMparse}{SIMparse}}), or some other suitable dataframe
with at least time/observation columns referred to by \code{formula}, with an ``id'' column (so named) if necessary.

\item[\code{formula}] A formula of the form \code{obs \textasciitilde{} time}.  This is only required with data that is not of class PMpop, PMpost, PMop or PMsim.

\item[\code{include}] A vector of subject IDs to include in the AUC calculations, e.g. c(1:3,5,15)

\item[\code{exclude}] A vector of subject IDs to exclude in the AUC calculations, e.g. c(4,6:14,16:20)

\item[\code{start}] Specify the time to begin AUC calculations. Default is 0.

\item[\code{end}] Specify the time to end AUC calculations so that AUC is calculated
from \code{start} to \code{end}.  Default for end is the maximum observation
time for each subject.  Subjects with insufficient data for a specified interval will have
AUC calculated for the available data, not to exceed the specified interval.

\item[\code{icen}] Only relevant for PMpost or PMpop objects which have predictions based on median or mean of each
subject's Bayesian posterior parameter distribution.  Default is "median", but could be "mean".

\item[\code{outeq}] Specify which output equation is to be used.  Default is 1.

\item[\code{block}] Specify which observation block (separated by EVID=4) is to be used for each subject.  Default is 1.

\item[\code{method}] Default is "linear" for AUC trapezoidal calculation.  Any other value will result in
linear up, log down.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{makeAUC} will calculate the area under the time concentration curve using the
trapezoidal approximation from a variety of inputs.  If a PMpost, PMop, or PMsim object is specified, 
\code{formula} is not required.  AUCs from PMop objects are based on observations.
For AUCs based on predictions, use a PMpost object.
\end{Details}
%
\begin{Value}
The output of \code{makeAUC} is a dataframe of class \emph{PMauc},
which has 2 columns:
\begin{ldescription}
\item[\code{id }] subject identification
\item[\code{tau }] AUC from \code{start} to \code{end}
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeOP}{makeOP}}, \code{\LinkA{SIMparse}{SIMparse}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
op <- makeOP(NPdata.1)
makeAUC(op)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{makeCov}{Extract covariate data}{makeCov}
%
\begin{Description}\relax
Generates an data.frame with subject-specific covariate data from an \emph{NPAG} or \emph{IT2B} object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeCov(data)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] A suitable data object of the \emph{NPAG} or \emph{IT2B} class (see \code{\LinkA{NPparse}{NPparse}} or \code{\LinkA{ITparse}{ITparse}}).
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
For each subject, \code{makeCov} extracts covariate information and Bayesian posterior parameter estimates.
This output of this function is suitable for exploration of covariate-parameter, covariate-time, or parameter-time relationships.
\end{Details}
%
\begin{Value}
The output of \code{makeCov} is a dataframe of class \emph{PMcov},
which has the following columns:
\begin{ldescription}
\item[\code{id }] Subject identification
\item[\code{time }] Times of covariate observations
\item[\code{covnames... }] Columns with each covariate observations in the dataset for each subject and \code{time} 
\item[\code{parnames... }] Columns with each parameter in the model and the \code{icen} summary
for each subject, replicated as necessary for covariate observation times and duplicated for Bayesian 
parameter means and medians 
\item[\code{icen}] The type of summarized Bayesian posterior individual parameter values: mean or median.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{NPparse}{NPparse}}, \code{\LinkA{ITparse}{ITparse}}, \code{\LinkA{plot.PMcov}{plot.PMcov}}, \code{\LinkA{summary.PMcov}{summary.PMcov}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
cov <- makeCov(NPdata.1)
cov
names(cov)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{makeCycle}{Summarize Pmetrics Run Cycle Information}{makeCycle}
%
\begin{Description}\relax
Parses the cycle information from an NPAG or an IT2B object.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeCycle(data)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] A suitable data object of the \emph{NPAG} or \emph{IT2B} class (see \code{\LinkA{NPparse}{NPparse}} or \code{\LinkA{ITparse}{ITparse}}).
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will parse the output of \code{\LinkA{NPparse}{NPparse}} or \code{\LinkA{ITparse}{ITparse}} to generate a
list suitable for analysis and plotting of NPAG or IT2B cycle information.
\end{Details}
%
\begin{Value}
The output of \code{makeCycle} is a list of class \emph{PMcycle},
which has 8 objects from NPAG or 6 objects from IT2B :
\begin{ldescription}
\item[\code{names }] Vector of names of the random parameters\end{ldescription}
\#' \begin{ldescription}
\item[\code{names }] Vector of names of the random parameters
\item[\code{cycnum }] Vector cycle numbers, which may start at numbers greater than 1 if a non-uniform prior was specified for the run (NPAG only)
\item[\code{ll }] Matrix of cycle number and -2*Log-likelihood at each cycle
\item[\code{gamlam }] A matrix of cycle number and gamma or lambda at each cycle
\item[\code{mean }] A matrix of cycle number and the mean of each random parameter at each cycle,  normalized to initial mean
\item[\code{sd }] A matrix of cycle number and the standard deviation of each random parameter
at each cycle,  normalized to initial standard deviation
\item[\code{median }] A matrix of cycle number and the median of each random parameter at each cycle,  normalized to initial median
\item[\code{aic }] A matrix of cycle number and Akaike Information Criterion at each cycle
\item[\code{bic }] A matrix of cycle number and Bayesian (Schwartz) Information Criterion at each cycle
\end{ldescription}
A plot method exists in \code{\LinkA{plot}{plot}} for \emph{PMcycle} objects.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{NPparse}{NPparse}}, \code{\LinkA{ITparse}{ITparse}},  \code{\LinkA{plot.PMcycle}{plot.PMcycle}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
cycle <- makeCycle(NPdata.1)
cycle
names(cycle)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{makeErrorPoly}{Assay error polynomial coefficients}{makeErrorPoly}
%
\begin{Description}\relax
This function plots first, second, and third order polynomial functions fitted
to pairs of observations and associated standard deviations for a given output assay.
In this way, the standard deviation associated with any observation may be calculated and
used to appropriately weight that observation in the model building process.  Observations
are weighted by the reciprocal of the variance, or squared standard deviation.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeErrorPoly(
  obs,
  sd,
  data,
  outeq = 1,
  col = "red",
  cex = 3,
  pch = "+",
  lcol = "blue",
  lwd = 2,
  ref = T,
  legend = T,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{obs}] A vector of observations

\item[\code{sd}] A vector of standard deviations obtained from repeated measurements at each
observation in \code{obs}

\item[\code{data}] A Pmetrics data file.  From this, the maximum and mininimum observations will be retrieved.
This is useful to ensure that calculated standard deviations are not negative
at any observation in the dataset.  If not specified, the default is the maximum \emph{obs}.

\item[\code{outeq}] The output equation in \emph{data}.  Default is 1.

\item[\code{col}] Color of the data points. Default is red.

\item[\code{cex}] Relative size of the data points.  Default is 3. See \code{\LinkA{par}{par}}.

\item[\code{pch}] Ploting symbol.  Default is ``+''.  See \code{\LinkA{par}{par}}.

\item[\code{lcol}] Color of the fitted polynomial lines.  Default is blue.

\item[\code{lwd}] Width of the lines. Default is 2.

\item[\code{ref}] Add a reference line at SD 0 to help evaluate that all fitted SDs are >0.  Default is true.

\item[\code{legend}] Boolean argument to plot legend.  Default is \code{TRUE}.

\item[\code{...}] Other plotting parameters as in \code{\LinkA{plot.default}{plot.default}} and \code{\LinkA{par}{par}}
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A plot of the measured observations and fitted polynomial curves and a list with the
first, second, and third order coefficients
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}
makeErrorPoly(obs=c(0,5,50,100,250,500,1000),sd=c(1,0.4,4.5,12,34,60,190))
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{makeFinal}{Summarize NPAG or IT2B Final Cycle Population Values}{makeFinal}
%
\begin{Description}\relax
Extracts final cycle information from NPAG or IT2B run.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeFinal(data)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] A suitable data object of the \emph{NPAG} or \emph{IT2B} class (see \code{\LinkA{NPparse}{NPparse}} or \code{\LinkA{ITparse}{ITparse}}).
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will parse the output of \code{\LinkA{NPparse}{NPparse}} or \code{\LinkA{ITparse}{ITparse}} to generate a
list suitable for analysis and plotting of NPAG  or IT2B final cycle population values.
\end{Details}
%
\begin{Value}
The output of \code{makeFinal} is a list of class \emph{PMfinal}, which contains the following:
\begin{ldescription}
\item[\code{popPoints }] (NPAG only) Dataframe of the final cycle joint population density of grid points
with column names equal to the name of each random parameter plus \emph{prob} for the
associated probability of that point
\item[\code{popMean }] The final cycle mean for each random parameter distribution
\item[\code{popSD }] The final cycle standard deviation for each random parameter distribution
\item[\code{popCV }] The final cycle coefficient of variation (SD/Mean) for each random parameter distribution
\item[\code{popVar }] The final cycle variance for each random parameter distribution
\item[\code{popCov }] The final cycle random parameter covariance matrix
\item[\code{popCor }] The final cycle random parameter correlation matrix
\item[\code{popMedian }] The final cycle median values for each random parameter
\end{ldescription}
\#' \begin{ldescription}
\item[\code{postPoints}] (NPAG only) Dataframe of posterior population points for each of the first 100 subject,
with columns id, point, parameters and probability.  The first column is the subject, the second column has the population
point number, followed by the values for the parameters in that point and the probability.
\item[\code{postMean }] A \emph{nsub} x \emph{npar} data frame containing 
the means of the posterior distributions for each parameter.
\item[\code{postSD }] A \emph{nsub} x \emph{npar} data frame containing 
the SDs of the posterior distributions for each parameter.
\item[\code{postVar }] A \emph{nsub} x \emph{npar} data frame containing 
the variances of the posterior distributions for each parameter.
\item[\code{postCov }] NPAG only: An array of dimensions \emph{npar} x \emph{npar} x \emph{nsub} that
contains the covariances of the posterior distributions for each parameter and subject.
\item[\code{postCor }] NPAG only: An array of dimensions \emph{npar} x \emph{npar} x \emph{nsub} that
contains the correlations of the posterior distributions for each parameter and subject.
\item[\code{postMed }] A \emph{nsub} x \emph{npar} data frame containing 
the medians of the posterior distributions for each parameter.
\item[\code{shrinkage }] A data frame with the shrinkage for each parameter.  \code{popVar}
is comprised of variance(EBE) + variance(EBD), where EBE is the Emprical Bayes Estimate or mean of the posterior
distribution for the parameter. EBD is the Empirical Bayes Distribution, or
the full Bayesian posterior distribution. In other words, if Bayesian posterior distributions are wide
for a given parameter due to sparse or uninformative sampling, then most of the population variance is due
to this variance and shrinkage of the EBE variance is high because individual posterior estimates
shrink towards the population mean.
\item[\code{gridpts }] (NPAG only) Initial number of support points
\item[\code{nsub }] Number of subjects
\item[\code{ab }] Matrix of boundaries for random parameter values
\end{ldescription}
A plot method exists in \code{\LinkA{plot}{plot}} for \emph{PMfinal} objects.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{NPparse}{NPparse}}, \code{\LinkA{ITparse}{ITparse}},  \code{\LinkA{plot.PMfinal}{plot.PMfinal}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
final <- makeFinal(NPdata.1)
final
names(final)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{makeNCA}{Non-compartmental analysis}{makeNCA}
%
\begin{Description}\relax
Performs a non-compartmental analysis from observed concentrations in the raw data
file or from an individual Bayesian posterior predicted 
time-observation profiles (PMpost object) generated automatically after an NPAG run 
by the \code{\LinkA{makePost}{makePost}} command and loaded with \code{\LinkA{PMload}{PMload}}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeNCA(
  x,
  postPred = F,
  include,
  exclude,
  input = 1,
  icen = "median",
  outeq = 1,
  block = 1,
  start = 0,
  end = Inf,
  first = NA,
  last = NA,
  terminal = 3
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] Data to analyze.  This can be specified in a number of ways.
\begin{itemize}

\item{} It can be the run number, e.g. 3, that has been previously loaded with \code{\LinkA{PMload}{PMload}}.
Either the mdata file from the run (NPAG or IT2B) can be used (default) or
the post object can be used (NPAG only) by specifying \code{postPred = T} below.  If \code{x} is a run number that corresponds 
to both an NPAG and IT2B run which have been previously loaded into memory with \code{PMload}, the NPAG run will be used. 
\item{} It can be the run number of a run that has \emph{not} been previously loaded with \code{\LinkA{PMload}{PMload}}.
In this case, the current working directory should be the Runs folder as \code{makeNCA} will call \code{PMload}. 
\item{} It can be the specific name of an mdata.x file already loaded into memory with \code{\LinkA{PMload}{PMload}}, e.g. mdata.3.  Note
that quotation marks are not necessary since mdata.3 is an object, not a label/character vector.
\item{} Finally, it can be the name of a Pmetrics data file in the current working directory, which will be loaded with
\code{\LinkA{PMreadMatrix}{PMreadMatrix}} and analyzed, e.g. ``data.csv''.  In this case, quotation marks are reqired, because \code{x}
is now a character vector specifying the filename of the file to load.

\end{itemize}


\item[\code{postPred}] Boolean switch to use the posterior predictions rather than the observed. 
concentrations.  Default is \code{FALSE}. Ignored if an IT2B run is
used to supply the raw data file.

\item[\code{include}] A vector of subject IDs to include in the NCA, e.g. c(1:3,5,15)

\item[\code{exclude}] A vector of subject IDs to exclude in the NCA, e.g. c(4,6:14,16:20). When \code{postPred} is \code{TRUE}, any subject(s) excluded from the IT2B/NPAG run will be excluded as well.

\item[\code{input}] The number of the input (e.g. drug) to analyze; default 1.

\item[\code{icen}] If \code{postPred} is \code{TRUE}, use predictions based on median or mean of each
subject's Bayesian posterior parameter distribution.  Default is "median", but could be "mean".

\item[\code{outeq}] The number of the output equation to analyze; default 1

\item[\code{block}] The number of the observation block within subjects, with each block delimited by EVID=4 in the data file; default 1

\item[\code{start}] The beginning of the time interval to look for doses and observations, e.g. 120.  It can be
a vector to allow for individual start times per subject, e.g. c(120,120,144,168).  If the length of \code{start}
is less than the number of subjects, the last value will be recycled as needed.  If the \code{start} time is not 0 (default), 
then it is assumed that steady state (multiple dose) conditions apply.

\item[\code{end}] Analogous to \code{start}, set this equal to the end of the dosing interval. It too can be a vector, with the last value
recycled as necessary.  Default is \code{Inf}, i.e. all data used.

\item[\code{first}] Alternative way to specify time interval for NCA by choosing dose number, e.g. 1 or 3.  May be a numeric vector, like \code{start} and \code{end},
e.g. c(1,1,1,3,1,...) to allow for individualization by subject.  The last value will be recycled to ensure length equal to the
number of subjects.  Default is \code{NA}, which means \code{start} will be used.

\item[\code{last}] The complement to \code{first}, specifying the last dose to end the time interval.  If \code{NA},
which is the default, then the maximum time per subject will be the upper bound of the time interval.
Like \code{first}, \code{last} can be a vector, with the last value recycled as necessary.  Use \code{NA} in the vector
to signify maximum time for that subject.

\item[\code{terminal}] Number of observations to use for terminal curve fitting (i.e. to estimate \emph{k}).  Default is 3.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
If concentrations from multiple dose intervals are included in the \code{start}-\code{end} time interval,
\code{makeNCA} will superpose the concentrations using the time after dose.  An error will be generated if
different doses are within this interval as superposition would no longer be valid.

A minimum of 5 concentrations must be available to perform NCA for any given subject.  Fewer than this will
suppress all results for that subject.
\end{Details}
%
\begin{Value}
A dataframe of class \emph{PMnca} with columns
\begin{ldescription}
\item[\code{id }] Subject identification
\item[\code{auc }] Area under the time-observation curve, using the trapezoidal approximation, from time 0 until the second dose, 
or if only one dose, until the last observation
\item[\code{aumc }] Area under the first moment curve
\item[\code{k }] Slope by least-squares linear regression of the final 3 log-transformed observations vs. time.  
If the final 3 concentrations are not decreasing such that linear regression results in a positive slope,
this value and all others that depend on \code{k} will be suppressed.
\item[\code{auclast }] Area under the curve from the time of the last observation to infinity, calculated as [Final obs]/k.
This value will be suppressed if start != 0.
\item[\code{aumclast }] Area under the first moment curve from the time of the last observation to infinity.
This value will be suppressed if start!=0.
\item[\code{aucinf }] Area under the curve from time 0 to infinity, caluculated as auc + auclast
\item[\code{aumcinf }] Area under the first moment curve from time 0 to infinity
\item[\code{mrt }] Mean residence time, calculated as 1/k
\item[\code{cmax }] Maximum predicted concentration after the first dose
\item[\code{tmax }] Time to cmax
\item[\code{cl }] Clearance, calculated as dose/aucinf
\item[\code{vdss }] Volume of distribution at steady state, calculated as cl*mrt
\item[\code{thalf }] Half life of elimination, calculated as ln(2)/k
\item[\code{dose }] Dose for each subject
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{makeOP}{Generated observed vs. predicted data}{makeOP}
%
\begin{Description}\relax
Generates an observed vs. predicted data.frame from an \emph{NPAG} or \emph{IT2B} object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeOP(data)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] A suitable data object of the \emph{NPAG} or \emph{IT2B} class (see \code{\LinkA{NPparse}{NPparse}} or \code{\LinkA{ITparse}{ITparse}}).
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{makeOP} will parse the output of \code{\LinkA{NPparse}{NPparse}} or \code{\LinkA{ITparse}{ITparse}} to generate a
data.frame suitable for analysis and plotting of observed vs. population or
or individual predicted outputs.
\end{Details}
%
\begin{Value}
The output of \code{makeOP} is a data frame of class \emph{PMop}, which has a population and posterior
prediction object (also class \emph{PMop}) for each output equation.  Each of these has 13 columns:
\begin{ldescription}
\item[\code{id }] subject identification
\item[\code{time }] observation time in relative hours
\item[\code{obs }] observation
\item[\code{pred }] prediction
\item[\code{pred.type }] Population predictions based on Bayesian prior parameter value distribution,
or individual predictions based on Bayesian posterior parameter value distributions
\item[\code{icen }] Predictions based on mean or median of Bayesian \code{pred.type} parameter values
\item[\code{outeq }] output equation number
\item[\code{block }] dosing block number for each subject, as defined by dose resets (evid=4).
\item[\code{obsSD }] standard deviation of the observation based on the assay error polynomial
\item[\code{d }] prediction error, \code{pred}-\code{obs}
\item[\code{ds }] squared prediction error
\item[\code{wd }] weighted prediction error, which is the prediction error divided by the \code{obsSD}
\item[\code{wds }] weighted squared prediction error
\end{ldescription}
A plot method exists in \code{\LinkA{plot}{plot}} for \emph{PMop} objects.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{NPparse}{NPparse}}, \code{\LinkA{ITparse}{ITparse}}, \code{\LinkA{plot.PMop}{plot.PMop}}, \code{\LinkA{summary.PMop}{summary.PMop}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
op <- makeOP(NPdata.1)
op
names(op)
summary(op)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{makePop}{Individual Bayesian population prior predictions at short intervals}{makePop}
%
\begin{Description}\relax
Returns the Bayesian population prior predictions at short intervals specified during the NPAG run,
up to 12 minutes.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makePop(run, NPdata)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{run}] The number of the folder that contains the relevant run.  If missing, \code{NPdata} will be used.

\item[\code{NPdata}] Optional name of NPdata object if run is missing.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A dataframe of class \emph{PMpop} with columns:
\begin{ldescription}
\item[\code{id}]  Subject id
\item[\code{time}]  Time of predictions in decimal hours
\item[\code{icen}]  Prediction based on mean or median of Bayesian posterior parameter distribution
\item[\code{pred}]  Predicted output for each outeq
\item[\code{outeq}]  Output equation number
\item[\code{block}]  Observation blocks within subjects as defined by EVID=4 dosing events
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{makePost}{Individual Bayesian posterior predictions at short intervals}{makePost}
%
\begin{Description}\relax
Returns the Bayesian posterior predictions at short intervals specified during the NPAG run,
up to 12 minutes.  These results are contained separately from the main output of NPAG, in the
PRTBxxxx file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makePost(run, NPdata)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{run}] The number of the folder that contains the relevant run.  If missing will be
set to current working directory.

\item[\code{NPdata}] Optional name of NPdata object if run is missing.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A dataframe of class \emph{PMpost} with columns:
\begin{ldescription}
\item[\code{id}]  Subject id
\item[\code{time}]  Time of predictions in decimal hours
\item[\code{icen}]  Prediction based on mean or median of Bayesian posterior parameter distribution
\item[\code{pred}]  Predicted output for each outeq
\item[\code{outeq}]  Output equation number
\item[\code{block}]  Observation blocks within subjects as defined by EVID=4 dosing events
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{makePTA}{Calculation of PTAs}{makePTA}
%
\begin{Description}\relax
Calculates the Percent Target Attainment (PTA)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makePTA(
  simdata,
  simlabels,
  targets,
  target.type,
  success,
  outeq = 1,
  free.fraction = 1,
  start,
  end,
  icen = "median",
  block = 1
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{simdata}] Can be one of multiple inputs.  Typically it is a vector of simulator output filenames, e.g. c(``simout1.txt'',``simout2.txt''),
with wildcard support, e.g. ``simout*'' or ``simout?'', or
a list of PMsim objects made by \code{\LinkA{SIMparse}{SIMparse}} with suitable simulated regimens and observations.  The number and times of simulated
observations does not have to be the same in all objects.  It can also be a \emph{PMpta} object previously made with
\code{makePTA} can be passed for recalculation with a new success value or simlabels.  Finally, \emph{PMpost} and \emph{PMmatrix} objects are 
also allowed.

\item[\code{simlabels}] Optional character vector of labels for each simulation.  Default is \code{c(``Regimen 1'', ``Regimen 2'',...)}.

\item[\code{targets}] A vector of pharmacodynamic targets, such as Minimum Inhibitory Concentrations (MICs), e.g. c(0.25, 0.5,1,2,4,8,16,32).
This can also be a sampled distribution using  \code{\LinkA{makePTAtarget}{makePTAtarget}}.

\item[\code{target.type}] A numeric or character vector, length 1.  If numeric, must correspond to an observation time common to all PMsim objects in
\code{simdata}, rounded to the nearest hour.  In this case, the target statistic will be the ratio of observation at time \code{target.type} to target.  This enables 
testing of a specific timed concentration (e.g. one hour after a dose or C1) which may be called a peak, but is not actually the maximum drug
concentration.  Be sure that the time in the simulated data is used, e.g. 122 after a dose given at 120.  Character values may be one of 
``time'', ``auc'', ``peak'', or ``min'', for, respectively, percent time above target within the time range
specified by \code{start} and \code{end}, ratio of area under the curve within the time range to target, ratio of peak concentration within the time range 
to target, or ratio of minimum concentration within the time range to target.

\item[\code{success}] A single value specifying the success statistic, e.g. 0.4 for proportion time (end-start) above target, or 100 for peak:target.

\item[\code{outeq}] An integer specifying the number of the simulated output equation to use. Default is 1.

\item[\code{free.fraction}] Proportion of free, active drug.  Default is 1, i.e. 100\% free drug or 0\% protein binding.

\item[\code{start}] Specify the time to begin PTA calculations. Default is a vector with the first observation time for subjects
in each element of \code{simdata}, e.g. dose regimen. If specified as a vector, values will be recycled as necessary.

\item[\code{end}] Specify the time to end PTA calculations so that PTA is calculated
from \code{start} to \code{end}.  Default for end is the maximum observation
time for subjects in each element of \code{simdata}, e.g. dose regimen.  If specified as a vector, values will be recycled
as necessary. Subjects with insufficient data (fewer than 5 simulated observations) for a specified interval will trigger a warning.
Ideally then, the simulated datset should contain sufficient observations within the interval specified by \code{start} and \code{end}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{makePTA} will calculate the PTA for any number of simulations, targets and definitions of success.
Simulations typically differ by dose, but may differ by other features such as children vs. adults. This function will also
accept data from real subjects either in the form of a \emph{PMpost} or a \emph{PMmatrix} object.
If a \emph{PMpta} object is passed to the function as the \code{simdata}, the only other parameter required is success. 
If desired, a new set of simlabels can be specified; all other parameters will be ignored.
\end{Details}
%
\begin{Value}
The output of \code{makePTA} is a list of class \emph{PMpta},
which has 2 objects:
\begin{ldescription}
\item[\code{results }] A data frame with the following columns: simnum, id, target, pdi.  
\emph{simnum} is the number of the simulation; \emph{id} is the simulated profile number
within each simulation; \emph{target} is the specified target; and \emph{pdi} is
the target pharmacodynamic index, e.g. time > target, auc:target, etc.
\item[\code{outcome }] A data frame summarizing the results with the following columns: simnum, target, prop.success, pdi.mean, and pdi.sd.
If \code{targets} was specified via \code{\LinkA{makePTAtarget}{makePTAtarget}} to be a sampled distribution, then
the target column will be missing from the outcome table.
\emph{simnum} and \emph{target} are as for \code{results}.  The \emph{prop.success} column has the proportion with a pdi > \code{success},
as specified in the function call.  The \emph{pdi.mean} and \emph{pdi.sd} columns have the 
mean and standard deviation of the target pharmacodynamic index (e.g. proportion end-start above target, ratio of Cmax to target) for each simulation and target.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely and Jan Strojil
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{plot.PMpta}{plot.PMpta}}, \code{\LinkA{SIMparse}{SIMparse}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{makePTAtarget}{Make PTA target object}{makePTAtarget}
%
\begin{Description}\relax
Make a Percent Target Attainment (PTA) Target
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makePTAtarget(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A data.frame or name of .csv file in working directory whose first two
columns are targets and the number of samples for each target.  An example can be
seen for Staphylococcus aureus susceptibility to vancomycin at the EUCAST website
at \LinkA{http://mic.eucast.org/Eucast2/regShow.jsp?Id=1214}{http://mic.eucast.org/Eucast2/regShow.jsp?Id=1214}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{makePTAtarget} generates an object of class \emph{PMpta.targ} which can
be used in the \code{\LinkA{makePTA command}{makePTA command}} for targets sampled from a distribution.
\end{Details}
%
\begin{Value}
A data frame with two columns named targets and n, of class \emph{PMpta.targ}.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{makePTA}{makePTA}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{makeValid}{Create a Pmetrics validation object}{makeValid}
%
\begin{Description}\relax
Creates a Pmetrics validation object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
makeValid(run, input = 1, outeq = 1, tad = F, binCov, doseC, timeC, tadC, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{run}] When the current working directory is the Runs folder, the folder name of a previous run that you wish to use for the npde,
which will typically be a number, e.g. 1.

\item[\code{input}] The input number.  Default is 1.

\item[\code{outeq}] The number of the output equation to simulate/test.  Default is 1.

\item[\code{tad}] Boolean argument, default \code{FALSE}.  If \code{TRUE}, will include 
time after dose (TAD) in binning as well as standard relative time.  \emph{NOTE:} Including TAD is only 
valid if steady state conditions exist for each patient.  This means that dosing is stable and regular
for each patient, without changes in amount or timing, and that sampling occurs after the average concentrations
are the same from dose to dose.  Otherwise observations are \emph{NOT} superimposable and \code{tad} should 
\emph{NOT} be used, i.e. should be set to \code{FALSE}.

\item[\code{binCov}] A character vector of the names of covariates which are included in the model, i.e. in the
model equations and which need to be binned.  For example \code{binCov=``wt''} if ``wt'' is included in a
model equation like V=V0*wt, or \code{binCov=c( ``wt'', ``crcl'')} if both ``wt'' and ``crcl'' 
are included in model equations.

\item[\code{doseC}] An integer with the number of dose/covariate bins to cluster, if known from a previous run of 
this function.  Including this value will skip the clustering portion for doses/covariates.

\item[\code{timeC}] An integer with the number of observation time bins to cluster, if known from a previous run of 
this function.  Including this value will skip the clustering portion for observation times.
\#' @param tadC An integer with the number of time after dose bins to cluster, if known from a previous run of 
this function.  Including this value will skip the clustering portion for time after dose. This argument
will be ignored if \code{tad=FALSE}.

\item[\code{...}] Other parameters to be passed to \code{\LinkA{SIMrun}{SIMrun}}, especially \code{limits}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{makeValid} will create an object suitable for plotting visual predictive checks (VPCs) and prediction-corrected visual
predictive checks (pcVPCs). The function will guide the user
through appropriate clustering of doses, covariates and sample times for prediction correction using the methods of Bergstrand et al (2011).
\end{Details}
%
\begin{Value}
The output of \code{makeValid} is a list of class \code{PMvalid}, which is a list with the following.  
\begin{ldescription}
\item[\code{simdata}] The combined, simulated files for all subjects using the population mean values and each subject
as a template. See \code{\LinkA{SIMparse}{SIMparse}}.
\item[\code{timeBinMedian}] A data frame with the median times for each cluster bin.
\item[\code{tadBinMedian}] A data frame with the median time after dose (tad) for each cluster bin.  This will be \code{NA} if 
\code{tad = FALSE}.
\item[\code{opDF}] A data frame with observations, predicitons, and bin-corrected predictions for each subject.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{SIMrun}{SIMrun}}, \code{\LinkA{plot.PMvalid}{plot.PMvalid}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{mic1}{Example MIC data}{mic1}
\keyword{datasets}{mic1}
%
\begin{Description}\relax
Example MIC data
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mic1
\end{verbatim}
\end{Usage}
%
\begin{Format}
An R data frame containing example MIC distribution data in two columns:
\begin{itemize}

\item{} mic Minimum inhibitory concentration
\item{} n Number of organisms with the given MIC

\end{itemize}
\end{Format}
%
\begin{Details}\relax
This data frame contains MIC data for cefepime against E. coli.  It was obtained 
from the EUCAST website at \url{http://mic.eucast.org}.  Select the organism
or drug, and then select the desired row of the resulting table to see
a histogram (top) and table (bottom) of MIC distributions.

Copy the table into excel, save as a .csv file, and read into R using
\code{\LinkA{read.csv}{read.csv}}.  Then use \code{\LinkA{makePTAtarget}{makePTAtarget}}.
\end{Details}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{MMopt}{Compute MM-optimal Sample Times}{MMopt}
%
\begin{Description}\relax
Computes 1 to 4 MM-optimal sampling times.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
MMopt(
  poppar,
  model = "model.txt",
  data = "data.csv",
  nsamp = 1,
  weight = list(none = 1),
  predInt = 0.5,
  outeq = 1,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{poppar}] An object of class \emph{PMfinal} (see \code{\LinkA{makeFinal}{makeFinal}})

\item[\code{model}] Name of a suitable model file template in the working directory.
The default is ``model.txt''.  This file will be converted to a fortran model file.
If it is detected to already be a fortran file, then the simulation will proceed without any further
file conversion.

\item[\code{data}] Either a PMmatrix object previously loaded with (\code{\LinkA{PMreadMatrix}{PMreadMatrix}}) or character vector with the filename of a Pmetrics matrix file
that contains template regimens and observation times.  The value for outputs can be coded as
any number(s) other than -99.  The number(s) will be replaced in the simulator output with the simulated values.

\item[\code{nsamp}] The number of MM-optimal sample times to compute; default is 1, but can be up to 4.  Values >4 will be capped at 4.

\item[\code{weight}] List whose names indicate the type of weighting, and values indicate the
relative weight. Values should sum to 1.  Names can be any of the following:
\begin{itemize}

\item{} \code{none} The default. MMopt times will be chosen to maximally discriminate all responses at all times.
\item{} \code{AUC} MMopt times will be chosen to maximally discriminate AUC, regardless of the shape of the response profile. 
\item{} \code{max} MMopt times will be chosen to maximally discriminate maximum, regardless of the shape of the response profile.
\item{} \code{min} MMopt times will be chosen to maximally discriminate minimum, regardless of the shape of the response profile. 

\end{itemize}

Any combination of AUC, max, and min can be chosen.  If ``none'' is specified, other
weight types will be ignored and the relative value will be set to 1.
For example,\code{list(auc=0.5,max=0.5)} or \code{auc=0.2,min=0.8}.

\item[\code{predInt}] The interval in fractional hours for simulated predicted outputs at times other than those specified in the template \code{data}.
The default is 0.5, which means there will be simulated outputs every 30 minutes from time 0 up 
to the maximal time in the template file.  You may also specify \code{predInt}
as a vector of 3 values, e.g. \code{c(1,4,1)}, similar to the R command \code{\LinkA{seq}{seq}}, where the
first value is the start time, the second is the stop time, and the third is the
step value.  Outputs for times specified in the template file will also be simulated.
To simulate outputs \emph{only} at the output times in the template data (i.e. EVID=0 events), use \code{predInt=0}.
Note that the maximum number of predictions total is 594, so the interval must be sufficiently large to accommodate this for a given
number of output equations and total time to simulate over.  If \code{predInt} is set so that this cap is exceeded, predictions will be truncated.

\item[\code{outeq}] Output equation to optimize

\item[\code{...}] Other parameters to pass to \code{\LinkA{SIMrun}{SIMrun}}, which are not usually necessary.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Based on the mulitple-model optimization algorithm developed by David Bayard and presented at the 2012 American
College of Clinical Pharmacology Meeting and the 2013 International Association of Therapeutic
Drug Monitoring and Clinical Toxicology meeting.  A manuscript is in preparation.
\end{Details}
%
\begin{Value}
A object of class \emph{MMopt} with 3 items.
\begin{ldescription}
\item[\code{sampleTime }] The MM-optimal sample times
\item[\code{bayesRisk }] The Bayesian risk of mis-classifying a subject based on the sample times.  This
is more useful for comparisons between sampling strategies, with minimization the goal.
\item[\code{simdata }] A \emph{PMsim} object with the simulated profiles
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{SIMrun}{SIMrun}}, \code{\LinkA{plot.MMopt}{plot.MMopt}}, \code{\LinkA{print.MMopt}{print.MMopt}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{mtsknn.eq}{Multivariate two-sample test based on k-nearest neighbors}{mtsknn.eq}
%
\begin{Description}\relax
Compare discrete distributions
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mtsknn.eq(x, y, k, clevel = 0.05, getpval = TRUE, print = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A matrix or data frame.

\item[\code{y}] A matrix or data frame.

\item[\code{k}] k An integer.

\item[\code{clevel}] The confidence level. Default value is 0.05.

\item[\code{getpval}] Logic value. If it is set to be TRUE the p value of 
test will be calcuated and reported; if it is set to be false the 
p value will not be calculated.

\item[\code{print}] Boolean value. If it is set to be TRUE the test 
result will be reported; if it is set to be FALSE the test 
result will not be reported.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function tests whether two samples share the same underlying 
distribution based on k-nearest-neighbors approach.
Matrices or data frames x and y are the two samples to be tested. 
Each row consists of the coordinates of a data point. 
The integer k is the number of nearest neighbors to choose in the 
testing procedure. This approach is robust in the unbalanced case.
\end{Details}
%
\begin{Value}
A list consists of the test statistics, 
normalized Z score and corresponding P value.
\end{Value}
%
\begin{Author}\relax
Lisha Chen (Yale), Peng Dai (Stonybrook) and Wei Dou (Yale)
\end{Author}
%
\begin{References}\relax
Schilling, M. F. (1986). Multivariate two-sample tests based on nearest neighbors. \emph{J. Amer. Statist. Assoc.}, 81 799-806.
Henze, N. (1988). A multivariate two-sample test based on the number of nearest neighbor type coincidences.\emph{Ann. Statist.}, 16 772-783.
Chen, L. and Dou W. (2009). Robust multivariate two-sample tests based on k nearest neighbors for unbalanced designs. \emph{manuscripts}.  
@export
@useDynLib Pmetrics knn
\end{References}
\inputencoding{utf8}
\HeaderA{NM2PM}{Convert NONMEM to Pmetrics Data Files}{NM2PM}
%
\begin{Description}\relax
\code{NM2PM} will convert NONMEM .csv data files to Pmetrics csv data files.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
NM2PM(data, ctl)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] The name and extension of a NONMEM data (e.g. .csv) file in the working directory, or the full path to a file.

\item[\code{ctl}] The name and extension of a NONMEM control (e.g. .ctl) file in the working directory, or the full path to a file.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The format of NONMEM and Pmetrics data .csv files are similar, but not quite identical.
A major difference is that the order of the columns are fixed in Pmetrics (not including covariates),
while they are user-determined in NONMEM, and specified in a control (.ctl) file.

A list of other differences follows by data item.
\begin{itemize}

\item{} ID This item is the same in both formats and is required.
\item{} EVID This is the same in both formats but is not required in NONMEM.  Doses have an EVID
of 1 and observations 0.  EVID=4 (dose/time reset) is the same in Pmetrics and NONMEM. 
EVID=2 (other event) and EVID=3 (dose reset) are not directly supported in Pmetrics, but if included
in a NONMEM file, will be converted into covariate values.  Specifically the value in the CMT variable will
be the covariate value for EVID=2, while for EVID=3, the covariate will be 1 at the time of the EVID=3 entry
and 0 othewise.  This allows for handling of these events in the Pmetrics model file using conditional statements.
\item{} DATE Pmetrics does not use dates, but will convert all NONMEM dates and times into relative times.
\item{} TIME Pmetrics uses relative times (as does NONMEM), but the NONMEM pre-processor will convert clock times
to relative times, as does \code{NM2PM}.
\item{} RATE NONMEM RATE items are converted by this function to Pmetrics DURation values.
\item{} AMT becomes DOSE in Pmetrics
\item{} ADDL is supported in both formats.  However, if NONMEM files contain an SS flag, it will be
incorporated as ADDL=-1 according to Pmetrics style.
\item{} II is the same in both formats.
\item{} INPUT in Pmetrics is similar to CMT in NONMEM for doses.  
\item{} DV in NONMEM becomes OUT in Pmetrics.  Ensure that the units of OUT are consistent with the
units of DOSE.
\item{} OUTEQ In Pmetrics, this is roughly equivalent to CMT in NONMEM for observation events.  
The lowest CMT value for any observation becomes OUTEQ=1; the next lowest becomes OUTEQ=2, etc.
\item{} SS Steady state dosing is incorporated into Pmetrics as ADDL=-1.
\item{} MDV Missing DV in NONMEM become OUT=-99 in Pmetrics.
\item{} Covariates These are copied from NONMEM to Pmetrics.  Note that Pmetrics does not allow
missing covariates at time 0 for each subject.
\item{} DROP Items marked as DROP in the NONMEM control file will not be included in the Pmetric data file.

\end{itemize}

It is strongly suggested to run \code{\LinkA{PMcheck}{PMcheck}} on the returned object for final adjusting.
\end{Details}
%
\begin{Value}
A Pmetrics style PMmatrix data.frame.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMcheck}{PMcheck}}, \code{\LinkA{PMwriteMatrix}{PMwriteMatrix}}, \code{\LinkA{PMwrk2csv}{PMwrk2csv}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{npde}{Compute normalised prediction distribution errors}{npde}
\aliasA{autonpde}{npde}{autonpde}
\keyword{models}{npde}
%
\begin{Description}\relax
These functions compute normalised prediction distribution errors (npde) and
optionally prediction discrepancies (pd). \code{npde} asks the user the name
and structure of the files containing the data, using \code{pdemenu}, while
\code{autonpde} takes these variables and others as arguments.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
autonpde(namobs, namsim, iid, ix, iy, imdv = 0, icens = 0,
icov = 0, iipred = 0, boolsave = TRUE, namsav = "output", type.graph = "eps",
verbose = FALSE, calc.npde=TRUE, calc.pd=TRUE, decorr.method = "cholesky",
 cens.method = "cdf", units = list(x="",y=""), detect=FALSE, ties=TRUE)

npde()
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{namobs}] name of the file containing the observed data, or a dataframe
containing the observed data (in both cases, the column containing the
various data required for the computation of the pde can be set using the
arguments \code{iid},\code{ix} and \code{iy} below)

\item[\code{namsim}] name of the file containing the simulated data, or a dataframe
containing the simulated data (the program will assume that subject ID are
in column 1 and simulated Y in column 3, see User Guide)

\item[\code{iid}] name/number of the column in the observed data containing the patient
ID; if missing, the program will attempt to detect a column named id

\item[\code{ix}] name/number of the column in the observed data containing the
independent variable (X); ; if missing, the program will attempt to detect a column named X

\item[\code{iy}] name/number of the column in the observed data containing the dependent
variable (Y); if missing, the program will attempt to detect a column with the response

\item[\code{imdv}] name/number of the column containing information about missing data
(MDV), defaults to 0 (column not present)

\item[\code{icens}] name/number of the column containing information about censored data
(cens), defaults to 0 (column not present)

\item[\code{icov}] name/number of the column(s) containing covariate information
defaults to 0 (no covariates)

\item[\code{iipred}] name/number of the column(s) with individual predictions
(ipred), defaults to 0 (individual predictions not available)

\item[\code{units}] a list with components x, y and cov (optional), specifying the
units respectively for the predictor (x), the response (y), and the covariates 
(a vector of length equal to the number of covariates). Units will default to (-) if not given.

\item[\code{detect}] a boolean controlling whether automatic recognition of columns in
the dataset is on, defaults to FALSE

\item[\code{boolsave}] a boolean (TRUE if graphs and results are to be saved to a
file, FALSE otherwise), defaults to TRUE

\item[\code{namsav}] name of the files to which results are to be saved (defaults
to "output", which will produce a file called output.eps (if the default
format of postscript is kept, see type.graph) for the graphs and a file
called output.npde for the numerical results (see value)

\item[\code{type.graph}] type of graph (one of "eps","jpeg","png","pdf"), defaults
to postscript ("eps")

\item[\code{calc.npde}] a boolean (TRUE if npde are to be computed, FALSE otherwise),
defaults to TRUE

\item[\code{calc.pd}] a boolean (TRUE if pd are to be computed, FALSE otherwise), defaults
to TRUE

\item[\code{cens.method}] a character string indicating the method used to handle 
censored data (see \code{\LinkA{npde.cens.method}{npde.cens.method}})
defaults to cdf

\item[\code{decorr.method}] a character string indicating the method used to decorrelate
observed and simulated data in the computation of npde (see \code{\LinkA{npde.decorr.method}{npde.decorr.method}})
defaults to cholesky

\item[\code{ties}] a boolean (if FALSE, the distributions of pd and npde are smoothed by jittering the values so that there are no ties), defaults to TRUE

\item[\code{verbose}] a boolean (TRUE if messages are to be printed as each subject is
processed, FALSE otherwise), defaults to FALSE
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Both functions compute the normalised prediction distribution errors (and/or
prediction discrepancies) in the same way. \code{npde} is an interactive
function whereas \code{autonpde} takes all required input as arguments.

When the computation of npde fails because of numerical problems, error
messages are printed out, then pd are computed instead and graphs of pd are
plotted so that the user may evaluate why the computation failed.

The function also prints out the characteristics of the distribution of the
npde (mean, variance, skewness and kurtosis) as well as the results of the
statistical tests applied to npde. In addition, if boolsave is TRUE, two files
are created: 
\begin{description}

\item[results file] the numerical results are saved in a file
with extension .npde (the name of which is given by the user). The file
contains the components id, xobs, ypred, npde, pd stored in columns
\item[graph file] the graphs are saved to a file with the same name as the
results file, and with extension depending on the format.

\end{description}

\end{Details}
%
\begin{Value}
An object of class \code{\LinkA{NpdeObject}{NpdeObject}}
\end{Value}
%
\begin{Author}\relax
Emmanuelle Comets <emmanuelle.comets@bichat.inserm.fr>
\end{Author}
%
\begin{References}\relax
K. Brendel, E. Comets, C. Laffont, C. Laveille, and F.
Mentre. Metrics for external model evaluation with an application to the
population pharmacokinetics of gliclazide. \emph{Pharmaceutical Research},
23:2036--49, 2006.
\end{References}
%
\begin{SeeAlso}\relax
\code{\LinkA{npde.graphs}{npde.graphs}}, \code{\LinkA{gof.test}{gof.test}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

data(theopp)
data(simtheopp)

# Calling autonpde with dataframes

x<-autonpde(theopp,simtheopp,1,3,4,boolsave=FALSE)
x

# Calling autonpde with names of files to be read from disk

write.table(theopp,"theopp.tab",quote=FALSE,row.names=FALSE)
write.table(simtheopp,"simtheopp.tab",quote=FALSE,row.names=FALSE)
x<-autonpde(namobs="theopp.tab", namsim="simtheopp.tab", iid = 1,
ix = 3, iy = 4, imdv=0, boolsave = FALSE)

head(x["results"]["res"])

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{npde.graphs,NpdeObject-method}{Save the graphs for a NpdeObject object to a file}{npde.graphs,NpdeObject.Rdash.method}
\keyword{IO}{npde.graphs,NpdeObject-method}
\keyword{files}{npde.graphs,NpdeObject-method}
%
\begin{Description}\relax
Save the graphs to a file on disk
\end{Description}
%
\begin{Usage}
\begin{verbatim}
npde.graphs(object, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] a NpdeObject object

\item[\code{...}] optional arguments to replace options in object
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The following options can be changed by passing the appropriate arguments: namsav (string giving the root name of the files, an extension depending on the type of graph will be added), namgr (string giving the full name of the file), type.graph (one of "eps", "pdf", "jpeg", "png")
\end{Details}
%
\begin{References}\relax
K. Brendel, E. Comets, C. Laffont, C. Laveille, and F.Mentre. Metrics for external model evaluation with an application to the population pharmacokinetics of gliclazide. \emph{Pharmaceutical Research}, 23:2036--49, 2006.
\end{References}
\inputencoding{utf8}
\HeaderA{npde.save,NpdeObject-method}{Save the results contained in a NpdeObject object to a file}{npde.save,NpdeObject.Rdash.method}
\keyword{IO}{npde.save,NpdeObject-method}
\keyword{files}{npde.save,NpdeObject-method}
%
\begin{Description}\relax
Save the results to a table on disk
\end{Description}
%
\begin{Usage}
\begin{verbatim}
npde.save(object, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] a NpdeObject object

\item[\code{...}] optional arguments to replace options in object
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The following options can be changed by passing the appropriate arguments: namsav (string giving the root name of the files, an extension .npde will be added), nameres (string giving the full name of the file)
\end{Details}
%
\begin{References}\relax
K. Brendel, E. Comets, C. Laffont, C. Laveille, and F.Mentre. Metrics for external model evaluation with an application to the population pharmacokinetics of gliclazide. \emph{Pharmaceutical Research}, 23:2036--49, 2006.
\end{References}
\inputencoding{utf8}
\HeaderA{npdeControl}{Set options for an NpdeObject}{npdeControl}
\aliasA{check.control.options}{npdeControl}{check.control.options}
\aliasA{replace.control.options}{npdeControl}{replace.control.options}
\keyword{methods}{npdeControl}
%
\begin{Description}\relax
Set, replace and check options for an NpdeObject
\end{Description}
%
\begin{Usage}
\begin{verbatim}
npdeControl(boolsave = TRUE, namsav = "output", type.graph = "eps", verbose = FALSE, calc.npde = TRUE, calc.pd = TRUE, decorr.method = "cholesky", cens.method = "omit", ties = TRUE, sample = FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{boolsave}] whether to save the results (a file containing the numerical results and a file with the graphs)

\item[\code{namsav}] the root name of the files to save to (the file with the results will be named ROOTNAME.npde and the graphs will be saved to ROOTNAME.format where format is given by the type.graph argument)

\item[\code{type.graph}] type of graph to save to (one of "eps", "pdf", "jpeg", "png")

\item[\code{verbose}] a boolean; if TRUE, a message is printed as the computation of the npde begins for each new subject

\item[\code{calc.npde}] a boolean; TRUE to compute npde

\item[\code{calc.pd}] a boolean; TRUE to compute pd

\item[\code{decorr.method}] the method used to decorrelate simulated and observed data (see \code{\LinkA{npde.decorr.method}{npde.decorr.method}})

\item[\code{cens.method}] the method used to handle censored data (see \code{\LinkA{npde.cens.method}{npde.cens.method}})

\item[\code{ties}] if FALSE, a smoothing will be applied to prediction discrepancies to avoid ties

\item[\code{sample}] if TRUE, the test on the pd will be performed after randomly sampling only pd per subject
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{npdeData}{Creates a NpdeData object}{npdeData}
\keyword{models}{npdeData}
%
\begin{Description}\relax
This function is used to create a NpdeData object, representing a longitudinal data structure, and fill it with data from a dataframe or a file on disk
\end{Description}
%
\begin{Usage}
\begin{verbatim}
npdeData(name.data,header=TRUE,sep="",na.strings=c(".","NA"),name.group, name.predictor,name.response, name.covariates,name.cens,name.miss,name.ipred, units=list(x="",y="",covariates=c()),detect=TRUE,verbose=FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{name.data}] name of the file containing the observed data, or a dataframe
containing the observed data

\item[\code{header}] boolean indicating whether the file has a header (mandatory if 
detect is TRUE)

\item[\code{sep}] field separator (for files on disk)

\item[\code{na.strings}] strings to be considered as indicating NA

\item[\code{name.group}] name/number of the column in the observed data containing the 
patient ID (if missing and detect is TRUE, columns named id, subject or sujet 
(regardless of case) will be assumed to contain this information)

\item[\code{name.predictor}] name/number of the column in the observed data containing 
the independent variable X (if missing and detect is TRUE, columns named xobs, 
time, dose, x, temps, tim (regardless of case) will be assumed to 
contain this information)

\item[\code{name.response}] name/number of the column in the observed data containing 
the dependent variable Y (if missing and detect is TRUE, columns named yobs, 
response, resp, conc, concentration (regardless of case) will be assumed to 
contain this information)

\item[\code{name.covariates}] name/number of the column(s) containing covariate 
information (optional)

\item[\code{name.cens}] name/number of the column containing information about censored 
data (cens) (if missing and detect is TRUE, column with a name containing cens 
(regardless of case) will be assumed to contain this information)

\item[\code{name.miss}] name/number of the column containing information about missing 
data (MDV) (if missing and detect is TRUE, column called mdv or miss 
(regardless of case) will be assumed to contain this information)

\item[\code{name.ipred}] name/number of the column(s) with individual predictions
(ipred)  (if missing and detect is TRUE, column with a name containing ipred 
(regardless of case) will be assumed to contain this information)

\item[\code{units}] a list with components x, y and cov (optional), specifying the
units respectively for the predictor (x), the response (y), and the covariates 
(a vector of length equal to the number of covariates). Units will default to (-) if not given.

\item[\code{detect}] a boolean controlling whether automatic recognition of columns in the dataset is on, defaults to TRUE

\item[\code{verbose}] whether to print warning messages, defaults to FALSE (set to TRUE to check how data is being handled)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
an object of class NpdeData
\end{Value}
%
\begin{Author}\relax
Emmanuelle Comets <emmanuelle.comets@bichat.inserm.fr>
\end{Author}
%
\begin{References}\relax
K. Brendel, E. Comets, C. Laffont, C. Laveille, and F.
Mentre. Metrics for external model evaluation with an application to the
population pharmacokinetics of gliclazide. \emph{Pharmaceutical Research},
23:2036--49, 2006.
\end{References}
%
\begin{SeeAlso}\relax
\code{\LinkA{npde}{npde}}, \code{\LinkA{autonpde}{autonpde}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

data(theopp)

x<-npdeData(theopp) # Automatic detection
print(x)
x<-npdeData(theopp,name.group="ID",name.predictor="Time",name.response="Conc", 
name.covariates=c("Wt"),units=list(x="hr",y="mg/L",covariates="kg")) # Explicit
print(x)
plot(x)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{NpdeData-class}{Class "NpdeData" representing the structure of the longitudinal data}{NpdeData.Rdash.class}
\aliasA{NpdeData}{NpdeData-class}{NpdeData}
\aliasA{print,NpdeData-method}{NpdeData-class}{print,NpdeData.Rdash.method}
\aliasA{show,NpdeData-method}{NpdeData-class}{show,NpdeData.Rdash.method}
\aliasA{summary,NpdeData-method}{NpdeData-class}{summary,NpdeData.Rdash.method}
\aliasA{[,NpdeData-method}{NpdeData-class}{[,NpdeData.Rdash.method}
\aliasA{[<\Rdash{},NpdeData-method}{NpdeData-class}{[<.Rdash.,NpdeData.Rdash.method}
\keyword{classes}{NpdeData-class}
%
\begin{Description}\relax
A longitudinal data structure
\end{Description}
%
\begin{Section}{Objects from the Class}
NpdeData objects are typically created by calls to \code{\LinkA{npdeData}{npdeData}} and contain the following slots:

\begin{description}

\item[name.data] character string giving the name of the dataset
\item[name.group] character string giving the name of the grouping term (ID)
\item[name.predictor] character string giving the name of the predictor (X)
\item[name.response] character string giving the name of the response (Y)
\item[name.cens] character string giving the name of the censoring indicator
\item[name.mdv] character string giving the name of the missing data indicator
\item[name.covariates] vector of character string giving the name(s) of the covariates
\item[name.ipred] character string giving the name of the individual predictions
\item[units] (optional) a list with the units for X, Y, and covariates
\item[data] a dataframe containing the data
\item[N] number of subjects
\item[ntot.obs] total number of non-missing observations
\item[nind.obs] vector of size N giving the number of non-missing observations for each subject
\item[ind] index of non-missing observations
\item[icens] index of censored observations (non-missing)
\item[not.miss] a vector of boolean indicating for each observation whether it is missing (FALSE) or available (TRUE)
\item[loq] the censoring value

\end{description}

\end{Section}
%
\begin{Section}{Methods}

\begin{description}

\item[npdeData(name.data):] Create a new \code{\LinkA{NpdeData}{NpdeData.Rdash.class}} object from dataset name.data
\item[print(npde.data):] Prints a summary of object npde.data
\item[show(npde.data):] Prints a short summary of object npde.data
\item[showall(npde.data):] Prints a detailed summary of object npde.data
\item[plot(npde.data):] Plots the data in npde.data. More details can be found in \code{\LinkA{plot.NpdeData}{plot.NpdeData}}
\item[summary(npde.data):] Returns a summary of object npde.data in list format
\item[set.plotoptions(npde.data):] Sets options for graphs of npde.data (internal method used in plots)

\end{description}

\end{Section}
%
\begin{SeeAlso}\relax
\code{\LinkA{npde}{npde}}, \code{\LinkA{autonpde}{autonpde}}, \code{\LinkA{plot.NpdeData}{plot.NpdeData}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

methods(class="NpdeData")

showClass("NpdeData")

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{NpdeObject-class}{Class "NpdeObject"}{NpdeObject.Rdash.class}
\aliasA{npde.graphs,NpdeObject}{NpdeObject-class}{npde.graphs,NpdeObject}
\aliasA{npde.main,NpdeObject}{NpdeObject-class}{npde.main,NpdeObject}
\aliasA{npde.save,NpdeObject}{NpdeObject-class}{npde.save,NpdeObject}
\aliasA{NpdeObject}{NpdeObject-class}{NpdeObject}
\aliasA{NpdeObject-class,}{NpdeObject-class}{NpdeObject.Rdash.class,}
\aliasA{plot,NpdeObject}{NpdeObject-class}{plot,NpdeObject}
\aliasA{print,NpdeObject-method}{NpdeObject-class}{print,NpdeObject.Rdash.method}
\aliasA{show,NpdeObject-method}{NpdeObject-class}{show,NpdeObject.Rdash.method}
\aliasA{showall,NpdeObject-method}{NpdeObject-class}{showall,NpdeObject.Rdash.method}
\aliasA{summary,NpdeObject-method}{NpdeObject-class}{summary,NpdeObject.Rdash.method}
\aliasA{test,NpdeObject-method}{NpdeObject-class}{test,NpdeObject.Rdash.method}
\aliasA{[,NpdeObject-method}{NpdeObject-class}{[,NpdeObject.Rdash.method}
\aliasA{[<\Rdash{},NpdeObject-method}{NpdeObject-class}{[<.Rdash.,NpdeObject.Rdash.method}
\keyword{classes}{NpdeObject-class}
%
\begin{Description}\relax
An object of class NpdeObject
\end{Description}
%
\begin{Section}{Objects from the Class}
NpdeObject objects are typically created by calls to \code{\LinkA{npde}{npde}} or \code{\LinkA{autonpde}{autonpde}}. They contain the following slots:

\begin{description}

\item[data] an object of class NpdeData, containing the observed data
\item[sim.data] an object of class NpdeSimData, containing the simulated data
\item[res] an object of class NpdeRes, containing the results
\item[options] a list of options
\item[prefs] a list of graphical preferences for the plots

\end{description}

\end{Section}
%
\begin{Section}{Methods}

\begin{description}

\item[print(x):] Prints a summary of object
\item[show(x):] Prints a short summary of object
\item[showall(x):] Prints a detailed summary of object
\item[plot(x):] Diagnostic and other plots. More details can be found in \code{\LinkA{plot.NpdeObject}{plot.NpdeObject}}
\item[summary(x):] Returns a summary of object x in list format
\item[gof.test(x, which="npde", parametric=TRUE, ...):] Returns goodness-of-fit tests
\item[set.plotoptions(x):] Sets options for graphs (internal method used in plots)

\end{description}

\end{Section}
%
\begin{SeeAlso}\relax
\code{\LinkA{npde}{npde}}, \code{\LinkA{autonpde}{autonpde}}, \code{\LinkA{NpdeData}{NpdeData}}, \code{\LinkA{NpdeSimData}{NpdeSimData}}, \code{\LinkA{NpdeRes}{NpdeRes}}, \code{\LinkA{gof.test}{gof.test}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

methods(class="NpdeObject")

showClass("NpdeObject")

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{NpdeSimData-class}{Class "NpdeSimData" representing the structure of the longitudinal data}{NpdeSimData.Rdash.class}
\aliasA{NpdeSimData}{NpdeSimData-class}{NpdeSimData}
\aliasA{show,NpdeSimData-method}{NpdeSimData-class}{show,NpdeSimData.Rdash.method}
\aliasA{[,NpdeSimData-method}{NpdeSimData-class}{[,NpdeSimData.Rdash.method}
\aliasA{[<\Rdash{},NpdeSimData-method}{NpdeSimData-class}{[<.Rdash.,NpdeSimData.Rdash.method}
\keyword{classes}{NpdeSimData-class}
%
\begin{Description}\relax
A longitudinal data structure, with simulated data
\end{Description}
%
\begin{Section}{Objects from the Class}
NpdeSimData objects are created by associating an NpdeData object with matching simulated data, and they contain the following slots.

\begin{description}

\item[name.simdata] character string giving the name of the dataset
\item[nrep] number of replications)
\item[datsim] a dataframe containing the simulated data,  with columns: idsim (subject id), irsim (replication index), xsim (simulated x), ysim (simulated response). After a call to \code{\LinkA{npde}{npde}} or \code{\LinkA{autonpde}{autonpde}}, an additional column ydsim (decorrelated replicated data) will be added.

\end{description}

\end{Section}
%
\begin{Section}{Methods}

\begin{description}

\item[print(npde.simdata):] Prints a summary of object npde.simdata
\item[show(npde.simdata):] Prints a short summary of object npde.simdata
\item[showall(npde.simdata):] Prints a detailed summary of object npde.simdata

\end{description}

\end{Section}
%
\begin{SeeAlso}\relax
\code{\LinkA{npde}{npde}}, \code{\LinkA{autonpde}{autonpde}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

showClass("NpdeSimData")

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{NPparse}{Parse Pmetrics NPAG Output}{NPparse}
%
\begin{Description}\relax
\code{NPparse} processes the output from an NPAG run into a list.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
NPparse(outfile = "NP_RF0001.TXT")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{outfile}] This is the filename of the output from NPAG. Typically,
the file will be called NP\_RF0001.txt, and this is the default.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function can take some time to process the RFILE, depending on the number of subjects,
doses, observations, etc.  Typical wait times are a few seconds up to 5 minutes.
When processing is complete a summary of the extracted data will be reported on the console.
\end{Details}
%
\begin{Value}
The output of \code{NPparse} is a list with the following objects and
of the class \emph{NPAG}.
\begin{ldescription}
\item[\code{nsub }] Number of subjects
\item[\code{nactve }] Number of active grid points at the final cycle
\item[\code{nvar }] Number of random variables or parameters in the model
\item[\code{nofix }] Number of fixed variables or parameters in the model
\item[\code{par }] Names of random parameters
\item[\code{parfix }] Names of fixed parameters
\item[\code{covnames }] Names of covariates
\item[\code{ab }] Initial boundaries for each random parameter
\item[\code{valfix }] Values for fixed parameters
\item[\code{ndim }] Number of differential equations in model, or 0 for only output equation, or -1 for analytic
solution (algabraic)
\item[\code{indpts }] Index for the initial number of gridpoints in the model
\item[\code{icycst }] Starting cycle number
\item[\code{icycmax }] Maximum number of cycles specified by the user
\item[\code{icyctot }] Number of cycles run.  If less than \code{icycmax}, convergence occurred.
\item[\code{converge }] Boolean value if convergence occurred.
\item[\code{ODEtol }] Ordindary Differential Equation solver tolerance.
\item[\code{prior }] Prior density for the run, either ``UNIFORM'' or the name of the user-specified density file, typically ``DEN0001''.
\item[\code{ERRmod }] Assay error model: 1 for SD; 2 for SD*gamma; 3 for additive lambda model; and 4 for gamma only
\item[\code{numeqt }] Number of output equations
\item[\code{ndrug }] Number of drug inputs
\item[\code{salt }] Vector of values of the salt fraction for each \code{ndrug}
\item[\code{ndose }] Vector of the number of doses for each subject in the population
\item[\code{ncov }] Number of covariates in the model
\item[\code{nobs }] Vector of the number of observations for each subject in the population
\item[\code{nobsmax }] Maximum number of observation in any individual subject
\item[\code{numt }] Vector of the number of time points for each subject at which a prediction is generated for each \emph{numeqt} output equation
\item[\code{corden }] Final cycle joint population density of parameter estimates
\item[\code{postden }] Array of posterior parameter value distributions for the first 100  subjects at each observation time point.
\emph{postden[nsub,nactvepost,density]} where \emph{nactvepost} is the posterior grid point
\item[\code{pyjgx }] Matrix of posterior probability of each \emph{nactve} point for each subject, given that subject's data
\item[\code{ypredpop }] Array of population model predictions for each subject at each observation time point.
\emph{ypredpop[nsub,numeqt,time,type]} where \emph{type} is 1=mean, 2=median, 3=mode of the population prior used to calculate ypredpop
\item[\code{ypredbay }] Array of Bayesian posterior model predictions for each subject at each observation time point.
\emph{ypredbay[nsub,numeqt,time,type]} where \emph{type} is 1=mean, 2=median, 3=mode of the population prior used to calculate ypredbay
\item[\code{ttpred }] Matrix of the prediction time points for each subject, with \emph{nsub} rows and max(\emph{numt}) columns
\item[\code{exx }] Array of the mean, median, and mode of the posterior marginal distribution for each parameter in each subject, of the form \emph{exx[nvar,type,nsub]}
\item[\code{ypredpopt }] Array of population model predictions for each subject at each
\emph{ttpred} time point,  of the form \emph{ypredpopt[nsub,  numeqt,  time,  type]},
where type is 1=mean,  2=median,  3=mode of the population prior used to calculate
\emph{ypredpopt}
\item[\code{ilog }] Matrix of cycle number and associated log-likelihood
\item[\code{iic }] Matrix with cycle number and Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) for each cycle
\item[\code{imean }] Matrix of cycle numbers and associated means for each random parameter
\item[\code{isd }] Matrix of cycle numbers and associated standard deviations for each random parameter
\item[\code{iaddl }] Array of additional information for each random parameter in each cycle,
of the form \emph{iaddl[info, nvar, cycle]},  where info is a value from 1 to 12:
1= mode; 2= skewness; 3= kurtosis; 4-8 give percentiles of the distribution (4=2.5\%; 5=25\%;
6=50\% [median],  7=75\%; 8=97.5\%); 9= the standard deviation of a normal distribution
with the same interquartile range; 10=the standard deviation of a normal distribution
with the same 95\% range; 11=the average of 9 and 10; 12=the \% scaled information
\item[\code{igamlam }] Matrix of cycle number and associated gamma or lambda
\item[\code{blog }] Vector of each subject's Bayesian posterior log-likelihood
\item[\code{bmean }] Matrix of subject numbers and associated Bayesian posterior means for each random parameter
\item[\code{bsd }] Matrix of subject numbers and associated Bayesian posterior standard deviations for each random parameter
\item[\code{baddl }] Array of Bayesian posterior additional information for each random parameter
for each subject, of the form \emph{baddl[info, nvar, nsub]},  where info is the same as for \emph{iaddl}.
\item[\code{bauc }] Matrix of AUC blocks for each subject with 5 columns:
[nsub,  numeqt,  nblock,  tau,  auc]; \emph{nsub} and \emph{numeqt} are as previously defined;
\emph{nblock} is the AUC block as defined by successive dose reset (evid=4) events;
\emph{tau} is the time interval for that block; \emph{auc} is the AUC for that block
\item[\code{sdata }] Subject data consisting of 5 columns: [id,  nsub,  age,  sex,  ht],
\emph{id} is the original identification number in the .csv matrix file;
\emph{nsub} is the sequential subject number in the NPAG run; \emph{age},
\emph{sex} and \emph{ht} will be missing for .csv input and present if included in .wrk input files
\item[\code{dosecov }] Matrix with all dosing information for each subject,  including times,  routes,  amounts,  and associated covariate values
\item[\code{outputs }] Matrix with measured outputs for each subject and associated assay error polynomials.
The order of the columns is nsub, time, numeqt, observation, c0, c1, c2, c3, where the last
four columns are the coefficients of the assay error polynomial for that observation, such that
SD[obs] = c0 + c1*[obs] + c2*[obs]**2 + c3*[obs]**3
\item[\code{negflag }] A flag indicating that some negative predictions were changed to missing.
This means that the model may be misspecified.
\item[\code{mdata }] The filename of the data used in the run.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{NPrun}{Execute an NPAG run.}{NPrun}
%
\begin{Description}\relax
Runs NPAG
\end{Description}
%
\begin{Usage}
\begin{verbatim}
NPrun(
  model = "model.txt",
  data = "data.csv",
  run,
  include,
  exclude,
  ode = -4,
  tol = 0.01,
  salt,
  cycles = 100,
  indpts,
  icen = "median",
  aucint,
  idelta = 12,
  prior,
  auto = T,
  intern = F,
  silent = F,
  overwrite = F,
  nocheck = F,
  parallel = NA,
  batch = F,
  alq = F,
  remote = F,
  server_address
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model}] Name of a suitable model file template in the working directory or
an existing (previous) run number corresponding to a folder in the current working directory that used the same model file as will be used in the current run.
If this is supplied, then the model file will be copied into the current 
working directory for convenience.  If not supplied, 
the default is ``model.txt''.  This file will be converted to a fortran model file.
If it is detected to already be a fortran file, then the analysis will proceed without any further
file conversion.

\item[\code{data}] Name of a suitable data file (see \code{\LinkA{PMwriteMatrix}{PMwriteMatrix}}) or
an existing (previous) run number corresponding to a folder in the current working directory that used the same data file as will be used in the current run.
If this is supplied, then previously made  '.ZMQ' files will be copied into the current 
working directory, bypassing the need to re-convert the .csv file and speeding up the run..

\item[\code{run}] Specify the run number of the output folder.  Default if missing is the next available number.

\item[\code{include}] Vector of subject id values in the data file to include in the analysis.  The default (missing) is all.

\item[\code{exclude}] A vector of subject IDs to exclude in the analysis, e.g. c(4,6:14,16:20)

\item[\code{ode}] Ordinary Differential Equation solver log tolerance or stiffness.  Default is -4, i.e. 0.0001.  Higher values will result in faster
runs, but parameter estimates may not be as accurate.

\item[\code{tol}] Tolerance for convergence of NPAG.  Smaller numbers make it harder to converge.
Default value is 0.01.

\item[\code{salt}] Vector of salt fractions for each drug in the data file, default is 1 for each drug.  This is not the same as bioavailability.

\item[\code{cycles}] Number of cycles to run. Default is 100.

\item[\code{indpts}] Index of starting grid point number.  Default is missing, which allows NPAG to choose depending on the number of random parameters: 
1 or 2 = index of 1; 3 = 3; 4 = 4, 5 = 6,
6 or more is 10+number of multiples for each parameter greater than 5, e.g. 6 = 101; 7 = 102, up to 108 for 13 or more parameters.

\item[\code{icen}] Summary of parameter distributions to be used to calculate predictions in HTML report.  Default is "median", but could be "mean".
Predictions based on both summaries will be available in objects loaded by \code{\LinkA{PMload}{PMload}}.

\item[\code{aucint}] Maintained for backwards compatibility and not used currently. Interval for AUC calculations.  Default is 24 hours if the number of intervals is not greater than 48; otherwise it defaults
to the interval which allows for <= 48 intervals.

\item[\code{idelta}] Interval in 1/60 time unit, typically minutes, for predictions at times other than observations.  Default is 12.

\item[\code{prior}] Name of a suitable NPAG output object from a prior run loaded with \code{\LinkA{PMload}{PMload}},
i.e. the \emph{NPdata} object.  A \code{prior} may be specified if the user wishes to
start from a non-uniform prior distribution for the NPAG run. The default value is -99,
which translates in NPAG to a uniform prior distribution.  An alternative is to include a DEN0001 file from the prior
NPAG run in the working directory of the new run, and specify this as the value for \code{prior}, e.g.
\code{prior = 'DEN0001'}.

\item[\code{auto}] If \code{auto} is \code{False} you can answer all questions about the run environment manually.  This might
be helpful for beginners.  Default is \code{True}.

\item[\code{intern}] MacOSX only: Run NPAG in the R console without a batch script.  Default is false.
This will be ignored if on Windows systems.  On the latter, the behavior of cmd.exe (aka the ``DOS'' window)
with R is poor - it does not update until the end of execution, so you cannot see any output that indicates that NPAG is running.  
If \code{intern=T} the HTML summary page will not be automatically loaded at the end of the run, but all post-run processing will occur normally,
and you can find the HTML summary page in the /outputs folder: NPAGreport.html.

\item[\code{silent}] Boolean operator controlling whether a model summary report is given.  Default is \code{TRUE}.

\item[\code{overwrite}] Overwrite existing run result folders.  Default is \code{FALSE}.

\item[\code{nocheck}] Suppress the automatic checking of the data file with \code{\LinkA{PMcheck}{PMcheck}}.  Default is \code{FALSE}.

\item[\code{parallel}] Run NPAG in parallel.  Default is \code{NA}, which will be set to \code{TRUE} for models that use
differential equations, and \code{FALSE} for algebraic/explicit models.  The majority of the benefit for parallelization comes
in the first cycle, with a speed-up of approximately 80\% of the number of available cores on your machine, e.g. an 8-core machine
will speed up the first cycle by 0.8 * 8 = 6.4-fold.  Subsequent cycles approach about 50\%, e.g. 4-fold increase on an 8-core
machine.  Overall speed up for a run will therefore depend on the number of cycles run and the number of cores.

\item[\code{batch}] Set to true when \code{\LinkA{PMbatch}{PMbatch}} is used.

\item[\code{alq}] For internal developer use only.  Should be set to \code{FALSE}.

\item[\code{remote}] Default is \code{FALSE}.  Set to \code{TRUE} if loading results of an NPAG run on remote server.

\item[\code{server\_address}] If missing, will use the default server address returned by getPMoptions(). 
Pmetrics will prompt the user to set this address the first time the \code{remote} argument is set to \code{TRUE}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{NPrun} will execute an NPAG run.

If all function arguments are default, the simplest execution of this command is 
\code{NPrun()}.  This will result in generation of a batch file.  On Unix (Mac) systems
will be launched automatically in a terminal window.  On Windows systems, the user
must execute the batch file from the current working directory, which will launch NPAG
in a command prompt (DOS-like) window.  In either case, NPAG will run independently of R
so that R can be used for other purposes if desired.
\end{Details}
%
\begin{Value}
A successful NPAG run will result in creation of a new folder in the working
directory.  This folder will be named numerically and sequentially with respect to previous runs.  
Within this folder will be four subfolders: etc, inputs, outputs, and wrkcopy, described below.
\begin{itemize}

\item{} \bold{etc}   Control files for NPAG generally not needed by the user after a completed run.
\item{} \bold{inputs}   This folder will contain the .csv data file and the model file.
\item{} \bold{outputs}   This folder will contain the output from the NPAG run.  These files will be
prefixed by DEN, ILOG, OUT, OUTT, PRTB and RFILE, with appended numbers, usually 0001.
DEN is the density file which can be used to specifiy a non-uniform prior parameter value
distribution for a subsequent NPAG run of the same model via the \code{prior} argument
above.  ILOG is a summary of cycle objective function values, gamma/lambda, and gridpoints.
OUT and OUTT are full and truncated textfiles containing all output of NPAG.  OUTT is missing
density file.  PRTB contains Bayesian posterior individual predictions for each subject and
output at timepoints specified in the NPAG instructions (e.g. every 2, 4, 8, 12 minutes) as well
as predictions at each observation time.  RFILE contains NPAG output formatted for easy import
into R, and is the file read by the \code{\LinkA{NPparse}{NPparse}} command.  Finally, there will also
be an nplog.txt file containing additional run information.
\item{} \bold{wrkcopy}    The working copy format which is used by NPAG.  Invisibly to the user,
the .csv input file is converted to these text files, one file per subject.  

\end{itemize}

\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{NPparse}{NPparse}}, \code{\LinkA{ITrun}{ITrun}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{plot.MMopt}{Plot Pmetrics Multiple-Model Optimal Sampling Objects}{plot.MMopt}
%
\begin{Description}\relax
Plots \emph{MMopt} objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'MMopt'
plot(x, mm.col = "red", mm.lty = 2, mm.lwd = 2, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{MMopt} data object generated by \code{\LinkA{MMopt}{MMopt}}

\item[\code{mm.col}] Color of the optimal sample time reference lines.  Default is red.

\item[\code{mm.lty}] Type of the optimal sample time reference lines.  Default is dashed.

\item[\code{mm.lwd}] Width of the optimal sample time reference lines.  Default is 2.

\item[\code{...}] Other parameters to pass to \code{\LinkA{plot.PMsim}{plot.PMsim}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Simulated observations are plotted on the y-axis vs. time on the x.axis.  
Optimal sampling times are indicated as vertical lines.
\end{Details}
%
\begin{Value}
Plots the simulation profiles with MMoptimal times indicated as vertical lines.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{plot.PMsim}{plot.PMsim}}, \code{\LinkA{plot}{plot}}, \code{\LinkA{par}{par}}, \code{\LinkA{axis}{axis}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{plot.NpdeData}{Plots a NpdeData object}{plot.NpdeData}
\keyword{plot}{plot.NpdeData}
%
\begin{Description}\relax
Plots the data in a NpdeData object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'NpdeData'
plot(x, y, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] a NpdeData object

\item[\code{y}] unused, here for compatibility with the base plot function

\item[\code{...}] additional graphical parameters to be passed on to the plot
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The default plot is a spaghetti plot of all the data, with a line joining the observations for each subject. If censored data is present, it is shown with a different symbol and colour.
\end{Details}
%
\begin{References}\relax
K. Brendel, E. Comets, C. Laffont, C. Laveille, and F.Mentre. Metrics for external model evaluation with an application to the population pharmacokinetics of gliclazide. \emph{Pharmaceutical Research}, 23:2036--49, 2006.
\end{References}
%
\begin{SeeAlso}\relax
\code{\LinkA{set.plotoptions}{set.plotoptions}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

data(theopp)

x<-npdeData(theopp,name.group="ID",name.predictor="Time",name.response="Conc", 
name.covariates=c("Wt"),units=list(x="hr",y="mg/L",covariates="kg"))
plot(x)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{plot.NpdeObject}{Plots a NpdeObject object}{plot.NpdeObject}
\keyword{plot}{plot.NpdeObject}
%
\begin{Description}\relax
Plots the data and diagnostic plots in a NpdeObject object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'NpdeObject'
plot(x, y, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] a NpdeObject object

\item[\code{y}] unused, here for compatibility with the base plot function

\item[\code{...}] additional graphical parameters, which when given will supersede graphical preferences stored in the object
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The default plot
\end{Details}
%
\begin{References}\relax
K. Brendel, E. Comets, C. Laffont, C. Laveille, and F.Mentre. Metrics for external model evaluation with an application to the population pharmacokinetics of gliclazide. \emph{Pharmaceutical Research}, 23:2036--49, 2006.
\end{References}
%
\begin{SeeAlso}\relax
\code{\LinkA{set.plotoptions}{set.plotoptions}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

data(theopp)
data(simtheopp)

x<-autonpde(theopp,simtheopp,iid="ID",ix="Time", iy="Conc", boolsave=FALSE)
plot(x)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{plot.PMcov}{Plot Pmetrics Covariate objects}{plot.PMcov}
%
\begin{Description}\relax
Plot PMcov objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMcov'
plot(
  x,
  formula,
  icen = "median",
  include,
  exclude,
  mult = 1,
  log = F,
  square = F,
  ref = F,
  lowess = F,
  grid = F,
  ident = F,
  reg = F,
  ci = 0.95,
  cex = 1,
  cex.lab = 1.2,
  x.stat = 0.6,
  y.stat = 0.1,
  col.stat = "black",
  cex.stat = 0.8,
  lwd = 2,
  col = "red",
  xlim,
  ylim,
  xlab,
  ylab,
  out = NA,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{PMcov} data object generated by \code{\LinkA{makeCov}{makeCov}}

\item[\code{formula}] This is a mandatory formula of the form \code{y \textasciitilde{} x}, where \code{y} and \code{x}
are the two \code{data} parameters to plot.

\item[\code{icen}] A character vector to summarize covariate and parameter values.  Default is ``median'', but can also be one of ``none'',
``mean''.  If \code{time} is a variable in \code{formula}, the value will be set to ``none'' and the \code{y} values
will be aggregated by subject ID vs. time.

\item[\code{include}] A vector of subject IDs to include in the plot, e.g. c(1:3,5,15)

\item[\code{exclude}] A vector of subject IDs to exclude in the plot, e.g. c(4,6:14,16:20)

\item[\code{mult}] Multiplication factor for y axis, e.g. to convert mg/L to ng/mL

\item[\code{log}] Boolean operator to plot in log-log space; the default is \code{False}

\item[\code{square}] Boolean operator to force a square plot with equal x and y limits; the default is \code{True}

\item[\code{ref}] Boolean operator to draw a unity line; the default is \code{True} unless ``time'' is the x value in \code{formula} in which case this is ignored

\item[\code{lowess}] Boolean operator to draw a lowess regression line; the default is \code{False} and this is ignored if ``time'' is the x value in \code{formula}

\item[\code{grid}] Either a boolean operator to plot a reference grid, or a list with elements x and y,
each of which is a vector specifying the native coordinates to plot grid lines; the default is \code{False}.
For example, grid=list(x=seq(0,24,2),y=1:10).  Defaults for missing x or y will be calculated by \code{\LinkA{axTicks}{axTicks}}.

\item[\code{ident}] Boolean operator to plot points as ID numbers; the default is \code{False}.
This option is useful to identify outliers.

\item[\code{reg}] Boolean operator to draw a linear regression line; the default is \code{True} unless ``time'' is the x value in \code{formula} in which case this is ignored.
If this option is selected, regression statistics will be printed on the plot if at least 3 subjects are included.

\item[\code{ci}] The confidence interval for the linear regression parameter estimates; the default is 0.95.

\item[\code{cex}] Size of the plot symbols.

\item[\code{cex.lab}] Size of the plot labels.

\item[\code{x.stat}] Horizontal position to plot the linear regression statistics;
the units are relative to the origin, i.e. extreme left is 0 and extreme right is 1.

\item[\code{y.stat}] Vertical position to plot the linear regression statistics; 
the units are relative to the origin, i.e. extreme bottom is 0 and extreme top is 1.

\item[\code{col.stat}] Color of the text for the regression statistics.

\item[\code{cex.stat}] Size of the text for the regression statistics.

\item[\code{lwd}] Width of the various regression or reference lines (unity, linear regression, or
lowess regression)

\item[\code{col}] This parameter will be applied to the plotting symbol and is ``red'' by default.

\item[\code{xlim}] Limits of the x-axis as a vector, e.g. \code{c(0,1)}.  It does not need to be specified, but can be.

\item[\code{ylim}] Analogous to \code{xlim}

\item[\code{xlab}] Label for the x-axis.  If missing, will default to the name of the x-variable.

\item[\code{ylab}] Label for the y-axis.  If missing, will default to the name of the y-variable.

\item[\code{out}] Direct output to a PDF, EPS or image file.  Format is a named list whose first argument, 
\code{type} is one of the following character vectors: ``pdf'', ``eps'' (maps to \code{postscript}),
``\code{png}'', ``\code{tiff}'', ``\code{jpeg}'', or ``\code{bmp}''.  Other named items in the list
are the arguments to each graphic device. PDF and EPS are vector images acceptable to most journals
in a very small file size, with scalable (i.e. infinite) resolution.  The others are raster images which may be very
large files at publication quality dots per inch (DPI), e.g. 800 or 1200. Default value is \code{NA} which means the 
output will go to the current graphic device (usually the monitor). For example, to output an eps file,
out=list(``eps'') will generate a 7x7 inch (default) graphic.

\item[\code{...}] Other parameters as found in \code{\LinkA{plot.default}{plot.default}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This method will plot any two columns, specified using a formula, of a PMcov object, which contains covariate and Bayesian posterior parameter information
for each subject.  Specifiying any two variables that do not include time will result in a scatter plot with optional regression and reference lines.  If
time is included as the x variable, the y variable will be plotted vs. time, aggregated by subject.  This can be useful to see time varying parameters,
although a formula within formula approach may be required, e.g. plot(cov.1,I(cl\_0*wt**0.75)\textasciitilde{}time) in order to see the change in cl over time according to 
the change in wt over time, even though cl\_0 is constant for a given subject.
\end{Details}
%
\begin{Value}
Plots the object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeCov}{makeCov}}, \code{\LinkA{plot}{plot}}, \code{\LinkA{par}{par}}, \code{\LinkA{axis}{axis}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
plot(cov.1,V~wt)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{plot.PMcycle}{Plot NPAG Cycle Information}{plot.PMcycle}
%
\begin{Description}\relax
\code{plot.PMcycle} plots \emph{PMcycle} objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMcycle'
plot(x, x.leg = 0, y.leg = 1, cex.leg = 1.2, omit, col, out = NA, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{PMcycle} data object generated by \code{\LinkA{makeCycle}{makeCycle}}

\item[\code{x.leg}] Porportionate location along the X-axis to place legend; 0 (default) is at left, 1 at right.

\item[\code{y.leg}] Porportionate location along the X-axis to place legend;  0 is at bottom, 1 (default) at top.

\item[\code{cex.leg}] Porportionate size of legend text.

\item[\code{omit}] Deceimal between 0 and 1 specifying the proportion of ``burn-in'' cycles to omit from the plots.  If missing,
the first 20\% will be omitted.

\item[\code{col}] A vector of colors for the curves, which will be recycled if too short.  Not mandatory.

\item[\code{out}] Direct output to a PDF, EPS or image file.  Format is a named list whose first argument, 
\code{type} is one of the following character vectors: ``pdf'', ``eps'' (maps to \code{postscript}),
``\code{png}'', ``\code{tiff}'', ``\code{jpeg}'', or ``\code{bmp}''.  Other named items in the list
are the arguments to each graphic device. PDF and EPS are vector images acceptable to most journals
in a very small file size, with scalable (i.e. infinite) resolution.  The others are raster images which may be very
large files at publication quality dots per inch (DPI), e.g. 800 or 1200. Default value is \code{NA} which means the 
output will go to the current graphic device (usually the monitor). For example, to output an eps file,
out=list(``eps'') will generate a 7x7 inch (default) graphic.

\item[\code{...}] Additional R plotting parameters.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Plots a panel with the following windows: -2 times the log-likelihood at each cycle, gamma/lambda at
each cycle; Akaike Information Criterion at each cyle and Bayesian (Schwartz) Information Criterion
at each cycle, the mean parameter values at each cycle (normalized to starting values); the normalized
standard deviation of the population distribution for each parameter at each cycle; and
the normalized median parameter values at each cycle.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeCycle}{makeCycle}}, \code{\LinkA{plot}{plot}}, \code{\LinkA{par}{par}}, \code{\LinkA{axis}{axis}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
plot(cycle.1)
plot(cycle.1,omit=0)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{plot.PMdopt}{Plot Pmetrics D-optimal Times}{plot.PMdopt}
%
\begin{Description}\relax
Plot PMdopt objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMdopt'
plot(
  x,
  col.mean = "red",
  lwd.mean = 4,
  ticksize.mean = 0.1,
  xlab = "Time",
  ylab = "Probability",
  layout = c(1, 1),
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{PMdopt} data object generated by \code{\LinkA{Dopt}{Dopt}}

\item[\code{col.mean}] This parameter will be applied to the tick mark indicating the weighted mean
optimal time

\item[\code{lwd.mean}] This parameter will be applied to the tick mark indicating the weighted mean
optimal time

\item[\code{ticksize.mean}] This parameter will be applied to the tick mark indicating the weighted mean
optimal time

\item[\code{xlab}] Define x-axis label.  Default is ``Time''.

\item[\code{ylab}] Define y-axis label.  Default ``Probability''.

\item[\code{layout}] This parameter specifies the number of rows and columns per page, e.g. layout=c(2,2).

\item[\code{...}] Other parameters as found in \code{\LinkA{plot.default}{plot.default}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will plot the output of the \code{\LinkA{Dopt}{Dopt}} function.  A histogram is generated
with the probability distribution of each optimal time for each support point in the model,
and the weighted mean for that time.
\end{Details}
%
\begin{Value}
Plots the object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{Dopt}{Dopt}}, \code{\LinkA{summary.PMdopt}{summary.PMdopt}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{plot.PMfinal}{Plot Pmetrics Final Cycle Parameter Value Distributions}{plot.PMfinal}
%
\begin{Description}\relax
Plot PMfinal objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMfinal'
plot(
  x,
  formula,
  include,
  exclude,
  ref = T,
  cex.lab = 1.2,
  col,
  col.ref,
  alpha.ref = 0.5,
  pch,
  cex,
  lwd,
  lwd.ref,
  density = F,
  scale = 20,
  bg,
  standard = F,
  probs = c(0.05, 0.25, 0.5, 0.75, 0.95),
  legend = T,
  grid = T,
  layout,
  xlab,
  ylab,
  xlim,
  ylim,
  out = NA,
  add = F,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{PMfinal} data object generated by \code{\LinkA{makeFinal}{makeFinal}}

\item[\code{formula}] An optional formula of the form \code{y \textasciitilde{} x}, where \code{y} and \code{x}
are two model parameters to plot in a 3-dimensional bivariate plot.  See details.

\item[\code{include}] A vector of subject IDs to include in a Bayesian posterior marginal parameter 
distribution plot, e.g. c(1:3,5,15).  Only relevant
for Bayesian posterior plots generated by \code{formula} values of the form \emph{prob\textasciitilde{}par}, where
\emph{par} is a parameter in the model.

\item[\code{exclude}] A vector of subject IDs to exclude in a Bayesian posterior marginal parameter 
distribution plot, e.g. c(4,6:14,16:20). Only relevant
for Bayesian posterior plots generated by \code{formula} values of the form \emph{prob\textasciitilde{}par}, where
\emph{par} is a parameter in the model.

\item[\code{ref}] Boolean operator to include (if \code{TRUE} which is the default) the population marginals
in posterior marginal plot as reference.

\item[\code{cex.lab}] Size of the plot labels for any univariate or bivariate marginal plot.

\item[\code{col}] This parameter will be applied to the histogram lines of a univariate marginal
plot, or the central point of a bivariate plot and is ``red'' by default for the former, 
and ``white'' for the latter.

\item[\code{col.ref}] Color of reference population marginals included in posterior marginal plots.

\item[\code{alpha.ref}] Alpha value for transparency of reference marginals. Default is 0.5, with 0=invisible and 1=opaque.

\item[\code{pch}] The plotting character for points in bivariate plots.  Default is a cross (pch=3).

\item[\code{cex}] The size of the points in bivariate plots

\item[\code{lwd}] Width of the histogram lines in the univariate marginal parameter distributions
or the thickness of the central points and lines around points in bivariate NPAG plots or around quantiles in the bivariate
IT2B plots.

\item[\code{lwd.ref}] Width of histogram lines for population marginals included in posterior marginal plots.

\item[\code{density}] Boolean operator to plot a kernel density function overlying the histogram
of a univarite marginal parameter distribution from NPAG; the default is \code{False}.
See \code{\LinkA{density}{density}}.  Ignored for IT2B output.

\item[\code{scale}] How large to scale the points in a bivariate NPAG plot, relative to their probability.
Ignored for IT2B output.

\item[\code{bg}] Background fill for points in bivariate NPAG plot.  Ignored for IT2B output.

\item[\code{standard}] Standardize the normal parameter distribution plots from IT2B to the same
scale x-axis.  Ignored for NPAG output.

\item[\code{probs}] Vector of quantiles to plot on bivariate IT2B plot.  Ignored for NPAG plot.

\item[\code{legend}] Boolean operator for default if \code{True} or list of parameters to be supplied to legend function to plot 
quantile legend on bivariate IT2B plot.  Ignored for NPAG plot.

\item[\code{grid}] Boolean operator to plot a grid on either a bivariate NPAG or IT2B plot.

\item[\code{xlab}] Define x-axis label for bivariate NPAG or IT2B plot.  Default is the name of the plotted x-variable.

\item[\code{ylab}] Define y-axis label for bivariate NPAG or IT2B plot.  Default is the name of the plotted y-variable.

\item[\code{xlim}] Limits for the x-axis in a bivariate NPAG or IT2B plot.  Default is the range of the x-variable.

\item[\code{ylim}] Limits for the y-axis in a bivariate NPAG or IT2B plot.  Default is the range of the y-variable.

\item[\code{out}] Direct output to a PDF, EPS or image file.  Format is a named list whose first argument, 
\code{type} is one of the following character vectors: ``pdf'', ``eps'' (maps to \code{postscript}),
``\code{png}'', ``\code{tiff}'', ``\code{jpeg}'', or ``\code{bmp}''.  Other named items in the list
are the arguments to each graphic device. PDF and EPS are vector images acceptable to most journals
in a very small file size, with scalable (i.e. infinite) resolution.  The others are raster images which may be very
large files at publication quality dots per inch (DPI), e.g. 800 or 1200. Default value is \code{NA} which means the 
output will go to the current graphic device (usually the monitor). For example, to output an eps file,
out=list(``eps'') will generate a 7x7 inch (default) graphic.

\item[\code{...}] Other parameters as found in \code{\LinkA{plot.default}{plot.default}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
If \code{formula} is omitted, this will generate a marginal plot for each parameter.  
For NPAG data, this will be a histogram of marginal values for each parameter and the associated probability
of that value.  For IT2B, this will be a series of normal distributions with mean and standard deviation
equal to the mean and standard deviation of each parameter marginal distribution, and the standard deviation and 95
indicated at the bottom of each plot.  IF \code{formula} IS specified,
this will generate one of two plots.  Specifying ``prob'' as the y-value vs. a parameter
will generate a marginal plot of Bayesian posterior parameter distributions for included/excluded
subjects.  For example, \code{prob\textasciitilde{}CL} will plot Bayesian posterior distributions for CL for each 
included/excluded subject.

On the other hand, if \code{formula} is two parameters, e.g. CL\textasciitilde{}V, this will generate a bivariate plot.  
For NPAG data, it will be support point with size proportional to the probability
of each point.  For IT2B, it will be an elliptical distribution of a bivariate normal distribution centered at the mean
of each plotted variable and surrounding quantiles of the bivariate distribution plotted in decreasing shades of grey.
\end{Details}
%
\begin{Value}
Plots the object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeFinal}{makeFinal}}, \code{\LinkA{plot}{plot}}, \code{\LinkA{par}{par}}, \code{\LinkA{axis}{axis}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
plot(final.1)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{plot.PMmatrix}{Plot PMmatrix Time-Output Data}{plot.PMmatrix}
%
\begin{Description}\relax
\code{plot.PMmatrix} plots \emph{PMmatrix} objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMmatrix'
plot(
  x,
  include,
  exclude,
  pred = NULL,
  icen = "median",
  mult = 1,
  outeq,
  group,
  block = 1,
  layout = c(3, 3),
  log = F,
  pch = NA,
  errbar = F,
  doses = F,
  tad = F,
  join = T,
  grid,
  ident = F,
  overlay = T,
  main,
  xlim,
  ylim,
  xlab = "Time (h)",
  ylab = "Observation",
  col,
  col.pred,
  cex = 1,
  legend,
  out = NA,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{PMmatrix} data object read by \code{\LinkA{PMreadMatrix}{PMreadMatrix}}

\item[\code{include}] A vector of subject IDs to include in the plot, e.g. c(1:3,5,15)

\item[\code{exclude}] A vector of subject IDs to exclude in the plot, e.g. c(4,6:14,16:20)

\item[\code{pred}] The name of a population or posterior prediction object read by \code{\LinkA{makePop}{makePop}} or 
\code{\LinkA{makePost}{makePost}}, respectively

\item[\code{icen}] Only relevant for PMpost or PMpop objects which have predictions based on median or mean of each
subject's Bayesian posterior parameter distribution.  Default is "median", but could be "mean".

\item[\code{mult}] Multiplication factor for y axis, e.g. to convert mg/L to ng/mL

\item[\code{outeq}] A vector of output equation(s) to plot; if missing, plot all.  E.g. outeq=1, outeq=2, outeq=c(1,3).

\item[\code{group}] Quoted name of a covariate in \code{data} by which
to distinguish groups with color in the plot. Note that if covariates do not have values on observation
rows, those observations will be unable to be grouped.  Grouping is only applicable if \code{outeq} is
specified; otherwise there would be a confusing mix of colors for groups and output equations.

\item[\code{block}] Which block to plot, where a new block is defined by dose resets (evid=4); default is 1.

\item[\code{layout}] If \code{overlay} is \code{False}, this parameter specifies the number of plots per page.

\item[\code{log}] Boolean operator to plot in log-log space; the default is \code{False}

\item[\code{pch}] Controls the plotting symbol for observations; default is NA which results in no symbol.
Use 0 for open square, 1 for open circle, 2 for open triangle, 3 for cross, 4 for X, or 5 for a diamond.
Other alternatives are ``*'' for asterisks, ``.'' for tiny dots, or ``+'' for a smaller,
bolder cross.  These plotting symbols are standard for R (see \code{\LinkA{par}{par}}).

\item[\code{errbar}] Either boolean (true/false) or a list.  If assay error coefficients are included
in the data file, setting this to \code{True} will plot error bars around each observation
according to the standard deviation calculated from C0, C1, C2 and C3 in the data file.
If C0, C1, C2, and C3 are missing in the data file, you can specify \code{errbar} to be a named list,
i.e. \code{list(c0=,c1=,c2=,c3=)}, where each value is a vector of length equal to the number of
output equations.  For example, with two output equations having coefficients of 
0.1, 0.15, 0, 0 and 0.2, 0.1, -0.001, and 0, specify as \code{errbar=list(c0=c(0.1,0.2),
c1=c(0.15,0.1),c2=c(0,-0.001),c3=c(0,0))}.

\item[\code{doses}] Boolean operator to include doses as small lines at the bottom of the plot.
Infusions are correctly represented according to their duration.  The default is \code{False}.
This parameter is ignored if \code{overlay} is \code{True}.

\item[\code{tad}] Boolean operator to use time after dose rather than time after start.  Default is \code{False}.

\item[\code{join}] Boolean operator to join observations by a straight line; the default is \code{True}.

\item[\code{grid}] Either a boolean operator to plot a reference grid, or a list with elements x and y,
each of which is a vector specifying the native coordinates to plot grid lines; the default is \code{False}.
For example, grid=list(x=seq(0,24,2),y=1:10).  Defaults for missing x or y will be calculated by \code{\LinkA{axTicks}{axTicks}}.

\item[\code{ident}] Boolean operator to plot points as ID numbers in overlay plots; the default is \code{False}.  Ignored if \code{overlay} is false.
This option is useful to identify outliers.\#' @param overlay Boolean operator to overlay all time concentration profiles in a single plot.
The default is \code{True}.

\item[\code{main}] An optional parameter to specify the title for plot(s).  If \code{overlay} is \code{False},
the default will be the subject identification. If \code{overlay} is \code{True}, the default is blank.
To omit a title from a non-overlaid plot, use the syntax \code{main=}``''.

\item[\code{xlim}] Optional to specify the limits for the x axis.

\item[\code{ylim}] Optional to specify the limits for the y axis.

\item[\code{xlab}] Label for the x axis.  Default is ``Time (h)''

\item[\code{ylab}] Label for the y axis.  Default is ``Observation''

\item[\code{col}] A vector of color names to be used for output equation or group coloring.  If the
length of \code{col} is too short, values will be recycled.

\item[\code{col.pred}] A vector of color names to be used for prediction (post or pop) coloring.  Default is the same
as \code{col}.

\item[\code{cex}] Size of the plot symbols.

\item[\code{legend}] Either a boolean operator or a list of parameters to be supplied to the \code{\LinkA{legend}{legend}}
function (see its documentation).  If \code{False} or missing, a legend will not be plotted.
If \code{True}, the default legend parameters will be used, as documented in that function, with exceptions
as noted in \emph{Details}.

\item[\code{out}] Direct output to a PDF, EPS or image file.  Format is a named list whose first argument, 
\code{type} is one of the following character vectors: ``pdf'', ``eps'' (maps to \code{postscript}),
``\code{png}'', ``\code{tiff}'', ``\code{jpeg}'', or ``\code{bmp}''.  Other named items in the list
are the arguments to each graphic device. PDF and EPS are vector images acceptable to most journals
in a very small file size, with scalable (i.e. infinite) resolution.  The others are raster images which may be very
large files at publication quality dots per inch (DPI), e.g. 800 or 1200. Default value is \code{NA} which means the 
output will go to the current graphic device (usually the monitor). For example, to output an eps file,
out=list(``eps'') will generate a 7x7 inch (default) graphic.

\item[\code{...}] Other parameters as found in \code{\LinkA{plot.default}{plot.default}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will plot raw and fitted time and concentration data with a variety of options.
For the legend, defaults that are different that the standard are:
\begin{itemize}

\item{} x Default ``topright''
\item{} legend Default will be factor label names if \code{group} is specified and valid; otherwise
``Output 1, Output 2,...Output n'', where \emph{n} is the number of output equations.  This default
can be overridden by a supplied character vector of output names.
\item{} fill The color of each group/output as specified by the default color scheme or \code{col}
\item{} bg Default ``white''

\end{itemize}

\end{Details}
%
\begin{Value}
Plots the object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMreadMatrix}{PMreadMatrix}}, \code{\LinkA{plot}{plot}}, \code{\LinkA{par}{par}}, \code{\LinkA{axis}{axis}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
plot(mdata.1)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{plot.PMop}{Plot Pmetrics Observed vs. Predicted Objects}{plot.PMop}
%
\begin{Description}\relax
Plot PMop objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMop'
plot(
  x,
  include,
  exclude,
  pred.type = "post",
  icen = "median",
  outeq = 1,
  mult = 1,
  resid = F,
  log = F,
  square = T,
  ref = T,
  lowess = F,
  reg = T,
  grid,
  ident = F,
  ci = 0.95,
  cex = 1,
  cex.lab = 1.2,
  x.stat = 0.4,
  y.stat = 0.1,
  col.stat = "black",
  cex.stat = 1.2,
  lwd = 2,
  col = "red",
  xlim,
  ylim,
  xlab,
  ylab,
  out = NA,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{PMop} data object generated by \code{\LinkA{makeOP}{makeOP}}.

\item[\code{include}] A vector of subject IDs to include in the plot, e.g. c(1:3,5,15)

\item[\code{exclude}] A vector of subject IDs to exclude in the plot, e.g. c(4,6:14,16:20)

\item[\code{pred.type}] Either 'post' for a posterior object or 'pop' for a population object.  Default is 'post'.

\item[\code{icen}] Can be either "median" for the predictions based on medians of \code{pred.type} parameter value
distributions, or "mean".  Default is "median".

\item[\code{outeq}] Output equation number.  Default is 1.

\item[\code{mult}] Multiplication factor for x and y axes, e.g. to convert mg/L to ng/mL.  Ignored for residual plots.

\item[\code{resid}] Boolean operator to generate a plot of weighted prediction error vs. prediction,
a plot of weighted prediction error vs. time, and histogram plot of the weighted prediction errors,
with overlying normal distribution of the same mean and variance if \code{ref} is true, and
a P-value for the Kolmogorov-Smirnov test for non-normality if \code{reg} is true.  The default is \code{False}.

\item[\code{log}] Boolean operator to plot in log-log space.  This parameter is ignored for residual plots.  The default is \code{False}

\item[\code{square}] Boolean operator to force a observed vs. predicted plots to be square with equal x and y limits.
This parameter is ignored for residual plots.  The default is \code{True}

\item[\code{ref}] Boolean operator to draw a reference line of slope 1 in observed vs. predicted plots and
slope 0 in residual plots, or a reference normal distribution in residual histogram; the default is \code{True}

\item[\code{lowess}] Boolean operator to draw a lowess regression line in observed vs. predicted or
residual plots; the default is \code{False}

\item[\code{reg}] Boolean operator to draw a linear regression line and print regression statistics on the plot.
For weighted residual plots, it will print the mean weighted prediction error with P value for difference from 0,
and the standard deviation of the weighted prediction errors, as well as the probability that the distribution of
weighted residuals is not different from normal by the Kolmogorov-Smirnov test.  The default is \code{True}.

\item[\code{grid}] Either a boolean operator to plot a reference grid, or a list with elements x and y,
each of which is a vector specifying the native coordinates to plot grid lines; the default is \code{False}.
For example, grid=list(x=seq(0,24,2),y=1:10).  Defaults for missing x or y will be calculated by \code{\LinkA{axTicks}{axTicks}}.
For residual plots, list values for \code{grid} will be interpreted as \code{True}, i.e. custom grid lines are not allowed.

\item[\code{ident}] Boolean operator to plot points as ID numbers; the default is \code{False}.
This option is useful to identify outliers.

\item[\code{ci}] The confidence interval for the linear regression parameter estimates; the default is 0.95.

\item[\code{cex}] Size of the plot symbols.

\item[\code{cex.lab}] Size of the plot labels.

\item[\code{x.stat}] Horizontal position to plot the regression or residual statistics;
the units are relative to the origin, i.e. extreme left is 0 and extreme right is 1.

\item[\code{y.stat}] Vertical position to plot the regression or residual statistics; 
the units are relative to the origin, i.e. extreme bottom is 0 and extreme top is 1.

\item[\code{col.stat}] Color of the text for the regression or residual statistics.

\item[\code{cex.stat}] Size of the text for the regression or residual statistics

\item[\code{lwd}] Width of the various regression or reference lines (reference, linear regression, or
lowess regression)

\item[\code{col}] This parameter will be applied to the plotting symbol and is ``red'' by default.

\item[\code{xlim}] Limits of the x-axis as a vector, e.g. \code{c(0,1)}.  It does not need to be specified, but can be.

\item[\code{ylim}] Analogous to \code{xlim}

\item[\code{xlab}] Label for the x-axis.  If missing, will default to ``Observed''.

\item[\code{ylab}] Label for the y-axis.  If missing, will default to ``Predicted''.

\item[\code{out}] Direct output to a PDF, EPS or image file.  Format is a named list whose first argument, 
\code{type} is one of the following character vectors: ``pdf'', ``eps'' (maps to \code{postscript}),
``\code{png}'', ``\code{tiff}'', ``\code{jpeg}'', or ``\code{bmp}''.  Other named items in the list
are the arguments to each graphic device. PDF and EPS are vector images acceptable to most journals
in a very small file size, with scalable (i.e. infinite) resolution.  The others are raster images which may be very
large files at publication quality dots per inch (DPI), e.g. 800 or 1200. Default value is \code{NA} which means the 
output will go to the current graphic device (usually the monitor). For example, to output an eps file,
out=list(``eps'') will generate a 7x7 inch (default) graphic.

\item[\code{...}] Other parameters as found in \code{\LinkA{plot.default}{plot.default}}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Plots the object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeOP}{makeOP}}, \code{\LinkA{plot}{plot}}, \code{\LinkA{par}{par}}, \code{\LinkA{axis}{axis}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
plot(op.1)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{plot.PMpta}{Plot PMpta Percent Target Attainment objects}{plot.PMpta}
%
\begin{Description}\relax
Plots PMpta objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMpta'
plot(
  x,
  include,
  exclude,
  plot.type = "pta",
  log = T,
  pch,
  grid,
  xlab,
  ylab,
  col,
  lty,
  lwd = 4,
  legend = T,
  ci = 0.9,
  out = NA,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{PMpta} data object read by \code{\LinkA{makePTA}{makePTA}}

\item[\code{include}] A vector of simulations (regimens) to include in the plot, e.g. c(1,3)

\item[\code{exclude}] A vector of simulations (regimens) in the plot, e.g. c(2,4:6)

\item[\code{plot.type}] Character vector controlling type of plot.
Default is ``pta'', which plots proportion with success on the y-axis and target on the x-axis.
The other choice is ``pdi'', which plots the median pdi (pharmacodynamic index), e.g. AUC/MIC, on the
y-axis, and target on the x-axis.

\item[\code{log}] Boolean operator to plot x-axis in logarithmic scale; the default is \code{True}

\item[\code{pch}] Vector of integers which control the plotting symbol for each regimen curve; the default is 1:nsim.  NA results in no symbol.
Use 0 for open square, 1 for open circle, 2 for open triangle, 3 for cross, 4 for X, or 5 for a diamond.
Other alternatives are ``*'' for asterisks, ``.'' for tiny dots, or ``+'' for a smaller,
bolder cross.  These plotting symbols are standard for R (see \code{\LinkA{par}{par}}).

\item[\code{grid}] Either a boolean operator to plot a reference grid, or a list with elements x and y,
each of which is a vector specifying the native coordinates to plot grid lines; the default is \code{False}.
For example, grid=list(x=seq(0,24,2),y=1:10).  Defaults for missing x or y will be calculated by \code{\LinkA{axTicks}{axTicks}}.

\item[\code{xlab}] Label for the x axis.  Default is ``MIC''

\item[\code{ylab}] Label for the y axis.  Default is ``Proportion with success''

\item[\code{col}] A vector of color names to be used for each regimen plotted.  If the
length of \code{col} is too short, values will be recycled.

\item[\code{lty}] A vector of line types to be used for each regimen plotted.  If the
length of \code{lty} is too short, values will be recycled.

\item[\code{lwd}] Line width, with default of 4.

\item[\code{legend}] Either a boolean operator or a list of parameters to be supplied to the \code{\LinkA{legend}{legend}}
function (see its documentation).  If \code{False}, a legend will not be plotted.
If \code{True} (the default), the default legend parameters will be used, as documented in that function, with exceptions
as noted in \emph{Details}.

\item[\code{ci}] Confidence interval around curves on \code{pdi} plot, on scale of 0 to 1. Default is 0.9.

\item[\code{out}] Direct output to a PDF, EPS or image file.  Format is a named list whose first argument, 
\code{type} is one of the following character vectors: ``pdf'', ``eps'' (maps to \code{postscript}),
``\code{png}'', ``\code{tiff}'', ``\code{jpeg}'', or ``\code{bmp}''.  Other named items in the list
are the arguments to each graphic device. PDF and EPS are vector images acceptable to most journals
in a very small file size, with scalable (i.e. infinite) resolution.  The others are raster images which may be very
large files at publication quality dots per inch (DPI), e.g. 800 or 1200. Default value is \code{NA} which means the 
output will go to the current graphic device (usually the monitor). For example, to output an eps file,
out=list(``eps'') will generate a 7x7 inch (default) graphic.

\item[\code{...}] Other parameters as found in \code{\LinkA{plot.default}{plot.default}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will plot the percent target attainment for objects made with the \code{\LinkA{makePTA}{makePTA}} function.
For the legend, defaults that are different that the standard are:
\begin{itemize}

\item{} x Default ``topright''
\item{} legend Default will be the labeled regimen names supplied during \code{\LinkA{makePTA}{makePTA}}, 
or if missing, ``Regimen 1, Regimen 2,...Regimen n'', where \emph{n} is the number of 
regimens in the PMpta object.  
This default can be overridden by a supplied character vector of regimen names.
\item{} col The color of each Regimen plot as specified by the default color scheme or \code{col}
\item{} pch The plotting character for each Regimen plot as specified by the default plotting characters or \code{pch}
\item{} lty The line type of each Regimen plot as specified by the default line types or \code{lty}
\item{} bg Default ``white''

\end{itemize}

\end{Details}
%
\begin{Value}
Plots the object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makePTA}{makePTA}}, \code{\LinkA{plot}{plot}}, \code{\LinkA{par}{par}}, \code{\LinkA{axis}{axis}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{plot.PMsim}{Plot Pmetrics Simulation Objects}{plot.PMsim}
%
\begin{Description}\relax
Plots \emph{PMsim} objects with the option to perform a visual and numerical predictive check
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMsim'
plot(
  x,
  mult = 1,
  log = T,
  probs = c(0.05, 0.25, 0.5, 0.75, 0.95),
  binSize = 0,
  outeq = 1,
  pch = NA,
  join = T,
  x.qlab = 0.4,
  cex.qlab = 0.8,
  pos.qlab = 1,
  ci = 0.95,
  cex.lab = 1.2,
  xlab = "Time (h)",
  ylab = "Output",
  xlim,
  ylim,
  obs,
  grid,
  ocol = "blue",
  add = F,
  out = NA,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{PMsim} data object generated by \code{\LinkA{SIMparse}{SIMparse}}

\item[\code{mult}] Multiplication factor for y axis, e.g. to convert mg/L to ng/mL

\item[\code{log}] Boolean operator to plot in log-log space; the default is \code{False}

\item[\code{probs}] Vector of quantiles to plot; if set to \code{NA}, all simulated profiles will be plotted,
and numerical predictive checking will be suppressed

\item[\code{binSize}] Width of binning interval for simulated concentrations, in time units, e.g. hours.  For example,
a \code{binSize} of 0.5 will pull all simulated concentrations +/- 0.5 hours into the same time.  This is useful
for plotting PMsim objects made during \code{\LinkA{makeNPDE}{makeNPDE}}. The default is 0, i.e. no binning.

\item[\code{outeq}] Which output equation to plot if more than 1

\item[\code{pch}] Controls the plotting symbol for observations; default is NA which results in no symbol.
Use 0 for open square, 1 for open circle, 2 for open triangle, 3 for cross, 4 for X, or 5 for a diamond.
Other alternatives are ``*'' for asterisks, ``.'' for tiny dots, or ``+'' for a smaller,
bolder cross.  These plotting symbols are standard for R (see \code{\LinkA{par}{par}}).

\item[\code{join}] Boolean operator to join observations by a straight line; the default is \code{True}.

\item[\code{x.qlab}] Proportionate value of x-axis at which to draw the quantile labels; 0 is left, 1 is right.
The default is 0.4.

\item[\code{cex.qlab}] Size of the quantile labels.

\item[\code{pos.qlab}] This allows more refined positioning of the quantile labels.  It takes standard R
values: 1, below; 2, left; 3, above; 4, right.

\item[\code{ci}] Width of confidence interval bands around simulated quantiles, from 0 to 1.  If 0, or \emph{nsim}<100, will not plot.
Default is 0.95, i.e. 95th percentile with tails of 2.5 percent above and below excluded.

\item[\code{cex.lab}] Size of the plot labels.

\item[\code{xlab}] Label for x-axis; default is ``Time''

\item[\code{ylab}] Label for y-axis; default is ``Output''

\item[\code{xlim}] Limits of the x-axis as a vector, e.g. \code{c(0,1)}.  It does not need to be specified, but can be.

\item[\code{ylim}] Analogous to \code{xlim}

\item[\code{obs}] The name of an \emph{makeOP} data object generated by \code{\LinkA{makeOP}{makeOP}}.  If specified,
the observations will be overlaid upon the simulation plot enabling a visual predicitve check.  In this case,
a list object will be returned with two items: \$npc containing the quantiles and probability that the observations
are below each quantile (binomial test); and \$simsum, the times of each observation and the 
value of the simulated quantile with upper and lower confidence intervals at that time.

\item[\code{grid}] Either a boolean operator to plot a reference grid, or a list with elements x and y,
each of which is a vector specifying the native coordinates to plot grid lines; the default is \code{False}.
For example, grid=list(x=seq(0,24,2),y=1:10).  Defaults for missing x or y will be calculated by \code{\LinkA{axTicks}{axTicks}}.

\item[\code{ocol}] Color for observations

\item[\code{add}] Boolean operator, if \code{True} will add lines to existing plot

\item[\code{out}] Direct output to a PDF, EPS or image file.  Format is a named list whose first argument, 
\code{type} is one of the following character vectors: ``pdf'', ``eps'' (maps to \code{postscript}),
``\code{png}'', ``\code{tiff}'', ``\code{jpeg}'', or ``\code{bmp}''.  Other named items in the list
are the arguments to each graphic device. PDF and EPS are vector images acceptable to most journals
in a very small file size, with scalable (i.e. infinite) resolution.  The others are raster images which may be very
large files at publication quality dots per inch (DPI), e.g. 800 or 1200. Default value is \code{NA} which means the 
output will go to the current graphic device (usually the monitor). For example, to output an eps file,
out=list(``eps'') will generate a 7x7 inch (default) graphic.

\item[\code{...}] Other parameters as found in \code{\LinkA{plot.default}{plot.default}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Simulated observations are plotted as quantiles on the y-axis vs. time on the x.axis.  If measured
observations are included, a visual and numerical predictive check will be performed.
\end{Details}
%
\begin{Value}
Plots the simulation object.  If \code{obs} is included, a list will be returned with
the folowing items:
\begin{ldescription}
\item[\code{npc}] A dataframe with three columns: quantile, prop.less, pval.  \emph{quantile} are those specified
by the \code{prob} argument to the plot call; \emph{prop.less} are the proportion of simulated
observations at all times less than the quantile; \emph{pval} is the P-value of the difference in the 
prop.less and quantile by the beta-binomial test.
\item[\code{simsum}] A dataframe with the quantile concentration at each simulated time,
with lower and upper confidence intervals
\item[\code{obs}] A dataframe similar to an PMop object made by \code{\LinkA{makeOP}{makeOP}}
with the addition of the quantile for each observation
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{SIMparse}{SIMparse}}, \code{\LinkA{plot}{plot}}, \code{\LinkA{par}{par}}, \code{\LinkA{axis}{axis}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{plot.PMvalid}{Plot Pmetrics Validation Objects}{plot.PMvalid}
%
\begin{Description}\relax
Plot PMop objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMvalid'
plot(
  x,
  type = "vpc",
  tad = F,
  icen = "median",
  lower = 0.025,
  upper = 0.975,
  log = F,
  pch.obs = 1,
  col.obs = "black",
  cex.obs = 1,
  theme = "color",
  col.obs.ci = "blue",
  col.obs.med = "red",
  col.sim.ci = "dodgerblue",
  col.sim.med = "lightpink",
  xlab = "Time",
  ylab = "Observation"
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{PMvalid} data object generated by \code{\LinkA{makeValid}{makeValid}}.

\item[\code{type}] Default is ``vpc'' for a visual prective check, but could be ``pcvpc'' for a 
prediction-corrected visual predictive check.

\item[\code{tad}] Plot using time after dose if \code{TRUE}.  Default is \code{FALSE} which plots using standard
relative time.  This will be the only option if \code{tad} was not set to \code{TRUE} when making the 
PMvalid object.

\item[\code{icen}] Can be either ``median'' for the predictions based on medians of the population parameter value
distributions, or ``mean''.  Default is ``median''.

\item[\code{lower}] The lower quantile displayed for the observed and simulated profiles. Default is 0.025.

\item[\code{upper}] The upper quantile displayed for the observed and simulated profiles. Default is 0.975.

\item[\code{log}] Boolean operator to plot in semilog space.  The default is \code{FALSE}.

\item[\code{pch.obs}] Control the plotting character used for observations.  Default is 1, i.e. an open circle.
See \code{\LinkA{points}{points}} for other values of \code{pch}.

\item[\code{col.obs}] Color for observations.  Default is black.

\item[\code{cex.obs}] Size for observatins.  Default is 1.

\item[\code{theme}] Default is ``color'', but could be ``grey'' or ``gray''.

\item[\code{col.obs.ci}] Color of the observation confidence interval (set by \code{lower} and \code{upper}).
Default is blue.

\item[\code{col.obs.med}] Color of the observation median.
Default is red.

\item[\code{col.sim.ci}] Color of the simulation confidence interval (set by \code{lower} and \code{upper}).
Default is dodgerblue.

\item[\code{col.sim.med}] Color of the simulation median.
Default is lightpink.

\item[\code{xlab}] Label for x axis.  Default is ``Time''.

\item[\code{ylab}] Label for y axis.  Default is ``Observation''.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Plots the object using ggplot2.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeValid}{makeValid}}, \code{\LinkA{plot}{plot}}, \code{\LinkA{par}{par}}, \code{\LinkA{points}{points}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{PMbuild}{Build Pmetrics}{PMbuild}
%
\begin{Description}\relax
\code{PMBuild} will ensure all dependent packages are installed and compile
Fortran source code for permanent Pmetrics modules
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMbuild()
\end{verbatim}
\end{Usage}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMcheck}{Check Pmetrics Inputs for Errors}{PMcheck}
%
\begin{Description}\relax
This function will check a .csv file or a data frame containing a
previously loaded .csv file (the output of \code{\LinkA{PMreadMatrix}{PMreadMatrix}} for errors
which would cause the analysis to fail.  If a model file is provided, and the data
file has no errors, it will also check the model file for errors.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMcheck(data, model, fix = F, quiet = F)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] The name of a Pmetrics .csv matrix file in the current working directory,
the full path to one not in the current working directory, or a data.frame containing 
the output of a previous \code{\LinkA{PMreadMatrix}{PMreadMatrix}} command.

\item[\code{model}] The filename of a Pmetrics model file in the current working directory.  This parameter is optional.
If specified, and the data object has no errors, the model file will be evaluated.

\item[\code{fix}] Boolean operator; if \code{TRUE}, Pmetrics will attempt to fix errors in the data file.
Default is \code{FALSE}.

\item[\code{quiet}] Boolean operator to suppress printed output.  Default is false.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Either a filename or a data object in memory are accepted as \code{data}.
The format of the .csv matrix file is fairly rigid.
It must have the following features.  Text is case-sensitive.
\begin{itemize}

\item{} A header in row 1 with the appropriate version, currently ``POPDATA DEC\_11''
\item{} Column headers in row 2.  These headers are: \#ID, EVID, TIME, DUR, DOSE, ADDL, II, INPUT, OUT, OUTEQ,
C0, C1, C2, C3.
\item{} No cell should be empty.  It should either contain a value or ``.'' as a placeholder.
\item{} Columns after C3 are interpreted as covariates.
\item{} All subject records must begin with TIME=0.
\item{} All dose events (EVID=1) must have entries in ID, EVID, TIME, DUR, DOSE and INPUT.  ADDL and II are optional, but if ADDL is not 0 or
missing, then II is mandatory.
\item{} All observation events (EVID=0) must have entries in ID, EVID, TIME, OUT, OUTEQ.
If an observation is missing, use \emph{-99}; otherwise use a ``.'' as a placeholder
in cells that are not required (e.g. INPUT for an observation event).
\item{} If covariates are present in the data, there must be an entry for every covariate at time 0 for each subject.
\item{} All covariates must be numeric.
\item{} All times within a subject ID must be monotonically increasing.
\item{} All subject IDs must be contiguous.
\item{} All rows must have EVID and TIME values.
\item{} All columns must be numeric except ID which may be alpha-numeric.
\item{} All subjects must have at least one observation, which could be missing, i.e. -99.

\end{itemize}


To use this function, see the example below.

After running PMcheck and looking at the errors in the errors.xlsx file, you can fix the
errors manually directly in the errors.xlsx file and resave it as a .csv file.
Alternatively, you could then try to fix the problem(s) with \code{mdata2 <- PMcheck(mdata,fix=T)}.  Note that we are now returning
a PMmatrix data object called mdata2 (hopefully cleaned of errors) rather than the PMerr object returned when \code{fix=FALSE}.
Pmetrics handles each of the errors in the following ways.
\begin{itemize}

\item{} If the columns are simply out of order, they will be reordered.  If some are missing, the fix must
be done by the user, i.e. manually.
\item{} All id and covariate values are truncated to 11 characters.
\item{} Missing observations are set to -99 (not ``.'').
\item{} Incomplete dose records are flagged for the user to fix manually.
\item{} Incomplete observation records are flagged for the user to fix manually.
\item{} Subjects without an EVID=1 as first event are flagged for the user to fix manually.
\item{} Subjects with TIME != 0 as first event have dummy dose=0 events inserted at time 0.
\item{} Subjects with a missing covariate at time 0 are flagged for the user to fix manually.
\item{} Non-numeric covariates are converted to numeric (via \LinkA{factor}{factor}).
\item{} Non-ordered times are sorted within a subject if there are no EVID=4 events; otherwise the
user must fix manually.
\item{} Non-contiguous subject ID rows are combined and sorted if there are no EVID=4 events; otherwise the
user must fix manually.
\item{} Rows missing an EVID are assigned a value of 0 if DOSE is  missing, 1 otherwise.
\item{} Rows missing a TIME value are flagged for the user to fix manually.
\item{} Columns that are non-numeric which must be numeric are flagged for the user to fix manually.
These are EVID, TIME, DUR, DOSE, ADDL, II, INPUT, OUT, OUTEQ, C0, C1, C2, and C3.  
Covariate columns are fixed separately (see above).

\end{itemize}

\end{Details}
%
\begin{Value}
If \code{fix=TRUE}, then \code{PMcheck} returns a PMmatrix data object which has been
cleaned of errors as much as possible, displaying a report on the console.  
If \code{fix=FALSE}, then \code{PMcheck} creates a file in the working directory called ``errors.xlsx''.
This file can be opened by Microsoft Excel or any other program that is capable of reading .xlsx files.  This file
contains highlighted areas that are erroneous, with clarifying comments.  You can correct the errors in the file
and then re-save as a .csv file.

When \code{fix=FALSE}, the function also returns a list of objects of class \emph{PMerr}.  Each object is itself a list whose 
first object (\code{\$msg}) is a character vector with ``OK'' plus a brief description if there is no error, or the error.  
The second object (\code{\$results}) is a vector of the row numbers that contain that error.
\begin{ldescription}
\item[\code{colorder}] The first 14 columns must be named id, evid, time, dur, dose, addl, ii, input, out, outeq, c0, c1, c2, and c3 in that order.
\item[\code{maxcharCol}] All column names should be less than or equal to 11 characters.
\item[\code{maxcharID}] All id values should be less than or equal to 11 characters.
\item[\code{missEVID}] Ensure that all rows have an EVID value.
\item[\code{missTIME}] Ensure that all rows have a TIME value.
\item[\code{doseDur}] Make sure all dose records are complete, i.e. contain a duration.
\item[\code{doseDose}] Make sure all dose records are complete, i.e. contain a dose.
\item[\code{doseInput}] Make sure all dose records are complete, i.e. contain an input number.
\item[\code{obsOut}] Make sure all observation records are complete, i.e. contain an output.
\item[\code{obsOuteq}] Make sure all observation records are complete, i.e. contain and outeq number.
\item[\code{T0}] Make sure each subject's first time=0.
\item[\code{covT0}] Make sure that there is an non-missing entry for each covariate at time=0 for each subject.
\item[\code{timeOrder}] Ensure that all times within a subject ID are monotonically increasing.
\item[\code{contigID}] Ensure that all subject IDs are contiguous.
\item[\code{nonNum}] Ensure that all columns except ID are numeric.
\item[\code{noObs}] Ensure that all subjects have at least one observation, which could be missing, i.e. -99.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely and Patrick Nolain
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMwriteMatrix}{PMwriteMatrix}}, \code{\LinkA{PMreadMatrix}{PMreadMatrix}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
data(PMex3)
err <- PMcheck(badData)
#look at the errors.xlsx file in the working directory
#try to automatically fix what can be fixed
goodData <- PMcheck(badData,fix=T)
PMcheck(goodData)
#you have to fix manually problems which require data entry

## End(Not run)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{PMcheckMatrix}{Deprecated functions.}{PMcheckMatrix}
\aliasA{ITload,}{PMcheckMatrix}{ITload,}
\aliasA{ITreport,}{PMcheckMatrix}{ITreport,}
\aliasA{NPload,}{PMcheckMatrix}{NPload,}
\aliasA{NPreport,}{PMcheckMatrix}{NPreport,}
\aliasA{PMcheckMatrix,}{PMcheckMatrix}{PMcheckMatrix,}
\aliasA{PMdiag}{PMcheckMatrix}{PMdiag}
\aliasA{PMfixMatrix,}{PMcheckMatrix}{PMfixMatrix,}
%
\begin{Description}\relax
The following functions are deprecated in Pmetrics.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMcheckMatrix()
\end{verbatim}
\end{Usage}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMcode}{Pmetrics GUI Tutor}{PMcode}
%
\begin{Description}\relax
Learn Pmetrics R code with user friendly graphical interfaces in the default browser.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMcode(func)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{func}] Quoted name of a function family used in Pmetrics.  Currently, these are limited to ``run'', 
for \code{\LinkA{NPrun}{NPrun}}, \code{\LinkA{ITrun}{ITrun}} and ``plot''.  For the first two, make sure that the model and data files are in your
working directory before calling the function.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
PMcode provides a graphical user interface to learn many of the Pmetrics functions and their arguments
using the Shiny package. A graphical user interface will launch in the default browser.  This GUI enables a point
and click approach to generating Pmetrics code (which can be pasted into the R script) and plot previews.
The idea is for users to learn the R code in an intuitive and easier manner.  There are more options available for Pmetrics
functions that are served by the GUI, but it is sufficiently powerful to serve basic needs.  To stop the shiny browser GUI, click
the stop buttton in Rstudio (upper left corner of console window) or ESC or CTRL-C may work when the R window is active.
\end{Details}
%
\begin{Value}
Nothing is returned, but the user interface is launched in the default browser.  Appropriate R code to execute
Pmetrics commands is generated depending on defaults and user-selected input.  For plotting, the resulting plot is previewed
directly in the browser.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMcompare}{Compare NPAG or IT2B runs}{PMcompare}
%
\begin{Description}\relax
Compare NPAG or IT2B runs
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMcompare(x, y, ..., icen = "median", outeq = 1, plot = F)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The run number of the first object you wish to compare. This should be a folder in your
working directory. To avoid confusion, this function does not use objects
already loaded with \code{\LinkA{PMload}{PMload}}.
This will serve as the reference output for P-value testing (see details).

\item[\code{y}] The run number of the second object to compare.

\item[\code{...}] Additional run numbers to compare.  See details.  Also, parameters to be passed to \code{\LinkA{plot.PMop}{plot.PMop}} 
if \code{plot} is true as well as to \code{\LinkA{mtsknn.eq}{mtsknn.eq}}.  Order does not matter.

\item[\code{icen}] Can be either "median" for the predictions based on medians of \code{pred.type} parameter value
distributions, or "mean".  Default is "median".\#' @param outeq Number of the output equation to compare; default is 1

\item[\code{plot}] Boolean operator selecting whether to generate observed vs. predicted plots for each data object
as in \code{\LinkA{plot.PMop}{plot.PMop}}
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Objects can be specified separated by commas, e.g. PMcompare(1,2,3) followed by
any arguments you wish to \code{\LinkA{plot.PMop}{plot.PMop}}, \code{\LinkA{mtsknn.eq}{mtsknn.eq}}. P-values are based on comparison using the nearest neighbors
approach if all models are non-parametrics.  Models may only be compared on parameters that are included
in the first model.  The P-value is the comparison between each model and the first model in
the list.  Missing P-values are when a model has no parameter names in common with the first
model, and for the first model compared to itself, or when models from IT2B runs are included.  Significant P-values indicate that the null
hypothesis should be rejected, i.e. the joint distributions between the two compared models are 
significantly different.
\end{Details}
%
\begin{Value}
A data frame with the following objects for each model to analyze:
\begin{ldescription}
\item[\code{run }] The run number of the data
\item[\code{type }] NPAG or IT2B data
\item[\code{nsub }] Number of subjects in the model
\item[\code{nvar }] Number of random parameters in the model
\item[\code{par }] Names of random parameters
\item[\code{cycles }] Number of cycles run
\item[\code{converge }] Boolean value if convergence occurred.
\item[\code{ll }] Final cycle -2*Log-likelihood 
\item[\code{aic }] Final cycle Akaike Information Criterion
\item[\code{bic }] Final cycle Bayesian (Schwartz) Information Criterion 
\item[\code{popBias }] Bias, or mean weighted prediction error of predictions based on population parameters minus observations
\item[\code{popImp }] Imprecision, or bias-adjusted mean weighted squared error of predictions based on population parameters minus observations 
\item[\code{popPerRMSE}] Percent root mean squared error of predictions based on population parameters minus observations
\item[\code{postBias }] Bias, or mean weighted prediction error of predictions - observations  based on posterior parameters
\item[\code{postImp }] Imprecision, or bias-adjusted mean weighted squared error of predictions - observations based on posterior parameters
\item[\code{postPerRMSE}] Percent root mean squared error of predictions based on posterior parameters minus observations
\item[\code{pval }] P-value for each model compared to the first. See details.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMload}{PMload}}, \code{\LinkA{plot.PMop}{plot.PMop}}, \code{\LinkA{mtsknn.eq}{mtsknn.eq}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{PMex1}{Example NPAG Output}{PMex1}
\keyword{datasets}{PMex1}
%
\begin{Description}\relax
Example dataset from an NPAG run.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMex1
\end{verbatim}
\end{Usage}
%
\begin{Format}
An R data file containing the output generated at the end of a successful NPAG run.
\begin{itemize}

\item{} NPdata.1 made by \code{\LinkA{NPparse}{NPparse}}
\item{} final.1 made by  \code{\LinkA{makeFinal}{makeFinal}}
\item{} cycle.1 made by \code{\LinkA{makeCycle}{makeCycle}}
\item{} op.1 made by \code{\LinkA{makeOP}{makeOP}}
\item{} cov.1 made by \code{\LinkA{makeCov}{makeCov}}
\item{} pop.1 made by \code{\LinkA{makePop}{makePop}}
\item{} post.1 made by \code{\LinkA{makePost}{makePost}}
\item{} mdata.1 the original data file as read by \code{\LinkA{PMreadMatrix}{PMreadMatrix}}

\end{itemize}
\end{Format}
%
\begin{Details}\relax
The run consisted of a model with an absorptive compartment and a central compartment.
There were 4 parameters in the model: lag time of absorption (Tlag1),
rate constant of absorption (Ka), volume (V) and rate constatn of elmination (Ke).
Parameters were log transformed.  There were 20 subjects in the dataset.  The run was
100 cycles long and did not converge.

The input files for this run (ex.csv and model.txt) can be downloaded as a zip file from 
\url{http://www.lapk.org/Pmetrics_install.php#examples}.
\end{Details}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMex2}{Example IT2B Output}{PMex2}
\keyword{datasets}{PMex2}
%
\begin{Description}\relax
Exmaple dataset from an IT2B run.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMex2
\end{verbatim}
\end{Usage}
%
\begin{Format}
An R data file containing the output generated at the end of a successful IT2B run.
\begin{itemize}

\item{} ITdata.1 made by \code{\LinkA{ITparse}{ITparse}}
\item{} final.1 made by  \code{\LinkA{makeFinal}{makeFinal}}
\item{} cycle.1 made by \code{\LinkA{makeCycle}{makeCycle}}
\item{} op.1 made by \code{\LinkA{makeOP}{makeOP}}
\item{} cov.1 made by \code{\LinkA{makeCov}{makeCov}}
\item{} mdata.1 the original data file as read by \code{\LinkA{PMreadMatrix}{PMreadMatrix}}

\end{itemize}
\end{Format}
%
\begin{Details}\relax
The run consisted of a model with an absorptive compartment and a central compartment.
There were 4 parameters in the model: lag time of absorption (Tlag1),
rate constant of absorption (Ka), volume (V) and rate constatn of elmination (Ke).
Parameters were log transformed.  There were 20 subjects in the dataset.  The run was
20 cycles long and did converge.

The input files for this run (ex.csv and model.txt) can be downloaded as a zip file from 
\url{http://www.lapk.org/Pmetrics_install.php#examples}.
\end{Details}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMex3}{Pmetrics data file with errors}{PMex3}
\keyword{datasets}{PMex3}
%
\begin{Description}\relax
Example dataset for an NPAG run, which has been corrupted with errors.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMex3
\end{verbatim}
\end{Usage}
%
\begin{Format}
badData is a PMmatrix object as read by \code{\LinkA{PMreadMatrix}{PMreadMatrix}}
\end{Format}
%
\begin{Details}\relax
Errors include missing covariate on first line for subject 1, alphanumeric covariate for
gender, and trailing dose for subject 1.
\end{Details}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMFortranConfig}{Read or define the Fortran compiler and command line template}{PMFortranConfig}
%
\begin{Description}\relax
\code{PMFortranConfig} will read or define the installed Fortran compiler and generate
a command line template appropriate to the compiler.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMFortranConfig(reconfig = F)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{reconfig}] Default is \code{False}.  If \code{True}, will allow user to change
the previously specified compiler and template.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Command line templates are defined for the following compilers: \bold{gfortran}, \bold{g95},
\bold{Intel Visual}, and \bold{Lahey}.  Additionally, users may specify a custom command line
template for any other compiler.  Within the template \emph{<exec>} is used as a placeholder
for the filename of the executable file, and \emph{<files>} as a placeholder for the files to
compile and link, both of which will be defined at run time by the appropriate Pmetrics functions.
The Pmetrics functions which use a Fortran compiler are \code{\LinkA{NPrun}{NPrun}}, \code{\LinkA{ITrun}{ITrun}},
\code{\LinkA{ERRrun}{ERRrun}}, and \code{\LinkA{SIMrun}{SIMrun}}.
\end{Details}
%
\begin{Value}
\code{PMFortranConfig} returns the compile command template specific to the chosen
compiler.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{NPrun}{NPrun}}, \code{\LinkA{ITrun}{ITrun}},\code{\LinkA{ERRrun}{ERRrun}}, and
\code{\LinkA{SIMrun}{SIMrun}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{PMgetCRCL}{Add Jelliffe Creatinine Clearance}{PMgetCRCL}
%
\begin{Description}\relax
Gets creatinine clearance as estimated by the Jelliffe equation.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMgetCRCL(
  mdata,
  idCol = "id",
  wtCol = "wt",
  maleCol = "male",
  ageCol = "age",
  scrCol = "scr",
  SI = F
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{mdata}] A Pmetrics matrix data object

\item[\code{idCol}] A character vector with the name
of the id column in \code{mdata}. The default is ``id''.

\item[\code{wtCol}] A character vector with the name of the weight
column in \code{data}.  The default is ``wt''.

\item[\code{maleCol}] A character vector with the name of the gender column in \code{mdata}.
Male should be 1 and female should be 0. The default is ``male''.

\item[\code{ageCol}] A character vector with the name of the age column in \code{mdata}.
The default is ``age''.

\item[\code{scrCol}] A character vector with the name of the serum creatinine column in \code{mdata}.
Default units are mg/dL, and the the default name is ``scr''.

\item[\code{SI}] Boolean value, if true, will expect serum creatinine to be in micromol/L.
Default is \code{FALSE}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The equation depends on age, sex, weight, and serum creatinine.
ESS = wt * (29.3 - (0.203 * age)) for males
ESS = wt * (25.1 - (0.175 * age)) for females
scrAve = (Scr1 + Scr2) / 2
ESS\_cor = ESS * (1.035 - (0.0337 * scrAve))
E = ESS\_cor - 4 * wt * (Scr2 - Scr1) / (time2 - time1)
CRCL = E / (14.4 * scrAve) in ml/min/1.73m\textasciicircum{}2
\end{Details}
%
\begin{Value}
A vector of length \code{nrow(mdata)} with Jelliffe CRCL values for every dose in \code{mdata}. Vector values
for observation events in \code{mdata} are NA.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMload}{Load Pmetrics NPAG or IT2B output}{PMload}
%
\begin{Description}\relax
Loads all the data from an \emph{NPAG} or \emph{IT2B} run
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMload(run = 1, ..., remote = F, server_address)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{run}] The numerical value of the folder number containing the run results.  This
number will also be used to name objects uniquely by appending ``.\code{run}'', 
e.g. NPdata.1 or ITdata.1 if run=1. This parameter is \code{1} by default.

\item[\code{...}] Additional runs to load if desired.

\item[\code{remote}] Default is \code{FALSE}.  Set to \code{TRUE} if loading results of an NPAG run on remote server.
See \code{\LinkA{NPrun}{NPrun}}. Currently remote runs are not configured for IT2B or the Simulator.

\item[\code{server\_address}] If missing, will use the default server address returned by getPMoptions(). 
Pmetrics will prompt the user to set this address the first time the \code{remote} argument is set to \code{TRUE}
in \code{\LinkA{NPrun}{NPrun}}.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The following objects are loaded into R.
\begin{ldescription}
\item[\code{NPdata/ITdata }] List with all output from NPAG/IT2B
\item[\code{pop }]  NPAG only: Population predictions for each output equation
\item[\code{post }]  NPAG only: Individual posterior predictions for each output equation
\item[\code{final }] Final cycle population support points and parameter summary statistics
\item[\code{cycle }] Cycle log-likelihood, AIC, BIC, Gamma/lambda, and normalized parameter means, medians and SDs
\item[\code{op }] List of observed vs. population and posterior predicted plots for each output equation
\item[\code{cov }] Data frame of subject ID, covariate values, and Bayesian posterior parameter estimates
\item[\code{mdata }] The original .csv data file used in the run
\item[\code{npde }] If \code{\LinkA{makeNPDE}{makeNPDE}} has been run after a run, this object will be added to 
the save data.  It contains the information required to plot and analzye normalized prediction
error discrepancies via the npde package of Comets et al
\item[\code{sim }] If \code{\LinkA{makeNPDE}{makeNPDE}} has been run after a run, this list object will be added to 
the save data.  It contains the results of each subject in the dataset simulated n times (default 1000)
using the final model population parameters.  To plot the results of subject 3 from run 2, for example, use the form
\code{plot(sim.2[[3]])}\end{ldescription}
.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMreport}{PMreport}}, \code{\LinkA{NPparse}{NPparse}}, \code{\LinkA{ITparse}{ITparse}}, 
\code{\LinkA{makeFinal}{makeFinal}}, \code{\LinkA{makeCycle}{makeCycle}}, \code{\LinkA{makeOP}{makeOP}}, \code{\LinkA{makeCov}{makeCov}}, 
\code{\LinkA{makePop}{makePop}}, \code{\LinkA{makePost}{makePost}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{PMmanual}{Open user and function manuals.}{PMmanual}
%
\begin{Description}\relax
Opens the Pmetrics User Manual and function libraries
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMmanual()
\end{verbatim}
\end{Usage}
%
\begin{Details}\relax
Help for Pmetrics.
\end{Details}
\inputencoding{utf8}
\HeaderA{PMmatrixRelTime}{Convert Absolute Dates and Times to Relative Hours}{PMmatrixRelTime}
%
\begin{Description}\relax
\code{PMmatrixRelTime} will convert absolute dates and times in a dataset
into relative hours, suitable for Pmetrics analysis.  Additionally, the user has
the option to split subjects into pseudosubjects every time a dose reset (evid=4)
is encountered.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMmatrixRelTime(
  data,
  idCol = "id",
  dateCol = "date",
  timeCol = "time",
  evidCol = "evid",
  format = c("m/d/y", "h:m"),
  split = F
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] The name of an R data object.

\item[\code{idCol}] A character vector with the name
of the id column in \code{data} or the number of the id column, default is ``id''

\item[\code{dateCol}] A character vector with the name of the date
column in \code{data} or the number of the date column, default is ``date''

\item[\code{timeCol}] A character vector with the name of the time
column in \code{data} or the number of the time column, default is ``time''

\item[\code{evidCol}] A character vector with the name of the event id
column in \code{data} or the number of the evid column, default is ``evid''

\item[\code{format}] Format of the date and time columns; default is
m/d/y and h:m:s, as specified in the chron::chron function.
Note the separators in each case (/ for dates and : for times).
For dates, \emph{m} is months in digits and can be one or two digits;
\emph{d} is the day of the month, again as one or two digits;
\emph{y} is the year in 2 or 4 digits.  For times, all values can be one
or two digits, but time is in 24-hour format, and \emph{s} is required
to avoid ambiguity.

\item[\code{split}] If \emph{true}, \code{PMmatrixRelTime} will split every \code{id}
into id.block, where block is defined by a dose reset, or evid=4,
e.g. \code{id} 1.1, 1.2, 1.3, 2.1, 3.1, 3.2.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Returns a dataframe with columns [id, evid, relTime].
If \code{split}=T all evid values that were previously 4 will be converted to 1.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMreadMatrix}{PMreadMatrix}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{PMmb2csv}{Convert Old .mb or USC*PACK Files to .csv Matrix File}{PMmb2csv}
%
\begin{Description}\relax
\code{PMmb2csv} will convert old style, single drug .mb or USC*PACK files into
a single .csv matrix file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMmb2csv(oldFiles, newFile = "data")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{oldFiles}] A character vector of files in the current working directory to convert.
This could be easily obtained with \code{\LinkA{list.files}{list.files}}.

\item[\code{newFile}] A single character vector with the basename (without any file extension) of the new file to be created.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
IDs will be suffixed with .1 to .9 for <10 subjects, .01 to .99 for <100 subjects and .001 to .999 for <1000 subjects,
as needed to ensure unique ID numbers.
\end{Details}
%
\begin{Value}
A new file will be created with the name equal to \code{newFile} and
an extension of ``csv''.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMnews}{Pmetrics changelog}{PMnews}
%
\begin{Description}\relax
See changelog for Pmetrics
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMnews(version = packageVersion("Pmetrics"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{version}] Default is the current version, otherwise a character string with the starting version you wish to see up to 
the current, e.g. ``0.21''.  Use ``all'' for all versions.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The changelog for the requested version.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}
PMnews()
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{PMpatch}{Download and install Pmetrics patches}{PMpatch}
%
\begin{Description}\relax
Download and install Pmetrics patches from LAPK website
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMpatch()
\end{verbatim}
\end{Usage}
%
\begin{Value}
A Pmetrics patch which will be installed via \code{source}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMreadMatrix}{Read a Pmetrics .csv Matrix Input File}{PMreadMatrix}
%
\begin{Description}\relax
\code{PMreadMatrix} reads an NPAG .csv matrix input file into R.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMreadMatrix(
  file,
  skip = 1,
  sep = getPMoptions("sep"),
  dec = getPMoptions("dec"),
  quiet = F,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{file}] The name of the file to be loaded, including the full path if not
in the current working directory (check with \code{\LinkA{getwd}{getwd}}).

\item[\code{skip}] Skip \emph{n} lines, with default set to 1.

\item[\code{sep}] Delimiter between columns, which is a comma by default, but can be changed with
\code{\LinkA{setPMoptions}{setPMoptions}}.

\item[\code{dec}] Decimal separator, which is a period by default, but can be changed with
\code{\LinkA{setPMoptions}{setPMoptions}}.

\item[\code{quiet}] Default is \emph{false}.  If \emph{true}, there will be no report to
the console on the contents of file.

\item[\code{...}] Other parameters to be passed to \code{\LinkA{read.table}{read.table}}
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The structure of a valid .csv file is fairly rigid.  See \code{\LinkA{PMcheckMatrix}{PMcheckMatrix}}
for details.  Note that \code{PMreadMatrix} converts the column headers in the
\code{matrixfile} from upper to lowercase for convenient referencing in R.
\end{Details}
%
\begin{Value}
\code{PMreadMatrix} returns a data.frame of class ``PMmatrix'' with one row per
event and the following columns.  
\begin{ldescription}
\item[\code{id }] The id value for each event.
\item[\code{evid }] The evid value for each event, with 0=observation, 1=dose, 4=dose reset, which resets the time to 0 and all compartment amounts to 0.  Note that evid=2 and 3 are not currently implemented.
\item[\code{time }] Relative time of the event in hours.
\item[\code{dur }] Duration of the dose.  If dose is instantaneous, e.g. an oral dose into an absorptive compartment, \code{dur} should be 0.  Any values greater than 0 are interpreted to mean a constant infusion of that duration, equalling the \code{dose}.
\item[\code{dose }] The dose.  Be sure that the units are consistent with \code{out}.
\item[\code{addl }] Optional number of additional doses to add at an interval specified in \emph{ii}.  The default if missing is 0.  A value of -1
will cause steady state conditions to be approximated.  Any value for \emph{addl} other than 0 or missing requires input in \emph{ii}.
\item[\code{ii }] The interdose interval for \emph{addl} doses or dosing at steady state.
\item[\code{input }] The input number corresponding to \code{dose}.
\item[\code{out }] The measured output, equivalent to ``DV'' in some other PK modeling software tools.
\item[\code{outeq }] The number of the output equation specified in the model file which corresponds to the \code{out} value.
\item[\code{C0 }] Assay error polynomial coefficient, e.g. SD = C0 + C1*obs + C2*obs\textasciicircum{}2 + C3*obs\textasciicircum{}3
\item[\code{C1 }] See \code{C0}
\item[\code{C2 }] See \code{C0}
\item[\code{C3 }] See \code{C0}
\item[\code{... }] Additional columns are interpreted to be covariates.
\end{ldescription}
If the file is successfully read and \code{quiet}=F,
the column headers of the scanned file will be reported to the console as a validation check.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMwriteMatrix}{PMwriteMatrix}}, \code{\LinkA{PMcheckMatrix}{PMcheckMatrix}}, and \code{\LinkA{plot.PMmatrix}{plot.PMmatrix}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{PMreport}{Summarize NPAG or IT2B Run}{PMreport}
%
\begin{Description}\relax
Generates a summary of a Pmetrics NPAG or IT2B run
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMreport(wd, rdata, icen = "median", type = "NPAG", parallel = F)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{wd}] The working directory containing the NP\_RFxxxx.TXT or IT\_RFxxxx.TXT file

\item[\code{rdata}] The processed output of an IT2B or NPAG run, depending on local or server runs.

\item[\code{icen}] Median (default), mean or mode of Bayesian posterior to be used to calculate predictions.

\item[\code{type}] ``NPAG'' (default) or ``IT2B'' report type

\item[\code{parallel}] Boolean parameter which indicates the type of run done.  Default is \code{FALSE} for serial.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Creates an HTML page and several files summarizing an NPAG or IT2B run.  This report is generated
automatically at the end of a successful run.
\end{Details}
%
\begin{Value}
Several files are placed in the \code{wd}
\begin{ldescription}
\item[\code{NPAGreport.html or IT2Breport.html }] An .html file containing a summary of all the results
\item[\code{poppoints.csv }] NPAG only: A .csv file containing the population support points and probabilities
\item[\code{poparam.csv }] A .csv file containing a summary of the population parameter values, including
mean, standard deviation, coefficient of variation, variance, and median
\item[\code{popcor.csv }] A .csv file containing the population parameter correlation matrix
\item[\code{popcov.csv }] A .csv file containing the population parameter covariance matrix
\item[\code{cycle.pdf }] A .pdf file containing the run cycle information (see \code{\LinkA{plot.PMcycle}{plot.PMcycle}})
\item[\code{cycle.png }] A thumbnail of the run cycle information for the .html file
\item[\code{final.pdf }] A .pdf file containing the population final cycle information (see \code{\LinkA{plot.PMfinal}{plot.PMfinal}})
\item[\code{final.png }] A thumbnail of the population final cycle information for the .html file
\item[\code{opx.pdf }] One or more .pdf files, where \emph{x} is the number of the output equation, each containing
two observed vs. predicted plots: population and individual Bayesian posterior predictions (see \code{\LinkA{plot.PMop}{plot.PMop}})
\item[\code{opx.png }] One or more thumnails of the observed vs. predicted plots for the .html file
\item[\code{NPAGout.Rdata or IT2Bout.Rdata }] An R data file containing the output of \code{\LinkA{NPparse}{NPparse}} or \code{\LinkA{ITparse}{ITparse}}, \code{\LinkA{makeFinal}{makeFinal}},
\code{\LinkA{makeCycle}{makeCycle}}, \code{\LinkA{makeOP}{makeOP}}, \code{\LinkA{makeCov}{makeCov}}, \code{\LinkA{makePop}{makePop}}, \code{\LinkA{makePost}{makePost}}, and 
the data file for the run read by \code{\LinkA{PMreadMatrix}{PMreadMatrix}}.  
This file can be loaded using \code{\LinkA{PMload}{PMload}}.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMsave}{Save Pmetrics objects}{PMsave}
%
\begin{Description}\relax
Saves Pmetrics objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMsave(run, ..., quiet = F)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{run}] The numerical value of the run number of the objects to be saved.
This parameter must be specified, as it also determines where to save the revised output.

\item[\code{...}] Additional objects to be saved, which do not need to be suffixed with the run number,
e.g. var1, var2, var3.

\item[\code{quiet}] Suppress written report.  Default is \code{FALSE}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Any objects that are made during the course of analysis in R can be added to the saved data
that are automatically generated at the end of an NPAG or IT2B run and loaded with \code{\LinkA{PMload}{PMload}}.
Objects with the same run number will be saved as a group.  So if a user has made a new object called
lm.1 that contains regressions related to run 1, it will be saved with any other object
that also has .1 at the end. 

Additionally, other objects can be saved via the \dots argument.  For exmaple PMsave(1,lm) will
save any object with .1 at the end, plus an object named "lm".  All objects will be suffixed
with the run number when loaded back with \code{\LinkA{PMload}{PMload}}.
\end{Details}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMload}{PMload}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{PMstep}{Stepwise covariate-parameter regressions}{PMstep}
%
\begin{Description}\relax
Perform a stepwise linear regression on all covariates and Bayesian posterior parameters
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMstep(x, icen = "median", direction = "backward")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A PMcov object loaded by \code{\LinkA{PMload}{PMload}}
or made by \code{\LinkA{makeCov}{makeCov}}.

\item[\code{icen}] A character vector to summarize covariate values.  Default is ``median'', but can also be 
``mean''.

\item[\code{direction}] The direction for covariate elmination can be ``backward'', ``forward'', or ``both''.
\emph{backward} is the default.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will perform stepwise linear regressions on a PMcov object loaded by \code{\LinkA{PMload}{PMload}},
or made by \code{\LinkA{makeCov}{makeCov}}.  Every covariate in the model will be tested in a stepwise linear regression for their relationships
to each parameter in the model.  Bayesian posterior parameters and individual covariates are used.
\end{Details}
%
\begin{Value}
A matrix with covariates in the rows and parameters in the columns.  Values for the matrix are the multi-variate P-values.
A value of \code{NA} indicates that the variable was not retained in the final model.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{step}{step}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{PMtree}{Create a new Pmetrics folder tree}{PMtree}
%
\begin{Description}\relax
Sets up a directory tree for a new Pmetrics project
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMtree(project = "NewProject", folder = getwd())
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{project}] A character string of a new project name, e.g. "DrugX"

\item[\code{folder}] The full path to the root folder for the new project.  Default is the
current working directory.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will create a new project folder tree with appropriate subfolders and a skeleton R script.
\end{Details}
%
\begin{Value}
A new folder named \code{project} with the following subfolders:
\begin{ldescription}
\item[\code{Rscript }] The folder for the Rscript containing all run instructions.
Within this folder will be a skeleton R script for the project.
\item[\code{Runs }] The folder for all Pmetrics runs.  Put run files, i.e. a data file and a
model file in this directory prior to each run.
\item[\code{Sim }] The folder for all simulations related to the project.
\item[\code{src }] The folder for source data files in their original format, to preserve
integrity and for audit purposes.
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMmanual}{PMmanual}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
PMtree("DrugX")
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{PMupdate}{Download and install Pmetrics updates}{PMupdate}
%
\begin{Description}\relax
Download and install Pmetrics updates from LAPK website
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMupdate(force = F)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{force}] Boolean operator to force downloading and installing.  Default is false.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
The latest system-specific Pmetrics update will be downloaded to a temporary
folder and then installed.  You need to restart R (Rstudio) and then reload Pmetrics with
the \code{library(Pmetrics)} command to complete the installation.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{PMwriteMatrix}{Write a Pmetrics .csv Matrix File}{PMwriteMatrix}
%
\begin{Description}\relax
\code{PMwriteMatrix} is the companion function to \code{\LinkA{PMreadMatrix}{PMreadMatrix}}.
It will write an appropriate R data object to a formatted .csv file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMwriteMatrix(data, filename, override = F, version = "DEC_11")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] Must be a data.frame with appropriate structure (see \code{\LinkA{PMcheck}{PMcheck}}.

\item[\code{filename}] Name of file to create.

\item[\code{override}] Boolean operator to write even if errors are detected.  Default is \code{False}.

\item[\code{version}] Which matrix data format version to write.  Default is the current version.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{PMwriteMatrix} will first run \code{\LinkA{PMcheck}{PMcheck}} to determine
if there are any errors in the structure of  \code{data}.  If the error check
fails, the file will not be written and a message will be printed on the console.
\end{Details}
%
\begin{Value}
Returns the error report (see \code{\LinkA{PMcheck}{PMcheck}} for details).
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMcheck}{PMcheck}}, \code{\LinkA{PMreadMatrix}{PMreadMatrix}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
data <- PMreadMatrix(paste(.libPaths(),"/Pmetrics/example/NPAG/PMex1.csv",sep=""))
data
#write to the current directory
PMwriteMatrix(data,"PMex1.csv")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{PMwrk2csv}{Convert Old .wrk Files to .csv Matrix File}{PMwrk2csv}
%
\begin{Description}\relax
\code{PMwrk2csv} will convert old style, single drug working copy files into
a single .csv matrix file.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
PMwrk2csv(prefix, ext = NULL, nsub)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{prefix}] The alphabetic prefix of the working copy files to be converted,
as a character vector.

\item[\code{ext}] The extension of the working copy files files, if it exists.
Does not have to be specified.

\item[\code{nsub}] The number of subjects, or working copy files to read.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will determine if the working copy files are old and convert them.
New, multi-drug working copy files will be ignored. IDs will be suffixed with
.1 to .9 for <10 subjects, .01 to .99 for <100 subjects and .001 to .999 for <1000 subjects,
as needed to ensure unique ID numbers.
\end{Details}
%
\begin{Value}
A new file will be created with the name equal to \code{prefix} and
an extension of ``csv''.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{print.gof.test}{Prints a summary of a gof.test result}{print.gof.test}
%
\begin{Description}\relax
Prints a summary of a gof.test result
\end{Description}
%
\begin{Usage}
\begin{verbatim}
print.gof.test(object, which = "npde", ...)
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{print.MMopt}{Print Pmetrics Multiple-Model Optimal Sampling Objects}{print.MMopt}
%
\begin{Description}\relax
Print \emph{MMopt} objects
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'MMopt'
print(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The name of an \emph{MMopt} data object generated by \code{\LinkA{MMopt}{MMopt}}
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Simulated observations are plotted on the y-axis vs. time on the x.axis.  
Optimal sampling times are indicated as vertical lines.
\end{Details}
%
\begin{Value}
Prints the optimal sampling times and Bayes Risk.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{MMopt}{MMopt}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{print.PMdopt}{Print PMdopt}{print.PMdopt}
%
\begin{Description}\relax
Print a Pmetrics PMdopt Object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMdopt'
print(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A PMdopt object made by \code{\LinkA{Dopt}{Dopt}}.

\item[\code{...}] Other parameters which are not necessary.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Print a Pmetrics D-optimal object, made by \code{Dopt}.
\end{Details}
%
\begin{Value}
A printed object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{Dopt}{Dopt}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{print.PMerr}{Print Data Errors}{print.PMerr}
%
\begin{Description}\relax
Print a Pmetrics Error Object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMerr'
print(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A PMerr object made by \code{\LinkA{PMcheckMatrix}{PMcheckMatrix}}.

\item[\code{...}] Other parameters which are not necessary.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Print the errors in a Pmetrics data file or PMmatrix object.
\end{Details}
%
\begin{Value}
A printed object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{PMcheckMatrix}{PMcheckMatrix}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{print.PMnpc}{Print NPC}{print.PMnpc}
%
\begin{Description}\relax
Print a Pmetrics NPC Object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMnpc'
print(x, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A PMnpc object made by \code{\LinkA{plot.PMsim}{plot.PMsim}}.

\item[\code{...}] Other parameters which are not necessary.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Print a Pmetrics NPC (Numerical Predictive Check) object, made by \code{plot.PMsim}.
\end{Details}
%
\begin{Value}
A printed object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{plot.PMsim}{plot.PMsim}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{print.summary.PMmatrix}{Summarize Covariates and Bayesian Posterior Parameter Values}{print.summary.PMmatrix}
%
\begin{Description}\relax
Print the summary of a Pmetrics PMmatrix object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'summary.PMmatrix'
print(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A summary.PMmatrix object made by \code{\LinkA{summary.PMmatrix}{summary.PMmatrix}}
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Summarize the raw data used for a Pmetrics run.
\end{Details}
%
\begin{Value}
A formatted printing of a \emph{summary.PMmatrix} object
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{summary.PMmatrix}{summary.PMmatrix}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{print.summary.PMop}{Print Summary of Observations and Predictions}{print.summary.PMop}
%
\begin{Description}\relax
Print a Pmetrics Observed vs. Predicted Summary Object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'summary.PMop'
print(x, digits = max(3, getOption("digits") - 3), ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A summary.PMop object made by \code{\LinkA{summary.PMop}{summary.PMop}}.

\item[\code{digits}] Integer, used for number of digits to print.

\item[\code{...}] Other parameters which are not necessary.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Print a summary of observations, predictions and errors in a summary.PMop object made by \code{\LinkA{summary.PMop}{summary.PMop}}.
\end{Details}
%
\begin{Value}
A printed object.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{summary.PMop}{summary.PMop}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{qgrowth}{Extract CDC pediatric growth charts}{qgrowth}
%
\begin{Description}\relax
Will extract height and weight for boys, girls or both for a given range of ages in months and percentile. This can be useful for 
simulations in Pmetrics.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
qgrowth(
  sex = c("M", "F", "B"),
  percentile = c("5", "10", "25", "50", "75", "90", "95"),
  agemos = (seq(0, 18) * 12)
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{sex}] A single quoted character: ``M'' for males, ``F'' for females, or ``B'' for both, in which case an average
of the two sexes will be returned.  Default is ``M''.

\item[\code{percentile}] An integer of the percentile for each age/sex to return.  Default is 5.

\item[\code{agemos}] The ages in months to return.  The default is \code{seq(0,18)*12}, i.e. 1 to 18 years.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
A dataframe with columns
\begin{ldescription}
\item[\code{age }] Age in months
\item[\code{wt }] Weight in kilograms
\item[\code{ht }] Height or length in centimeters
\item[\code{sex }] The selected \code{sex}
\item[\code{percentile }] The selected \code{percentile}
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{set.plotoptions}{Set graphical preferences}{set.plotoptions}
\aliasA{set.plotoptions,NpdeData-method}{set.plotoptions}{set.plotoptions,NpdeData.Rdash.method}
\aliasA{set.plotoptions,NpdeObject-method}{set.plotoptions}{set.plotoptions,NpdeObject.Rdash.method}
\aliasA{set.plotoptions.NpdeData}{set.plotoptions}{set.plotoptions.NpdeData}
\aliasA{set.plotoptions.NpdeObject}{set.plotoptions}{set.plotoptions.NpdeObject}
\keyword{plot}{set.plotoptions}
%
\begin{Description}\relax
This function is used to set options for graphs
\end{Description}
%
\begin{Usage}
\begin{verbatim}
set.plotoptions(object, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] an object of class NpdeData or NpdeObject

\item[\code{...}] arguments to replace default arguments (currently ignored)
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
See documentation for a list of available options.
\end{Details}
%
\begin{Value}
a list of options for graphs
\end{Value}
%
\begin{Author}\relax
Emmanuelle Comets <emmanuelle.comets@bichat.inserm.fr>
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{npde}{npde}}, \code{\LinkA{autonpde}{autonpde}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{setPMoptions}{Set Pmetrics User Options}{setPMoptions}
%
\begin{Description}\relax
Set user options for Pmetrics
\end{Description}
%
\begin{Usage}
\begin{verbatim}
setPMoptions(sep, dec, server_address)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{sep}] The field separator character; ``,'' by default, but could be ``;''

\item[\code{dec}] The decimal separator character; ``.'' by default, but could be ``,''
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function will set user options for Pmetrics.
\end{Details}
%
\begin{Value}
The user preferences file will be updated.  This will persist from session to session.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{showall}{Brief summary of an object}{showall}
\aliasA{showall,NpdeData-method}{showall}{showall,NpdeData.Rdash.method}
\aliasA{showall,NpdeSimData-method}{showall}{showall,NpdeSimData.Rdash.method}
\aliasA{showall.NpdeData}{showall}{showall.NpdeData}
\aliasA{showall.NpdeObject}{showall}{showall.NpdeObject}
\aliasA{showall.NpdeRes}{showall}{showall.NpdeRes}
\aliasA{showall.NpdeSimData}{showall}{showall.NpdeSimData}
\keyword{print}{showall}
%
\begin{Description}\relax
Prints a brief summary of an object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'NpdeData'
showall(object)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] an object
\end{ldescription}
\end{Arguments}
\inputencoding{utf8}
\HeaderA{SIMparse}{Parse Pmetrics Simulator Output}{SIMparse}
%
\begin{Description}\relax
Parses the output of the Pmetrics simulator
\end{Description}
%
\begin{Usage}
\begin{verbatim}
SIMparse(file, include, exclude, combine = F, silent = F, parallel)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{file}] An output file or files of the simulator in the current working directory, or the full
pathname to the file.  To load and combine multiple outputs, specify files separated by commas
or using wild cards.  See details.

\item[\code{include}] A vector of files to include in the parsing.  For example, if you used a wild
card in the \code{file} argument, such as ``simout?.txt'', which returned four files:
simout1.txt, simout2.txt, simout3.txt and simout4.txt, and you wished to only parse the first
and fourth file, specify \code{include=c(1,4)}.

\item[\code{exclude}] See the discussion for \code{include}, but this will exclude specified files.

\item[\code{combine}] Boolean parameter, default \code{False}, which specifies whether you wish to combine
the parsed files into a single PMsim object.  This can be useful for making visual predictive
checks, for example.  If \code{combine=F}, and multiple files are parsed, then the return object 
will be a list of PMsim objects, which can be plotted or otherwise accessed using standard list
referencing, e.g. simlist[[1]], simlist[[2]], etc.

\item[\code{silent}] Suppress messages

\item[\code{parallel}] Runs in parallel mode.  Defaults to true if multiple files are to be parsed, otherwise false.
Can be overridden by specifying \code{TRUE} or \code{FALSE}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
For \code{file} specification ``?'' will be matched by just a single numeral or character; ``*'' will be
matched by any number of consecutive alphanumeric characters.  Examples include \code{file='simout1.txt,simout2.txt,simout3.txt'},
\code{file='simout?.txt'} and \code{file='sim*.txt'}.All three will find the files simout1.txt,
simout2.txt, and simout3.txt in the working directory. The second example would also find simout4.txt, etc.  The third 
example would also find sim\_1.txt if that existed. 
Note that to combine simulator output files, the numbers of simulated profiles may differ.
The number of outputs and times of observations also may differ, although combining these may lead to
strange plots since not all profiles have the same observations. 
For parallel execution, the function requires packages 'doParallel' and 'foreach'. If not installed, it will try to install, failing that it will run in serial mode.
\end{Details}
%
\begin{Value}
If one file is parsed or multiple files are parsed and combined, the return will be a list with five items, of class \emph{PMsim}.
If multiple files are parsed and not combined, then the return will be a list of \emph{PMsim} objects.
\begin{ldescription}
\item[\code{obs }] An data frame of simulated observations with 4 columns: id, time, out, outeq.
\emph{id} is the number of the simulated subject, which will have a unique ending appended
if simulations are combined, such that \emph{id} will become x.y with x being the simulated profile
number and y being the simulation template number.  \emph{time} is the time of the simulated
output, \emph{out} of output equation number \emph{outeq}.
\item[\code{amt }] An data frame of simulated amounts with 4 columns: id, time, out, comp.
\emph{id} is the number of the simulated subject, which will have a unique ending appended
if simulations are combined, such that \emph{id} will become x.y with x being the simulated profile
number and y being the simulation template number.  \emph{time} is the time of the simulated
amount, \emph{out} in compartment  number \emph{comp}.
\item[\code{parValues }] A datframe of the simulated parameter values, combined across files as necessary
\item[\code{totalSets}] The total number of parmeter sets simulated, which may be greater than the number of rows in \code{parValues} if some sets
were discarded for being outside specified limits.  For more than one file parsed, this will the total number in all files.
\item[\code{totalMeans}] The means of each simulated parameter based on all profiles in a given file (even those discarded for exceeding limits).
For more than one file parsed, this will be the weighted averages for all simulations.
\item[\code{totalCov}] The covariances of the simulated parameter sets based on all profiles in a given file (even those discarded for exceeding limits).
For more than one file parsed, this will be the weighted averages for all simulations.
\end{ldescription}
A plot method exists in \code{\LinkA{plot.PMsim}{plot.PMsim}} for \emph{PMsim} objects.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{SIMrun}{SIMrun}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{SIMrun}{Run the Pmetrics Simulator}{SIMrun}
%
\begin{Description}\relax
Runs the Pmetrics simulator
\end{Description}
%
\begin{Usage}
\begin{verbatim}
SIMrun(
  poppar,
  limits = NULL,
  model = "model.txt",
  data = "data.csv",
  split,
  include,
  exclude,
  nsim = 1000,
  predInt = 0,
  covariate,
  usePost = F,
  seed = -17,
  ode = -4,
  obsNoise,
  doseTimeNoise = rep(0, 4),
  doseNoise = rep(0, 4),
  obsTimeNoise = rep(0, 4),
  makecsv,
  outname,
  clean = T,
  silent = F,
  nocheck = F,
  overwrite = F
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{poppar}] Either an object of class \emph{PMfinal} (see \code{\LinkA{makeFinal}{makeFinal}})
or a list containing three items in this order, but of any name: vector of weights, vector of mean parameter values, and a covariance matrix.
If only one distribution is to be specified the \code{weights} vector should be of length 1 and contain a 1.
If multiple distributions are to be sampled, the \code{weights} vector should be of length equal to the number
of distributions and its values should sum to 1, e.g. \code{c(0.25,0.05,0.7)}.  The means matrix may be a vector for a single
distribution, or a matrix with \code{length(weights)} rows and number of columns equal to the number of parameters, \emph{npar}.
The covariance matrix will be divided by \code{length(weights)} and applied to each distribution.

\item[\code{limits}] If limits are specified, each simulated parameter set that contains a value outside of the limits 
will be ignored and another set will be generated.  Four options exist for limits.  1) The default \code{NULL} 
indicates that no limits are to be applied to simulated parameters.   
2) The second option is to set \code{limits} to \code{NA}. This will use the parameter limits on the 
primary parameters that are specified in the model file.  
3) The third option is a numeric vector of length 1 or 2, e.g. 3 or c(0.5,4), which specifies what to multiply the
columns of the limits in the model file.  If length 1, then the lower limits will be the same as in the model file, and
the upper limits will be multiplied by value specified.  If length 2, then the lower and upper limits will be multiplied
by the specified values.  If this option is used, \code{popppar} must be a \code{PMfinal} object.
4) The fourth option for limits is a fully customized matrix of limits for simulated values for each parameter which will
overwrite any limits in the model file.  If specified, it should be a data.frame or matrix with number of rows equal to the number
of random paramters and 2 columns, corresponding to the minimum and maximum values.  For example, a final\$ab object, or a directly coded
matrix, e.g. matrix(c(0,5,0,5,0.01,100),nrow=3,ncol=2,byrow=T) for 3 parameters
with limits of [0,5], [0,5] and [0.01,100], respectively.  It is possible to convert a parameter to fixed by omitting
the second limit.   Means and covariances of the total number of simulated sets
will be returned to verify the simulation, but only those sets within the specified limits will be used to generate output(s) and the means and covariances of the
retained sets may (and likely will be) different than those specified by \code{poppar}.

\item[\code{model}] Name of a suitable model file template in the working directory.
The default is ``model.txt''.  This file will be converted to a fortran model file.
If it is detected to already be a fortran file, then the simulation will proceed without any further
file conversion.

\item[\code{data}] Either a PMmatrix object previously loaded with (\code{\LinkA{PMreadMatrix}{PMreadMatrix}}) or character vector with the filename of a Pmetrics matrix file
that contains template regimens and observation times.  The value for outputs can be coded as
any number(s) other than -99.  The number(s) will be replaced in the simulator output with the simulated values.

\item[\code{split}] Boolean operator controlling whether to split an NPAG \emph{PMfinal} object into one distribution
per support point, with means equal to the vector of parameter values for that point, and covariance equal to
the population covariance divided by the number of support points.  Default for NPAG \emph{PMfinal} objects is \code{TRUE}, otherwise \code{FALSE}

\item[\code{include}] A vector of subject IDs in the \code{matrixfile} to iterate through, with each subject
serving as the source of an independent simulation.  If missing, all subjects in the datafile will be used.

\item[\code{exclude}] A vector of subject IDs to exclude in the simulation, e.g. c(4,6:14,16:20)
If a \emph{makecsv} filename is supplied, ID numbers will be of the form nsub.nsim, e.g. 1.001 through 1.1 for the
first subject, 2.001 through 2.1 for the second subject, etc. if 1000 simulations are made from each subject.

\item[\code{nsim}] The number of simulated profiles to create, per subject.  Default is 1000.  Entering 0 will result in one profile being simulated from each
point in the non-parametric prior (for NPAG final objects only).

\item[\code{predInt}] The interval in fractional hours for simulated predicted outputs at times other than those specified in the template \code{data}.
The default is 0, which means there will be simulated outputs only at times specified in the data file (see below).  Values of predInt > 0 result in simulated
outputs at the specified value of predInt, e.g. every 15 minutes for predInt = 0.25 from time 0 up 
to the maximal time in the template file, per subject if nsub > 1.  You may also specify \code{predInt}
as a vector of 3 values, e.g. \code{c(1,4,1)}, similar to the R command \code{\LinkA{seq}{seq}}, where the
first value is the start time, the second is the stop time, and the third is the
step value.  Finally, you can have multiple such intervals by specifying \code{predInt} as a list of such
vectors, e.g. \code{list(c(0,24,1),c(72,96,1))}.  Outputs for times specified in the template file will also be simulated.
To simulate outputs \emph{only} at the output times in the template data (i.e. EVID=0 events), use \code{predInt=0}, which is the default.
Note that the maximum number of predictions total is 594, so the interval must be sufficiently large to accommodate this for a given
number of output equations and total time to simulate over.  If \code{predInt} is set so that this cap is exceeded, predictions will be truncated.

\item[\code{covariate}] If you are using the results of an NPAG or IT2B run to simulate, i.e. a \emph{PMfinal} object as \code{poppar}, 
then you can also simulate with covariates. This argument is a list with the following names.
\begin{itemize}

\item{} \code{cov} The name of a PMcov object, such as that loaded with PMload. 
Pmetrics will use this object to calculate the correlation matrix between all covariates and Bayesian posterior parameter values.
\item{} \code{mean} A named list that allows you to specify a different mean for one or more of the covariates. Each named item in the list is 
the name of a covariate in your data that is to have a different mean. If this argument is missing then the mean covariate values in 
the population will be used for simulation. The same applies to any covariates that are not named in this list.  Example: \code{covariate=list(cov=cov.1,mean=list(wt=50))}.
\item{} \code{sd} This functions just as the \code{mean} list argument does - allowing you to specify different standard deviations for covariates in the simulation. 
If it, or any covariate in the \code{sd} list is missing, then the standard deviations of the covariates in the population are used. Example: \code{covariate=list(cov=cov.1,sd=list(wt=10))}
\item{} \code{limits} This is a bit different than the limits for population parameters above.
Here, \code{limits} is similar to \code{mean} and \code{sd} for covariates in that it is 
a named list with the minimum and maximum allowable simulated values for each covariate.  If it is
missing altogether, then no limits will apply.  If it is specified, then named covariates will have the
indicated limits, and covariates not in the list will have limits that are the same as in the
original population.  If you want some to be limited and some to be unlimited, then specify the
unlimited ones as items in this list with very large ranges.  Example: \code{covariate=list(cov=cov.1,limits=list(wt=c(10,70)))}
\item{} \code{fix} A character vector (not a list) of covariates to fix and not simulate.  In this case
values in the template data file will be used and not simulated.  Example: c(``wt'', ``age'')

\end{itemize}
 
Whether you use the means and standard deviations in the population 
or specify your own, the covariance matrix in poppar will be augmented by the covariate covariances for any non-fixed covariates. 
The parameter plus covariate means and this augmented covariance matrix will be used for simulations. 
In effect, all non-fixed covariates are moved into the \#Primary block of the model file to become parameters that are simulated. 
In fact, a copy of your model file is made with a ``c'' prepended to the model name (e.g. ``model.txt'' -> ``c\_model.txt'').

\item[\code{usePost}] Boolean argument.  Only applicable when \code{poppar} is an NPAG \emph{PMfinal} object.
If so, and \code{usePost} is \code{TRUE}, the posterior for each subject (modified by \code{include} or \code{exclude}) in \code{poppar} 
will be used to simulate rather than the population prior.  The number of subjects in the template \code{data} file
must be the same.  Normally one would use the same data file as used to make the model final parameter distribution in \code{poppar},
but if different templates are desired, the number must be equivalent to the number of included subjects from whom the posteriors are obtained.

\item[\code{seed}] The seed for the random number generator.  For \code{nsub} > 1, should be a vector of length equal to \code{nsub}.
Shorter vectors will be recycled as necessary.  Default is -17.

\item[\code{ode}] Ordinary Differential Equation solver log tolerance or stiffness.  Default is -4, i.e. 0.0001.  Higher values will result in faster
runs, but simulated concentrations may not be as accurate.

\item[\code{obsNoise}] The noise added to each simulated concentration for each output equation, where the noise
is randomly drawn from a normal distribution with mean 0 and SD = C0 + C1*conc + C2*conc\textasciicircum{}2 + C3*conc\textasciicircum{}3.
Default values are 0 for all coefficients (i.e.) no noise. If present will override any other values in the data file or model file.
Specify as a vector of length 4 times the number of output equations, e.g.
c(0.1,0.1,0,0) for one output and c(0.1,0.1,0,0,0.01,0.2,-0.001,0) for two output equations.
If specified as \code{NA}, values in the data file will be used (similar to \code{limits}, above).  If they are missing, values in the model file
will be used.

\item[\code{doseTimeNoise}] A vector of length four to specify dose time error polynomial coefficients.  The default is 0 for all coefficients.

\item[\code{doseNoise}] A vector of length four to specify dose amount error polynomial coefficients.  The default is 0 for all coefficients.

\item[\code{obsTimeNoise}] A vector of length four to specify observation timing error polynomial coefficients.  The default is 0 for all coefficients.

\item[\code{makecsv}] A character vector for the name of the single .csv file to be made for all simulated
``subjects''.  If missing, no files will be made.

\item[\code{outname}] The name for the output file(s) without an extension.  Numbers 1 to \code{nsub} will be appended to the files.
If missing, will default to ``simout''.

\item[\code{clean}] Boolean parameter to specify whether temporary files made in the course of the simulation run should
be deleted. Defaults to \code{True}.  This is primarily used for debugging.

\item[\code{silent}] Boolean operator controlling whether a model summary report is given.  Default is \code{FALSE}.

\item[\code{nocheck}] Suppress the automatic checking of the data file with \code{\LinkA{PMcheck}{PMcheck}}.  Default is \code{FALSE}.

\item[\code{overwrite}] Cleans up any old output files without asking before creating new output. Default is \code{FALSE}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The Monte Carlo simulator in Pmetrics is a powerful tool for parametric or semi-parametric
sampling.  NPAG or IT2B final objects can easily be used as the prior distributions for 
sampling, or prior distributions may be manually specified.  Prior distributions may be
unimodal-multivariate (parametric sampling), or multimodal-multivariate (semi-parametric sampling).
For priors from NPAG, this can easily be accomplished with the \code{split} argument. 

It is also possible to simulate with covariates if they are included as part of the model.
By specifying a covariate list argument, Pmetrics will first calculate the correlation matrix
between the covariates and the Bayesian posterior parameter values for each subject in the population
model.  Using either the mean and standard deviation of each covariate in the population, 
or a user-specified mean and/or standard deviation, Pmetrics will then calculate an augmented 
covariance matrix to be used in simulations.  Pmetrics will make a copy of the model file with all
covariates moved into the primary block as parameters to be simulated.  

Noise can be applied to the simulated observations. Noise may also be applied to
the observation times, to the dose times, or to the dose amounts.  

Limits on the simulated parameter sets can also be specified using the limits on primary parameters in 
the model file or by specifying them manually as an argument. Limits can also be applied to simulated 
covariates. 

It is permissible to fix a parameter for simulation that was a random parameter in the model prior by 
changing the range in the model file to a single value for that parameter.

The same model and data file strutures are used for the simulator as for any other
Pmetrics functions.  In this case, the data file will serve as the template for the information 
regarding dosing, covariate values, and observations.  Template data files may have more than one
subject in them, in which case the simulator will use each subject specified by the \code{include}
argument (default is all subjects) to generate \code{nsim} parameter sets and corresponding
observations.  

Simulator output is directed to text files, one for each template subject, which can be 
read back into R by \code{link\{SIMparse\}}.  Output may also be directed to a new Pmetrics
.csv data file using the \code{makecsv} argument.
\end{Details}
%
\begin{Value}
No value is returned, but simulated file(s) will be in the working directory.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{SIMparse}{SIMparse}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
wd <- getwd()
#make 1 lognormal distribution for each parameter
weights <- 1
mean <- log(c(0.7,0.05,100))
cov <- matrix(rep(0,length(mean)**2),ncol=length(mean))
diag(cov) <- (c(0.15,0.15,0.15)*mean)**2
#make the prior for the simulation
poppar <- list(weights,mean,cov)
setwd(paste(normalizePath(get("PmetricsPath",envir=PMenv),winslash="/"),"/Pmetrics/example/Sim",sep=""))
#run simulation
SIMrun(poppar,"temp1.csv",nsim=15,model="model1.for",obsNoise=c(0.02,0.1,0,0),makecsv="PMex1.csv",outname="example",clean=T)
#extract results of simulation
simout <- SIMparse("example1.txt")
file.remove("example1.txt")
#plot simulated profiles (use help(plot.PMsim) for more information)
plot(simout,ci=0,probs=NA,x.qlab=0.75,log=T,col="red",lwd=2,pch=NA,join=T)
setwd(wd)

## End(Not run)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{skewness}{Skewness}{skewness}
\keyword{univar}{skewness}
%
\begin{Description}\relax
Computes the skewness.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
skewness(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] a numeric vector containing the values whose skewness is to be
computed. NA values are removed in the computation.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
If \eqn{N = \mathrm{length}(x)}{}, then the skewness of \eqn{x}{}
is defined as \deqn{N^{-1} \mathrm{sd}(x)^{-3} \sum_i (x_i -
\mathrm{mean}(x))^3.}{}
\end{Details}
%
\begin{Value}
The skewness of \code{x}.
\end{Value}
%
\begin{References}\relax
G. Snedecor, W. Cochran. \emph{Statistical Methods}, 
Wiley-Blackwell, 1989
\end{References}
%
\begin{Examples}
\begin{ExampleCode}

x <- rnorm(100)
skewness(x)

\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{ss.PK}{Sample size calculations for Phase 1 PK study design}{ss.PK}
%
\begin{Description}\relax
This function calculates sample size based on a desired standard error of the mean,
to a specified confidence, for a given mean and standard deviation.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ss.PK(n, mean, sd, precision, ci = 0.95)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{n}] Sample size.  This value can be missing if sample size is desired, or 
specified to calculate the maximum sd for given \code{mean}, \code{precision}, and \code{ci}.

\item[\code{mean}] Mean prameter value.  User value is mandatory.

\item[\code{sd}] Standard deviation of parameter values.  If present, the function will return \code{n}.
If missing and \code{n} is specified, will return the maximum sd as detailed above.

\item[\code{precision}] Desired width of the standard error of the mean (SEM).  Default is 0.2, i.e. 20\% or
10\% below and 10\% above the mean.  If missing, and \code{mean}, \code{sd} and \code{n} are specified,
\code{precision} will be calculated.

\item[\code{ci}] Confidence for the desired width of the SEM.  Default is 0.95.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The formula is n = qnorm((1+ci)/2)**2 * sd**2 / (precision*mean)**2
\end{Details}
%
\begin{Value}
The missing argument: \code{n}, \code{sd} or \code{precision}.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
\inputencoding{utf8}
\HeaderA{summary.PMcov}{Summarize Covariates and Bayesian Posterior Parameter Values}{summary.PMcov}
%
\begin{Description}\relax
Summarize a Pmetrics Covariate object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMcov'
summary(x, icen = "median")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A PMcov object made by \code{\LinkA{makeCov}{makeCov}}.

\item[\code{icen}] Summary function for covariates and posterior parameters. Default is ``median'', but can specify ``mean''.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Summarize covariates and Bayesian posterior parameter values for each subject.
\end{Details}
%
\begin{Value}
A data frame with the summary of the PMcov object for each subject's covariates and 
Bayesian posterior parameter values.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeCov}{makeCov}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{summary.PMdopt}{Summarize PMdopt objects}{summary.PMdopt}
%
\begin{Description}\relax
Summarize a Pmetrics D-optimal object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMdopt'
summary(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A PMdopt object made by \code{\LinkA{Dopt}{Dopt}}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Summarize observations, predictions and errors in a PMdopt object made by \code{\LinkA{Dopt}{Dopt}}.
\end{Details}
%
\begin{Value}
The weighted mean D-optimal times.
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeOP}{makeOP}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{summary.PMfinal}{Summary Statistics for PMfinal Objects}{summary.PMfinal}
%
\begin{Description}\relax
Generates summary statistics of final population model parameters.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMfinal'
summary(x, lower = 0.025, upper = 0.975)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] The PMfinal object made after an NPAG or IT2B, e.g. final.1 after run 1.

\item[\code{lower}] Desired lower confidence interval boundary.  Default is 0.025. Ignored for IT2B objects.

\item[\code{upper}] Desired upper confidence interval boundary.  Default is 0.975. Ignored for IT2B objects.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
For NPAG runs, this function will generate weighted medians as central tendencies of the
population points with a 95\% confidence interval (95\% CI) around the median, 
and the median absolute weighted deviation (MAWD) from the median as a measure 
of the variance, with its 95\% CI.  These estimates correspond to weighted mean, 
95\% CI of the mean, variance, and 95\% CI of the variance, respectively, for a 
sample from a normal distribution.  To estimate these non-parametric summaries, 
the function uses a Monte Carlo simulation approach, creating  1000 x npoint samples 
with replacement from the weighted marginal distribution of each parameter, 
where npoint is the number of support points in the model.  As an example, 
if there are 100 support points, npoint = 100, and for Ka, there will be 
1000 sets of 100 samples drawn from the weighted marginal distribution of the 
values for Ka.  For each of the 1,000 sets of npoint values, the median and MAWD are 
calculated, with MAWD equal to the median absolute difference between each point 
and the median of that set.  The output is npoint estimates of the weighted median 
and npoint estimates of the MAWD for each parameter, from which the median, 2.5th, 
and 97.5th percentiles can be found as point estimates and 95\% confidence 
interval limits, respectively, of both the weighted median and MAWD.

For IT2B runs, the function will return the mean and variance of each parameter,
and the standard errors of these terms, using SE (mean) = SD/sqrt(nsub) and 
SE (var) = var * sqrt(2/(nsub-1)).
\end{Details}
%
\begin{Value}
The output is a data frame.
For NPAG this has 4 columns:
\begin{ldescription}
\item[\code{value }] The value of the summary statistic
\item[\code{par }] The name of the parameter
\item[\code{type }] Either \emph{WtMed} for weighted median, or \emph{MAWD} for MAWD (see details)
\item[\code{quantile }] Requested \code{lower}, 0.5 (median), and \code{upper} quantiles
\end{ldescription}
For IT2B this has 5 columns:
\begin{ldescription}
\item[\code{mean }] Parameter mean value
\item[\code{se.mean }] Standard error of the mean
\item[\code{cv.mean }] Error of the mean divided by mean
\item[\code{var }] Variance of the parameter values
\item[\code{se.var }] Standard error of the variance
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeFinal}{makeFinal}}, \code{\LinkA{ITparse}{ITparse}},  \code{\LinkA{plot.PMfinal}{plot.PMfinal}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
data(PMex1)
final <- makeFinal(NPdata.1)
summary(final)
\end{ExampleCode}
\end{Examples}
\inputencoding{utf8}
\HeaderA{summary.PMmatrix}{Summarize PMmatrix objects}{summary.PMmatrix}
%
\begin{Description}\relax
Summarize a Pmetrics PMmatrix object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMmatrix'
summary(x, formula, FUN, ..., include, exclude)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A PMmatrix object loaded by \code{\LinkA{PMreadMatrix}{PMreadMatrix}} or \code{\LinkA{PMload}{PMload}}.

\item[\code{formula}] Optional formula for specifying custom summaries.  See \code{\LinkA{aggregate}{aggregate}}
and \code{\LinkA{formula}{formula}} for details on how to specify formulae in R. If, for example, the data contain
a covariate for weight named 'wt', then to summarize the mean dose in mg/kg per subject specify 
\code{formula=dose/wt\textasciitilde{}id, FUN=mean}.

\item[\code{FUN}] The summary function to apply to \code{formula}, if specified.

\item[\code{...}] Additional arguments to \code{FUN}, e.g. \code{na.rm=T}

\item[\code{include}] A vector of subject IDs to include in the summary, e.g. c(1:3,5,15)

\item[\code{exclude}] A vector of subject IDs to exclude in the summary, e.g. c(4,6:14,16:20)
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Summarize the raw data used for a Pmetrics run.
\end{Details}
%
\begin{Value}
A list of class \emph{summary.PMmatrix} with the summary of the PMmatrix object, 
containing the following items:
\begin{ldescription}
\item[\code{nsub}] Number of subjects
\item[\code{ndrug}] Number of drug inputs
\item[\code{numeqt}] Number of outputs
\item[\code{nobsXouteq}] Number of observations by outeq
\item[\code{missObsXouteq}] Number of missing observations by outeq
\item[\code{ncov}] Number of covariates
\item[\code{covnames}] Covariate names
\item[\code{ndoseXid}] Number of doses per input per subject
\item[\code{nobsXid}] Number of observations per outeq per subject
\item[\code{doseXid}] Doses per input per subject
\item[\code{obsXid}] Observations per outeq per subject
\item[\code{formula}] Results of including \code{formula}
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{print.summary.PMmatrix}{print.summary.PMmatrix}}, \code{\LinkA{aggregate}{aggregate}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{summary.PMop}{Summarize Observations and Predictions}{summary.PMop}
%
\begin{Description}\relax
Summarize a Pmetrics Observed vs. Predicted x
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMop'
summary(
  x,
  digits = max(3, getOption("digits") - 3),
  pred.type = "post",
  icen = "median",
  outeq = 1,
  ...
)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A PMop object made by \code{\LinkA{makeOP}{makeOP}}.

\item[\code{digits}] Integer, used for number of digits to print.

\item[\code{pred.type}] Either 'post' for a posterior object or 'pop' for a population object.  Default is 'post'.

\item[\code{icen}] Can be either "median" for the predictions based on medians of \code{pred.type} parameter value
distributions, or "mean".  Default is "median".

\item[\code{outeq}] Output equation number.  Default is 1.

\item[\code{...}] Other parameters which can be passed to \code{summary}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Summarize observations, predictions and errors in a PMop x made by \code{\LinkA{makeOP}{makeOP}}.
\end{Details}
%
\begin{Value}
A list with two xs.  The first component of the list is a
matrix with the minimum, first quartile, median, third quartile, maximum,
mean and standard deviation for times, observations and predictions in \code{x}.
The second contains the mean prediction error,
the mean weighted prediction error (bias), the mean squared prediction error, root mean sqaured error (RMSE),
percent root mean squared error (
squared prediction error, the bias-adjusted mean squared prediction error, and the bias-
adjusted mean weighted squared prediction error (imprecision).
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makeOP}{makeOP}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{summary.PMpta}{Summarize Percent Target Attainment}{summary.PMpta}
%
\begin{Description}\relax
Summarize a Pmetrics Percent Target Attainment Object
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'PMpta'
summary(x, ci = 0.95, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] A PMpta object made by \code{\LinkA{makePTA}{makePTA}}.

\item[\code{ci}] Confidence interval for pharmacodynamic index reporting.  Default is 0.95.

\item[\code{...}] Other parameters which can be passed to \code{summary}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Summarize target statistics and success proportions in a PMpta object made by \code{\LinkA{makePTA}{makePTA}}.
\end{Details}
%
\begin{Value}
A list with two named objects: pta (probability of target attainment)
and pti (pharmacodynamic index).
\begin{ldescription}
\item[\code{pta }] A data frame with the following columns: simnum, target, prop.success, pdi.mean, and pdi.sd  
\emph{simnum} is the number of the simulation; \emph{target} is the specified target; 
\emph{success}  has the proportion with a ratio > \code{prop.success}; \emph{pdi.mean} and \emph{pdi.sd} 
are the mean and standard deviation of the pharmacodyamic index (e.g. AUC/MIC) for each simulation and target.
\item[\code{pdi }] A data frame with the following columns: target, simnum, lowerCI, median, upperCI.
\emph{target} and \emph{simnum} are as above. \emph{lowerCI}, \emph{median}, 
and \emph{upperCI} are the lower limit, median, and upper limit of the confidence
interval for the pdi whose width is specified by \code{ci}
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Michael Neely
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{makePTA}{makePTA}}
\end{SeeAlso}
\inputencoding{utf8}
\HeaderA{[,NpdeData-method}{Get/set methods for NpdeData object}{[,NpdeData.Rdash.method}
\keyword{methods}{[,NpdeData-method}
%
\begin{Description}\relax
Access slots of a NpdeData using the object["slot"] format
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S4 method for signature 'NpdeData'
x[i, j, drop]
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{[,NpdeObject-method}{Get/set methods for NpdeData object}{[,NpdeObject.Rdash.method}
\keyword{methods}{[,NpdeObject-method}
%
\begin{Description}\relax
Access slots of a NpdeData using the object["slot"] format
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S4 method for signature 'NpdeObject'
x[i, j, drop]
\end{verbatim}
\end{Usage}
\inputencoding{utf8}
\HeaderA{[,NpdeRes-method}{Get/set methods for NpdeRes object}{[,NpdeRes.Rdash.method}
\keyword{methods}{[,NpdeRes-method}
%
\begin{Description}\relax
Access slots of a NpdeRes using the object["slot"] format
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S4 method for signature 'NpdeRes'
x[i, j, drop]
\end{verbatim}
\end{Usage}
\printindex{}
\end{document}
